import json
import copy
import traceback
import re
from typing import Dict, List, Any, Optional, Tuple, Callable
from storyteller.llm_call.openai_llm import call_openai
from storyteller.llm_call.prompt_factory import get_prompt
from storyteller.algorithm.utils.universalsc import run_universal_self_consistency
from storyteller.algorithm.mcts_node import Chapter, ReportGenerationState

def process_response(response_text: str, action_type: str) -> Any:
    """å¤„ç†LLMå“åº”ï¼Œæ ¹æ®ä¸åŒçš„è¡ŒåŠ¨ç±»å‹è¿›è¡Œå¤„ç†
    
    å‚æ•°:
        response_text: LLMè¿”å›çš„åŸå§‹å“åº”
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        
    è¿”å›:
        å¤„ç†åçš„å“åº”å¯¹è±¡
    """
    try:
        if action_type == "chapters":
            # å¤„ç†ç« èŠ‚å“åº”
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå–JSONéƒ¨åˆ†
            # ç§»é™¤Markdownä»£ç å—æ ‡è®°
            response_text = response_text.replace("```json", "").replace("```", "").strip()
            # è§£æJSON
            return json.loads(response_text)
        elif action_type == "tasks":
            # å¤„ç†ä»»åŠ¡å“åº”
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå–JSONéƒ¨åˆ†
            # ç§»é™¤Markdownä»£ç å—æ ‡è®°
            response_text = response_text.replace("```json", "").replace("```", "").strip()
            # è§£æJSON
            return json.loads(response_text)
        else:
            print(f"âš ï¸ æœªçŸ¥çš„è¡ŒåŠ¨ç±»å‹: {action_type}")
            return None
    except json.JSONDecodeError as e:
        print(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
        print(f"åŸå§‹å“åº”: {response_text}")
        return None
    except Exception as e:
        print(f"âŒ å¤„ç†å“åº”æ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return None

def get_clustering_config(action_type: str) -> Dict[str, Any]:
    """è·å–ä¸åŒè¡ŒåŠ¨ç±»å‹çš„èšç±»é…ç½®
    
    å‚æ•°:
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        
    è¿”å›:
        èšç±»é…ç½®å­—å…¸
    """
    if action_type == "chapters":
        return {
            "item_type": "ç« èŠ‚ç»“æ„æ–¹æ¡ˆ",
            "response_key": "chapters",
            "cluster_key": "chapters",
            "similarity_criteria": "- ç›¸ä¼¼æˆ–é‡æ–°æªè¾ä½†è¦†ç›–ç›¸åŒåˆ†æç»´åº¦çš„ç« èŠ‚\n- ç›¸åŒåˆ†æä¸»é¢˜çš„ç»†å¾®é‡æ–°æ’åº",
            "difference_criteria": "- å®Œå…¨ä¸åŒçš„åˆ†æç»´åº¦\n- é€šè¿‡ä¸åŒçš„é€»è¾‘æ¡†æ¶æ„å»ºåˆ†æ"
        }
    elif action_type == "tasks":
        return {
            "item_type": "æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆ",
            "response_key": "chapters",  # åŸå§‹å“åº”ä¸­çš„ç« èŠ‚é”®
            "cluster_key": "chapters",   # èšç±»ç»“æœåº”ä½¿ç”¨çš„é”®
            "similarity_criteria": "- å¯¹ç›¸åŒç« èŠ‚åˆ†é…äº†ç±»ä¼¼æ•°æ®åˆ†æä»»åŠ¡\n- ä½¿ç”¨ç›¸ä¼¼çš„å¯è§†åŒ–ç±»å‹å’Œè®¾è®¡ç­–ç•¥\n- å…³æ³¨ç›¸åŒçš„æ•°æ®ç‰¹å¾æˆ–ç»´åº¦",
            "difference_criteria": "- å¯¹ç« èŠ‚åˆ†é…äº†ä¸åŒçš„æ•°æ®åˆ†æä»»åŠ¡\n- ä½¿ç”¨ä¸åŒçš„å¯è§†åŒ–ç±»å‹å’Œè®¾è®¡ç­–ç•¥\n- å…³æ³¨ä¸åŒçš„æ•°æ®ç‰¹å¾æˆ–ç»´åº¦"
        }
    elif action_type == "transition":
        return {
            "item_type": "è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ",
            "response_key": "transitions",
            "cluster_key": "transitions",
            "similarity_criteria": "- ç›¸ä¼¼çš„è¿‡æ¸¡é€»è¾‘\n- å¼ºè°ƒç›¸åŒçš„ç« èŠ‚è¿æ¥ç‚¹\n- é‡‡ç”¨ç±»ä¼¼çš„å†™ä½œé£æ ¼",
            "difference_criteria": "- ä¸åŒçš„è¿‡æ¸¡é€»è¾‘\n- å¼ºè°ƒä¸åŒçš„ç« èŠ‚è¿æ¥ç‚¹\n- é‡‡ç”¨ä¸åŒçš„å†™ä½œé£æ ¼"
        }
    elif action_type == "narrative":
        return {
            "item_type": "å™äº‹ç­–ç•¥æ–¹æ¡ˆ",
            "response_key": "chapter_order",
            "cluster_key": "chapter_order",
            "similarity_criteria": "- ç›¸ä¼¼çš„ç« èŠ‚æ’åºé€»è¾‘\n- ç›¸ä¼¼çš„å™äº‹æ¡†æ¶",
            "difference_criteria": "- ä¸åŒçš„ç« èŠ‚æ’åºé€»è¾‘\n- ä¸åŒçš„å™äº‹æ¡†æ¶"
        }
    else:
        print(f"âš ï¸ æœªçŸ¥çš„è¡ŒåŠ¨ç±»å‹: {action_type}")
        return {
            "item_type": "æ–¹æ¡ˆ",
            "response_key": "items",
            "cluster_key": "items",
            "similarity_criteria": "- å†…å®¹ç›¸ä¼¼ä½†è¡¨è¿°ä¸åŒ\n- å…³æ³¨ç›¸åŒçš„ç»´åº¦",
            "difference_criteria": "- å†…å®¹æˆªç„¶ä¸åŒ\n- å…³æ³¨ä¸åŒçš„ç»´åº¦"
        }

def format_responses_for_clustering(responses: List[Any], action_type: str) -> List[Dict[str, Any]]:
    """æ ¼å¼åŒ–å“åº”ç”¨äºèšç±»
    
    å‚æ•°:
        responses: ç”Ÿæˆçš„å“åº”åˆ—è¡¨
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        
    è¿”å›:
        æ ¼å¼åŒ–åçš„å“åº”åˆ—è¡¨
    """
    formatted_responses = []
    config = get_clustering_config(action_type)
    response_key = config.get("response_key", "")
    
    if action_type == "tasks":
        # å¯¹äºä»»åŠ¡æ–¹æ¡ˆï¼Œå°†æ•´ä¸ªå“åº”ä½œä¸ºä¸€ä¸ªæ•´ä½“æ–¹æ¡ˆå¤„ç†
        for i, response in enumerate(responses):
            if isinstance(response, dict) and response_key in response:
                formatted_responses.append({
                    "index": i,
                    "content": response  # ä¼ é€’æ•´ä¸ªå“åº”ï¼ŒåŒ…å«æ‰€æœ‰ç« èŠ‚å’Œä»»åŠ¡
                })
            else:
                print(f"âš ï¸ å“åº” {i} æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡")
    else:
        # å…¶ä»–ç±»å‹ä½¿ç”¨åŸæœ‰é€»è¾‘
        for i, response in enumerate(responses):
            if isinstance(response, dict) and response_key in response:
                formatted_responses.append({
                    "index": i,
                    "content": response[response_key]
                })
            else:
                print(f"âš ï¸ å“åº” {i} æ ¼å¼ä¸æ­£ç¡®ï¼Œè·³è¿‡")
    
    return formatted_responses

def build_clustering_prompt(formatted_responses: List[Dict[str, Any]], action_type: str, **kwargs) -> str:
    """æ„å»ºèšç±»æç¤º
    
    å‚æ•°:
        formatted_responses: æ ¼å¼åŒ–åçš„å“åº”åˆ—è¡¨
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        **kwargs: å…¶ä»–å‚æ•°ï¼ŒåŒ…æ‹¬QUERYå’ŒDATA_CONTEXT
        
    è¿”å›:
        èšç±»æç¤ºå­—ç¬¦ä¸²
    """
    config = get_clustering_config(action_type)
    
    query = kwargs.get("QUERY", "æœªæä¾›æŸ¥è¯¢")
    data_context = kwargs.get("DATA_CONTEXT", "æœªæä¾›æ•°æ®ä¸Šä¸‹æ–‡")
    
    # æ ¹æ®ç±»å‹è°ƒæ•´æç¤ºå†…å®¹
    if action_type == "tasks":
        # å¯¹äºä»»åŠ¡æ–¹æ¡ˆçš„ç‰¹å®šæç¤º
        response_contents = []
        for i, resp in enumerate(formatted_responses):
            # ä¸ºæ¯ä¸ªæ•´ä½“ä»»åŠ¡æ–¹æ¡ˆåˆ›å»ºæ›´å‹å¥½çš„æ‘˜è¦
            resp_content = resp["content"]
            chapters = resp_content.get("chapters", [])
            
            chapters_summary = []
            for chapter in chapters:
                chapter_title = chapter.get("title", "æœªå‘½åç« èŠ‚")
                task_count = len(chapter.get("tasks", []))
                task_types = set()
                for task in chapter.get("tasks", []):
                    chart_types = task.get("chart_type", [])
                    if isinstance(chart_types, list) and chart_types:
                        task_types.add(chart_types[0])
                    elif isinstance(chart_types, str):
                        task_types.add(chart_types)
                
                chapters_summary.append(f"  - ç« èŠ‚ã€Œ{chapter_title}ã€: {task_count}ä¸ªä»»åŠ¡, å›¾è¡¨ç±»å‹: {', '.join(task_types)}")
            
            summary = f"æ–¹æ¡ˆç´¢å¼•: {resp['index']}\nç« èŠ‚å’Œä»»åŠ¡æ¦‚å†µ:\n" + "\n".join(chapters_summary)
            response_contents.append(summary)
        
        # æ„å»ºç‰¹å®šäºä»»åŠ¡æ–¹æ¡ˆçš„æç¤º
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®åˆ†æå’Œå¯è§†åŒ–ä¸“å®¶ã€‚è¯·å¸®åŠ©æˆ‘å¯¹å¤šä¸ªæ•´ä½“ä»»åŠ¡æ–¹æ¡ˆè¿›è¡Œèšç±»åˆ†æã€‚

# ç”¨æˆ·æŸ¥è¯¢
{query}

# æ•°æ®ä¸Šä¸‹æ–‡
{data_context}

# å€™é€‰æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆ
ä»¥ä¸‹æ˜¯å¤šä¸ªå€™é€‰æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆçš„æ¦‚å†µï¼Œæ¯ä¸ªæ–¹æ¡ˆéƒ½åŒ…å«å¤šä¸ªç« èŠ‚åŠå…¶ä»»åŠ¡:

{chr(10).join(response_contents)}

# èšç±»æ ‡å‡†
è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†å¯¹å€™é€‰æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆè¿›è¡Œèšç±»:

## ç›¸ä¼¼æ€§æ ‡å‡†ï¼ˆåŒä¸€èšç±»ï¼‰
{config['similarity_criteria']}

## å·®å¼‚æ€§æ ‡å‡†ï¼ˆä¸åŒèšç±»ï¼‰
{config['difference_criteria']}

# ä»»åŠ¡
1. åˆ†ææ¯ä¸ªå€™é€‰æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆçš„ç« èŠ‚åˆ†é…å’Œä»»åŠ¡ç‰¹ç‚¹
2. æ ¹æ®ç›¸ä¼¼æ€§æ ‡å‡†å°†ç›¸ä¼¼çš„æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆåˆ†ç»„åˆ°åŒä¸€èšç±»
3. ç¡®ä¿ä¸åŒèšç±»ä¹‹é—´å…·æœ‰æ˜æ˜¾çš„å·®å¼‚
4. ä¸ºæ¯ä¸ªèšç±»æä¾›ä¸€ä¸ªå”¯ä¸€çš„IDå’Œç®€çŸ­æè¿°
5. ä»æ¯ä¸ªèšç±»ä¸­é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆ

# è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„:
```json
{{
  "clusters": [
    {{
      "cluster_id": "å”¯ä¸€èšç±»ID",
      "description": "èšç±»ç®€çŸ­æè¿°",
      "indices": [å€™é€‰æ–¹æ¡ˆçš„ç´¢å¼•æ•°ç»„],
      "best_index": æœ€ä¼˜æ–¹æ¡ˆçš„ç´¢å¼•,
      "reason": "é€‰æ‹©è¯¥æ–¹æ¡ˆä½œä¸ºæœ€ä¼˜çš„åŸå› "
    }}
    // æ›´å¤šèšç±»...
  ]
}}
```

æ³¨æ„:
- æ¯ä¸ªå€™é€‰æ•´ä½“ä»»åŠ¡æ–¹æ¡ˆå¿…é¡»ä¸”åªèƒ½å±äºä¸€ä¸ªèšç±»
- èšç±»æ•°é‡åº”æ ¹æ®å†…å®¹å·®å¼‚è‡ªç„¶ç¡®å®šï¼Œä¸éœ€è¦å¼ºåˆ¶æŒ‡å®š
- è¯·ç¡®ä¿é€‰æ‹©çš„æœ€ä¼˜æ–¹æ¡ˆ(best_index)å­˜åœ¨äºè¯¥èšç±»çš„indicesæ•°ç»„ä¸­

è¯·ç¡®ä¿è¾“å‡ºä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
    else:
        # åŸæœ‰çš„é€šç”¨æç¤º
        prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ•°æ®åˆ†æå’Œèšç±»ä¸“å®¶ã€‚è¯·å¸®åŠ©æˆ‘å¯¹å¤šä¸ª{config['item_type']}è¿›è¡Œèšç±»åˆ†æã€‚

# ç”¨æˆ·æŸ¥è¯¢
{query}

# æ•°æ®ä¸Šä¸‹æ–‡
{data_context}

# å€™é€‰{config['item_type']}
ä»¥ä¸‹æ˜¯å¤šä¸ªå€™é€‰{config['item_type']}ï¼Œæ¯ä¸ªéƒ½æœ‰ç´¢å¼•å’Œå†…å®¹:
{json.dumps(formatted_responses, ensure_ascii=False, indent=2)}

# èšç±»æ ‡å‡†
è¯·æ ¹æ®ä»¥ä¸‹æ ‡å‡†å¯¹å€™é€‰{config['item_type']}è¿›è¡Œèšç±»:

## ç›¸ä¼¼æ€§æ ‡å‡†ï¼ˆåŒä¸€èšç±»ï¼‰
{config['similarity_criteria']}

## å·®å¼‚æ€§æ ‡å‡†ï¼ˆä¸åŒèšç±»ï¼‰
{config['difference_criteria']}

# ä»»åŠ¡
1. åˆ†ææ¯ä¸ªå€™é€‰{config['item_type']}çš„å†…å®¹å’Œç»“æ„
2. æ ¹æ®ç›¸ä¼¼æ€§æ ‡å‡†å°†ç›¸ä¼¼çš„{config['item_type']}åˆ†ç»„åˆ°åŒä¸€èšç±»
3. ç¡®ä¿ä¸åŒèšç±»ä¹‹é—´å…·æœ‰æ˜æ˜¾çš„å·®å¼‚
4. ä¸ºæ¯ä¸ªèšç±»æä¾›ä¸€ä¸ªå”¯ä¸€çš„IDå’Œç®€çŸ­æè¿°
5. ä»æ¯ä¸ªèšç±»ä¸­é€‰æ‹©æœ€å…·ä»£è¡¨æ€§çš„å†…å®¹

# è¾“å‡ºæ ¼å¼
è¯·ä»¥JSONæ ¼å¼è¾“å‡ºç»“æœï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„:
```json
{{
  "clusters": [
    {{
      "cluster_id": "å”¯ä¸€èšç±»ID",
      "description": "èšç±»ç®€çŸ­æè¿°",
      "indices": [å€™é€‰æ–¹æ¡ˆçš„ç´¢å¼•æ•°ç»„],
      "{config['cluster_key']}": [ä»£è¡¨æ€§å†…å®¹]
    }},
    // æ›´å¤šèšç±»...
  ]
}}
```

æ³¨æ„:
- æ¯ä¸ªå€™é€‰{config['item_type']}å¿…é¡»ä¸”åªèƒ½å±äºä¸€ä¸ªèšç±»
- èšç±»æ•°é‡åº”æ ¹æ®å†…å®¹å·®å¼‚è‡ªç„¶ç¡®å®šï¼Œä¸éœ€è¦å¼ºåˆ¶æŒ‡å®š
- ä»£è¡¨æ€§å†…å®¹åº”è¯¥æ˜¯èšç±»ä¸­æœ€æ¸…æ™°ã€æœ€å…¨é¢çš„å†…å®¹

è¯·ç¡®ä¿è¾“å‡ºä¸ºæœ‰æ•ˆçš„JSONæ ¼å¼ã€‚
"""
    
    return prompt

def cluster_responses(formatted_responses: List[Dict[str, Any]], action_type: str, llm_kwargs: Dict[str, Any], **kwargs) -> List[Dict[str, Any]]:
    """å¯¹å“åº”è¿›è¡Œèšç±»
    
    å‚æ•°:
        formatted_responses: æ ¼å¼åŒ–åçš„å“åº”åˆ—è¡¨
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        llm_kwargs: LLMè°ƒç”¨å‚æ•°
        **kwargs: å…¶ä»–å‚æ•°
        
    è¿”å›:
        èšç±»ç»“æœåˆ—è¡¨
    """
    # æ„å»ºèšç±»æç¤º
    prompt = build_clustering_prompt(formatted_responses, action_type, **kwargs)
    
    # è°ƒç”¨LLMè¿›è¡Œèšç±»
    responses = call_openai(prompt, **llm_kwargs)
    if not responses:
        print(f"âŒ èšç±»æ—¶æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
        return []
    
    # å¤„ç†èšç±»ç»“æœ
    try:
        response_text = responses[0]
        print(f"æ”¶åˆ°åŸå§‹èšç±»å“åº”: \n{response_text}...")  # æ‰“å°å‰100ä¸ªå­—ç¬¦ç”¨äºè°ƒè¯•
        
        # å¢å¼ºçš„JSONæå–
        # 1. å°è¯•æŸ¥æ‰¾JSONä»£ç å—
        json_pattern = r'```(?:json)?\s*({[\s\S]*?})\s*```'
        json_matches = re.findall(json_pattern, response_text)
        
        if json_matches:
            # ä½¿ç”¨ç¬¬ä¸€ä¸ªæ‰¾åˆ°çš„JSONå—
            json_text = json_matches[0]
            print(f"ä»å“åº”ä¸­æå–åˆ°JSONå—ï¼Œé•¿åº¦: {len(json_text)}")
        else:
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°JSONä»£ç å—ï¼Œå°è¯•å¯»æ‰¾å¯èƒ½çš„JSONå¯¹è±¡
            curly_pattern = r'({[\s\S]*})'
            curly_matches = re.findall(curly_pattern, response_text)
            
            if curly_matches:
                potential_jsons = []
                for match in curly_matches:
                    try:
                        # å°è¯•è§£ææ¯ä¸ªæ½œåœ¨çš„JSON
                        json.loads(match)
                        potential_jsons.append(match)
                    except:
                        pass
                
                if potential_jsons:
                    # ä½¿ç”¨æ‰¾åˆ°çš„æœ€é•¿çš„æœ‰æ•ˆJSON
                    json_text = max(potential_jsons, key=len)
                    print(f"ä»å“åº”ä¸­æå–åˆ°å¯èƒ½çš„JSONå¯¹è±¡ï¼Œé•¿åº¦: {len(json_text)}")
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„JSONï¼Œå›é€€åˆ°åŸå§‹æ¸…ç†æ–¹æ³•
                    json_text = response_text.replace("```json", "").replace("```", "").strip()
                    print("æœªæ‰¾åˆ°æ˜ç¡®çš„JSONå—ï¼Œä½¿ç”¨æ¸…ç†åçš„å®Œæ•´å“åº”")
            else:
                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»ä½•èŠ±æ‹¬å·ï¼Œå›é€€åˆ°åŸå§‹æ¸…ç†æ–¹æ³•
                json_text = response_text.replace("```json", "").replace("```", "").strip()
                print("æœªæ‰¾åˆ°ä»»ä½•JSONæ ¼å¼å†…å®¹ï¼Œä½¿ç”¨æ¸…ç†åçš„å®Œæ•´å“åº”")
        
        # å°è¯•è§£ææå–çš„JSONæ–‡æœ¬
        clustering_result = json.loads(json_text)
        
        # æå–èšç±»
        if "clusters" in clustering_result:
            clusters = clustering_result["clusters"]
            print(f"æˆåŠŸè§£æåˆ° {len(clusters)} ä¸ªèšç±»")
            
            # ç‰¹æ®Šå¤„ç†ä»»åŠ¡èšç±»ç»“æœ
            if action_type == "tasks":
                # å¯¹äºä»»åŠ¡æ–¹æ¡ˆï¼Œéœ€è¦ä»åŸå§‹å“åº”ä¸­æå–å®Œæ•´çš„ä»»åŠ¡æ–¹æ¡ˆ
                for cluster in clusters:
                    if "best_index" in cluster:
                        best_index = cluster["best_index"]
                        # æŸ¥æ‰¾è¿™ä¸ªç´¢å¼•å¯¹åº”çš„åŸå§‹å“åº”
                        for resp in formatted_responses:
                            if resp["index"] == best_index:
                                # å°†å®Œæ•´çš„åŸå§‹å“åº”æ”¾å…¥èšç±»ç»“æœä¸­
                                cluster["chapters"] = resp["content"]["chapters"]
                                print(f"ä¸ºèšç±» {cluster.get('cluster_id', 'unknown')} åº”ç”¨æœ€ä¼˜æ–¹æ¡ˆ (ç´¢å¼•: {best_index})")
                                break
                    else:
                        # å¦‚æœæ²¡æœ‰æŒ‡å®šbest_indexï¼Œä½¿ç”¨ç¬¬ä¸€ä¸ªç´¢å¼•
                        indices = cluster.get("indices", [])
                        if indices:
                            best_index = indices[0]
                            for resp in formatted_responses:
                                if resp["index"] == best_index:
                                    cluster["chapters"] = resp["content"]["chapters"]
                                    print(f"ä¸ºèšç±» {cluster.get('cluster_id', 'unknown')} åº”ç”¨ç¬¬ä¸€ä¸ªæ–¹æ¡ˆ (ç´¢å¼•: {best_index})")
                                    break
            
            return clusters
        else:
            print(f"âŒ èšç±»ç»“æœä¸­æ²¡æœ‰æ‰¾åˆ°clustersé”®")
            return []
    except json.JSONDecodeError as e:
        print(f"âŒ èšç±»ç»“æœJSONè§£æé”™è¯¯: {str(e)}")
        print(f"åŸå§‹å“åº”: {response_text}")
        
        # å°è¯•æ›´çµæ´»çš„æ–¹å¼æå–JSON
        try:
            # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æŸ¥æ‰¾ä»¥"clusters"å¼€å§‹çš„JSONæ•°ç»„éƒ¨åˆ†
            clusters_pattern = r'"clusters"\s*:\s*(\[[\s\S]*?\])'
            clusters_match = re.search(clusters_pattern, response_text)
            
            if clusters_match:
                clusters_text = "{" + f'"clusters":{clusters_match.group(1)}' + "}"
                clusters_json = json.loads(clusters_text)
                print(f"ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼æˆåŠŸæå–clusterséƒ¨åˆ†")
                
                # å¦‚æœæ˜¯ä»»åŠ¡èšç±»ï¼Œéœ€è¦é¢å¤–å¤„ç†
                if action_type == "tasks":
                    for cluster in clusters_json["clusters"]:
                        if "best_index" in cluster:
                            best_index = cluster["best_index"]
                            for resp in formatted_responses:
                                if resp["index"] == best_index:
                                    cluster["chapters"] = resp["content"]["chapters"]
                                    break
                
                return clusters_json["clusters"]
        except Exception as nested_e:
            print(f"äºŒæ¬¡å°è¯•è§£æä¹Ÿå¤±è´¥: {str(nested_e)}")
        
        return []
    except Exception as e:
        print(f"âŒ å¤„ç†èšç±»ç»“æœæ—¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return []

def create_fallback_node(node, action, depth_increment=1):
    """åˆ›å»ºåå¤‡èŠ‚ç‚¹ï¼Œç”¨äºé”™è¯¯å¤„ç†æƒ…å†µ
    
    å‚æ•°:
        node: åŸå§‹èŠ‚ç‚¹
        action: çˆ¶è¡ŒåŠ¨
        depth_increment: æ·±åº¦å¢é‡
        
    è¿”å›:
        åå¤‡èŠ‚ç‚¹
    """
    fallback_node = copy.deepcopy(node)
    fallback_node.parent_node = node
    fallback_node.parent_action = action
    fallback_node.depth = node.depth + depth_increment
    
    # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
    if action.__class__.__name__ == "Query2Chapters":
        fallback_node.node_type = ReportGenerationState.a1
    elif action.__class__.__name__ == "Chapters2Tasks":
        fallback_node.node_type = ReportGenerationState.a2
    
    return fallback_node

def generate_diverse_responses(prompt: str, llm_kwargs: Dict[str, Any], n: int = 4) -> List[Any]:
    """ç”Ÿæˆå¤šæ ·åŒ–çš„å“åº”
    
    å‚æ•°:
        prompt: æç¤ºå­—ç¬¦ä¸²
        llm_kwargs: LLMè°ƒç”¨å‚æ•°
        n: ç”Ÿæˆå“åº”çš„æ•°é‡
        
    è¿”å›:
        å¤„ç†åçš„å“åº”åˆ—è¡¨
    """
    # å¤åˆ¶LLMå‚æ•°ä»¥ä¾¿ä¿®æ”¹
    llm_kwargs_copy = llm_kwargs.copy()
    
    responses = []
    for i in range(n):
        # ä¸ºæ¯æ¬¡ç”Ÿæˆè°ƒæ•´æ¸©åº¦å‚æ•°
        llm_kwargs_copy['temperature'] = 0.3 + (i * 0.2)  # 0.3, 0.5, 0.7, 0.9
        
        print(f"ğŸ”„ ç”Ÿæˆå“åº” {i+1}/{n} (æ¸©åº¦: {llm_kwargs_copy['temperature']})")
        
        # è°ƒç”¨LLMç”Ÿæˆå“åº”
        response_texts = call_openai(prompt, **llm_kwargs_copy)
        if not response_texts:
            print(f"âš ï¸ ç”Ÿæˆ {i+1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
            continue
        
        response_text = response_texts[0]
        
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå–JSONéƒ¨åˆ†
            response_text = response_text.replace("```json", "").replace("```", "").strip()
            # è§£æJSON
            response_json = json.loads(response_text)
            responses.append(response_json)
            
            print(f"âœ… ç”Ÿæˆ {i+1} æˆåŠŸ")
        except json.JSONDecodeError as e:
            print(f"âŒ ç”Ÿæˆ {i+1} JSONè§£æé”™è¯¯: {str(e)}")
            print(f"åŸå§‹å“åº”: {response_text}")
        except Exception as e:
            print(f"âŒ ç”Ÿæˆ {i+1} å¤„ç†å‡ºé”™: {str(e)}")
    
    return responses

def unified_generation_framework(node, action, llm_kwargs: Dict[str, Any], 
                               action_type: str, 
                               prompt_generator: Callable, 
                               node_applier: Callable,
                               n: int = 4, 
                               **kwargs) -> List[Any]:
    """ç»Ÿä¸€çš„ç”Ÿæˆæ¡†æ¶ï¼Œç”¨äºç”Ÿæˆå’Œèšç±»å¤šæ ·æœ¬
    
    å‚æ•°:
        node: å½“å‰èŠ‚ç‚¹
        action: è¡ŒåŠ¨å¯¹è±¡
        llm_kwargs: LLMè°ƒç”¨å‚æ•°
        action_type: è¡ŒåŠ¨ç±»å‹ï¼Œå¦‚"chapters"æˆ–"tasks"
        prompt_generator: æç¤ºç”Ÿæˆå‡½æ•°ï¼Œæ¥æ”¶èŠ‚ç‚¹å’Œå…¶ä»–å‚æ•°ï¼Œè¿”å›æç¤ºå­—ç¬¦ä¸²
        node_applier: èŠ‚ç‚¹åº”ç”¨å‡½æ•°ï¼Œæ¥æ”¶èŠ‚ç‚¹ã€èšç±»ç»“æœå’Œå…¶ä»–å‚æ•°ï¼Œè¿”å›æ›´æ–°åçš„èŠ‚ç‚¹
        n: ç”Ÿæˆæ ·æœ¬æ•°é‡
        **kwargs: å…¶ä»–å‚æ•°
        
    è¿”å›:
        å­èŠ‚ç‚¹åˆ—è¡¨
    """
    try:
        # è·å–å¿…è¦çš„å‚æ•°
        query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
        data_context = node.report.data_context
        
        print(f"ğŸ” æ­£åœ¨ç”Ÿæˆ{action_type}...")
        
        # ç”Ÿæˆprompt
        prompt = prompt_generator(node, **kwargs)
        
        # æ£€æŸ¥æ˜¯å¦åº”è¯¥ä½¿ç”¨UniversalSCæ–¹æ³•
        if action_type == "chapters" and hasattr(node.report, "use_usc") and node.report.use_usc:
            print("ğŸ”„ ä½¿ç”¨UniversalSCæ–¹æ³•ç”Ÿæˆç« èŠ‚...")
            clusters = run_universal_self_consistency(query, data_context, llm_kwargs, n=n)
            print(f"âœ… å®Œæˆç« èŠ‚èšç±»ï¼Œå¾—åˆ° {len(clusters)} ä¸ªèšç±»")
        else:
            # ç”Ÿæˆå¤šæ ·åŒ–å“åº”
            responses = generate_diverse_responses(prompt, llm_kwargs, n=n)
            print(f"âœ… ç”Ÿæˆäº† {len(responses)} ä¸ªæœ‰æ•ˆå“åº”")
            
            if not responses:
                print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆå“åº”ï¼Œè¿”å›åå¤‡èŠ‚ç‚¹")
                return [create_fallback_node(node, action)]
            
            # æ ¼å¼åŒ–å“åº”ç”¨äºèšç±»
            formatted_responses = format_responses_for_clustering(responses, action_type)
            print(f"âœ… æ ¼å¼åŒ–äº† {len(formatted_responses)} ä¸ªå“åº”ç”¨äºèšç±»")
            
            if len(formatted_responses) < 2:
                print("âš ï¸ å¯èšç±»çš„å“åº”æ•°é‡ä¸è¶³ï¼Œä½¿ç”¨å•ä¸€å“åº”")
                # å¦‚æœåªæœ‰ä¸€ä¸ªæœ‰æ•ˆå“åº”ï¼Œç›´æ¥ä½¿ç”¨å®ƒ
                if formatted_responses:
                    if action_type == "tasks":
                        # å¯¹äºä»»åŠ¡ï¼Œç›´æ¥ä½¿ç”¨å®Œæ•´çš„å“åº”
                        response_idx = formatted_responses[0]["index"]
                        content = formatted_responses[0]["content"]
                        
                        # åˆ›å»ºä¸€ä¸ªèšç±»ç»“æ„
                        clusters = [{
                            "cluster_id": "cluster_1",
                            "description": "å”¯ä¸€ä»»åŠ¡æ–¹æ¡ˆ",
                            "indices": [response_idx],
                            "chapters": content["chapters"]
                        }]
                    else:
                        # å…¶ä»–ç±»å‹ä½¿ç”¨åŸæœ‰é€»è¾‘
                        config = get_clustering_config(action_type)
                        response_idx = formatted_responses[0]["index"]
                        content = formatted_responses[0]["content"]
                        
                        clusters = [{
                            "cluster_id": "cluster_1",
                            config.get("cluster_key", "items"): content
                        }]
                else:
                    print("âŒ æ²¡æœ‰å¯ç”¨çš„å“åº”ï¼Œè¿”å›åå¤‡èŠ‚ç‚¹")
                    return [create_fallback_node(node, action)]
            else:
                # å¯¹å“åº”è¿›è¡Œèšç±»
                # æ·»åŠ æŸ¥è¯¢å’Œæ•°æ®ä¸Šä¸‹æ–‡åˆ°èšç±»å‚æ•°
                clustering_kwargs = {
                    "QUERY": query,
                    "DATA_CONTEXT": data_context,
                    **kwargs
                }
                
                clusters = cluster_responses(formatted_responses, action_type, llm_kwargs, **clustering_kwargs)
                print(f"âœ… èšç±»å®Œæˆï¼Œå¾—åˆ° {len(clusters)} ä¸ªèšç±»")
        
        if not clusters:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆèšç±»ï¼Œè¿”å›åå¤‡èŠ‚ç‚¹")
            return [create_fallback_node(node, action)]
        
        # åˆ›å»ºå­èŠ‚ç‚¹
        nodes = []
        for cluster_idx, cluster in enumerate(clusters):
            # ä½¿ç”¨èŠ‚ç‚¹åº”ç”¨å‡½æ•°å°†èšç±»ç»“æœåº”ç”¨åˆ°èŠ‚ç‚¹
            child_nodes = node_applier(node, action, cluster, **kwargs)
            if child_nodes:
                nodes.extend(child_nodes)
                print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_idx+1}/{len(clusters)}")
            else:
                print(f"âš ï¸ åº”ç”¨èšç±» {cluster_idx+1}/{len(clusters)} å¤±è´¥")
        
        if not nodes:
            print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆèŠ‚ç‚¹ï¼Œè¿”å›åå¤‡èŠ‚ç‚¹")
            return [create_fallback_node(node, action)]
            
        return nodes
    
    except Exception as e:
        print(f"âŒ ç»Ÿä¸€ç”Ÿæˆæ¡†æ¶å‡ºé”™: {str(e)}")
        traceback.print_exc()
        return [create_fallback_node(node, action)] 