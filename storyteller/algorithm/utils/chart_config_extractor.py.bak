import json
import re
from typing import Dict, Any, List, Optional, Union, Tuple
import pandas as pd
import numpy as np
import os
import sys
import yaml
from dotenv import load_dotenv
from storyteller.llm_call.openai_llm import call_openai
from storyteller.llm_call.prompt_factory import get_prompt

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv(override=True)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
# è·å–å½“å‰æ–‡ä»¶çš„è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
# è·å–é¡¹ç›®æ ¹ç›®å½•ï¼ˆå‡è®¾å½“å‰æ–‡ä»¶åœ¨storyteller/algorithm/utils/ä¸‹ï¼‰
project_root = os.path.abspath(os.path.join(current_dir, '../../..'))
if project_root not in sys.path:
    sys.path.append(project_root)

# åŠ è½½å…¨å±€é…ç½®
def load_config():
    """åŠ è½½config.yamlä¸­çš„é…ç½®"""
    config_path = os.path.join(current_dir, "../../config/config.yaml")
    try:
        with open(config_path, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        print(f"âœ… æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶: {config_path}")
        return config
    except Exception as e:
        print(f"âš ï¸ åŠ è½½é…ç½®æ–‡ä»¶å¤±è´¥: {str(e)}")
        return {"llm_kwargs": {}}

# å…¨å±€é…ç½®
GLOBAL_CONFIG = load_config()

class ChartConfigExtractor:
    """
    ä½¿ç”¨LLMè§£æPythonå¯è§†åŒ–ä»£ç ï¼Œæå–å›¾è¡¨é…ç½®ä¿¡æ¯ï¼Œ
    ä»¥ä¾¿è½¬æ¢ä¸ºAntV G2é…ç½®ã€‚
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. ä½¿ç”¨GPT-4åˆ†æPythonå¯è§†åŒ–ä»£ç 
    2. æå–å…³é”®é…ç½®ä¿¡æ¯ï¼ˆå›¾è¡¨ç±»å‹ã€å­—æ®µã€èšåˆæ–¹æ³•ç­‰ï¼‰
    3. å¤„ç†æ•°æ®å¹¶ç”ŸæˆG2æ ¼å¼çš„é…ç½®
    """
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        self.default_config = {
            "chart_type": "bar",
            "title": None,
            "x_field": None,
            "y_field": None,
            "data_columns": [],
            "hue_column": None,
            "is_stacked": False,
            "agg_method": None
        }

    def extract_from_code(self, code: str) -> Dict[str, Any]:
        """
        ä»ä»£ç ä¸­æå–å›¾è¡¨é…ç½®
        
        å‚æ•°:
            code: å¯è§†åŒ–ä»£ç å­—ç¬¦ä¸²
            
        è¿”å›:
            åŒ…å«å›¾è¡¨é…ç½®çš„å­—å…¸
        """
        try:
            # å‡†å¤‡å‚æ•°
            prompt_args = {
                "CODE": code
            }
            
            # è·å–æ¨¡æ¿
            prompt = get_prompt("chart_config_analysis", prompt_args)
            
            # ä»å…¨å±€é…ç½®ä¸­è·å–LLMå‚æ•°
            llm_kwargs = GLOBAL_CONFIG.get("llm_kwargs", {})
            if not llm_kwargs:
                print("âš ï¸ æœªæ‰¾åˆ°å…¨å±€LLMé…ç½®ï¼Œä½¿ç”¨é»˜è®¤å€¼")
                llm_kwargs = {
                    "model": "gpt-4-32k",
                    "temperature": 0.0,
                    "max_tokens": 4096
                }
            else:
                # ç¡®ä¿å…³é”®å‚æ•°å­˜åœ¨ï¼ŒåŒæ—¶è¦†ç›–temperatureä¸º0
                llm_kwargs = llm_kwargs.copy()  # åˆ›å»ºå‰¯æœ¬é¿å…ä¿®æ”¹å…¨å±€é…ç½®
                llm_kwargs["temperature"] = 0.0  # å¯¹äºé…ç½®æå–ï¼Œå§‹ç»ˆä½¿ç”¨ä½temperature
                llm_kwargs["max_tokens"] = llm_kwargs.get("max_tokens", 4096)
            
            print(f"ğŸ” ä½¿ç”¨LLMé…ç½®: model={llm_kwargs.get('model')}, base_url={llm_kwargs.get('base_url', 'é»˜è®¤')}")
            
            # å®ç°é‡è¯•æœºåˆ¶
            max_retries = 3
            for retry in range(max_retries):
                try:
                    # è°ƒç”¨LLMï¼Œä½¿ç”¨å…¨å±€é…ç½®
                    responses = call_openai(
                        prompt=prompt,
                        **llm_kwargs
                    )
                    
                    if responses and len(responses) > 0:
                        response_text = responses[0].strip()
                        print(f"âœ… æˆåŠŸè·å–LLMå“åº” (å°è¯• {retry+1}/{max_retries})")
                        
                        # è§£æJSONå“åº”
                        config = self._parse_json_response(response_text)
                        
                        # å¦‚æœè·å–åˆ°äº†é…ç½®
                        if config:
                            # å¡«å……é»˜è®¤å€¼
                            return self._fill_config_defaults(config)
                    
                    # å¦‚æœæ²¡æœ‰è·å–åˆ°æœ‰æ•ˆå“åº”ï¼Œé‡è¯•
                    print(f"âš ï¸ LLMè°ƒç”¨æ²¡æœ‰è¿”å›æœ‰æ•ˆé…ç½® (å°è¯• {retry+1}/{max_retries})")
                    if retry < max_retries - 1:
                        print("å°†åœ¨1ç§’åé‡è¯•...")
                        import time
                        time.sleep(1)
                    
                except Exception as e:
                    print(f"âš ï¸ LLM APIè°ƒç”¨å‡ºé”™: {str(e)} (å°è¯• {retry+1}/{max_retries})")
                    import traceback
                    traceback.print_exc()
                    if retry < max_retries - 1:
                        print("å°†åœ¨1ç§’åé‡è¯•...")
                        import time
                        time.sleep(1)
            
            # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥ï¼Œè¿”å›é»˜è®¤é…ç½®
            print("âš ï¸ è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œè¿”å›é»˜è®¤å›¾è¡¨é…ç½®")
            
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç‰¹å®šå›¾è¡¨ç±»å‹
            if "hist" in code.lower():
                default_config = self.default_config.copy()
                default_config["chart_type"] = "histogram"
                print("æ£€æµ‹åˆ°å¯èƒ½æ˜¯histogramå›¾è¡¨ï¼Œè®¾ç½®é»˜è®¤chart_typeä¸ºhistogram")
                return default_config
                
            return self.default_config.copy()
        
        except Exception as e:
            print(f"æå–å›¾è¡¨é…ç½®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            # è¿”å›é»˜è®¤é…ç½®
            return self.default_config.copy()
    
    
    def _parse_json_response(self, response_text: str) -> Dict[str, Any]:
        """è§£æLLMè¿”å›çš„JSONå“åº”"""
        try:
            # ç›´æ¥å°è¯•è§£æ
            return json.loads(response_text)
        except json.JSONDecodeError:
            # å°è¯•æå–JSONéƒ¨åˆ†
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                try:
                    return json.loads(json_match.group(0))
                except:
                    print("æ— æ³•è§£ææå–çš„JSONéƒ¨åˆ†")
            
            # æœ€åä¸€æ¬¡å°è¯•ï¼šä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯
            try:
                # æ›¿æ¢å•å¼•å·ä¸ºåŒå¼•å·
                fixed_text = response_text.replace("'", '"')
                # ç¡®ä¿å±æ€§åæœ‰åŒå¼•å·
                fixed_text = re.sub(r'(\w+):', r'"\1":', fixed_text)
                return json.loads(fixed_text)
            except:
                print("æ‰€æœ‰JSONè§£æå°è¯•éƒ½å¤±è´¥äº†")
            
        return None
    
    def _fill_config_defaults(self, config: Dict[str, Any]) -> Dict[str, Any]:
        """å¡«å……é…ç½®ä¸­ç¼ºå¤±çš„é»˜è®¤å€¼"""
        # å¤åˆ¶é»˜è®¤é…ç½®
        result = self.default_config.copy()
        
        # ç¡®ä¿ä¸ä¸¢å¤±æ´¾ç”Ÿåˆ—ä¿¡æ¯
        if "derived_columns" in config:
            result["derived_columns"] = config["derived_columns"]
        
        # ç”¨æä¾›çš„é…ç½®æ›´æ–°é»˜è®¤å€¼
        result.update(config)
        
        # ç¡®ä¿å›¾è¡¨ç±»å‹æœ‰æ•ˆ
        if not result["chart_type"]:
            result["chart_type"] = "bar"
        
        # æ™ºèƒ½æ„å»ºæ ‡é¢˜ï¼ˆå¦‚æœç¼ºå¤±ï¼‰
        if not result["title"]:
            x_field = result.get("x_field", "")
            y_field = result.get("y_field", "")
            agg_method = result.get("agg_method", "")
            
            if agg_method and y_field:
                agg_display = {
                    "count": "Count of",
                    "sum": "Sum of",
                    "mean": "Average",
                    "min": "Minimum",
                    "max": "Maximum"
                }.get(agg_method, agg_method.capitalize())
                
                result["title"] = f"{agg_display} {y_field} by {x_field}"
            elif x_field and y_field:
                result["title"] = f"{y_field} by {x_field}"
        
        return result
    
    def _handle_special_chart_types(self, df_copy: pd.DataFrame, chart_type: str, x_field: str, y_field: str) -> Optional[Dict[str, Any]]:
        """å¤„ç†ç‰¹æ®Šå›¾è¡¨ç±»å‹ï¼ˆboxplotã€violinã€histogramã€scatterï¼‰"""
        try:
            if not (x_field and y_field and y_field in df_copy.columns):
                return None
                
            print(f"ä¸º{chart_type}ç±»å‹å‡†å¤‡æ•°æ®ï¼Œä¸ä½¿ç”¨èšåˆ...")
            
            # æ•£ç‚¹å›¾ç‰¹æ®Šå¤„ç†
            if chart_type == "scatter":
                return self._handle_scatter_plot(df_copy, x_field, y_field)
            
            # boxplotç­‰å…¶ä»–åˆ†å¸ƒå›¾è¡¨å¤„ç†
            # è·å–å”¯ä¸€çš„xå€¼ä½œä¸ºæ ‡ç­¾
            unique_x = df_copy[x_field].unique()
            labels = [str(x) for x in unique_x]
            
            # ä¸ºæ¯ä¸ªxå€¼åˆ›å»ºå¯¹åº”çš„yå€¼æ•°ç»„
            datasets = []
            for x_val in unique_x:
                y_values = df_copy[df_copy[x_field] == x_val][y_field].tolist()
                datasets.append({
                    "label": str(x_val),
                    "data": y_values
                })
            
            return {
                "type": chart_type,  # æ·»åŠ å›¾è¡¨ç±»å‹
                "labels": labels,
                "datasets": datasets
            }
            
        except Exception as e:
            print(f"å¤„ç†{chart_type}æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return None
    
    def _handle_scatter_plot(self, df: pd.DataFrame, x_field: str, y_field: str) -> Dict[str, Any]:
        """å¤„ç†æ•£ç‚¹å›¾æ•°æ®"""
        df_copy = df.copy()
        
        # ç¡®ä¿xå’Œyå­—æ®µéƒ½æ˜¯æ•°å€¼ç±»å‹
        for field, name in [(x_field, 'Xè½´'), (y_field, 'Yè½´')]:
            if not pd.api.types.is_numeric_dtype(df_copy[field]):
                try:
                    print(f"{name}å­—æ®µä¸æ˜¯æ•°å€¼ç±»å‹ï¼Œå°è¯•è½¬æ¢...")
                    df_copy[field] = pd.to_numeric(df_copy[field], errors='coerce')
                except Exception as e:
                    print(f"æ— æ³•å°†{name}å­—æ®µè½¬æ¢ä¸ºæ•°å€¼ç±»å‹: {str(e)}")
        
        # å»é™¤ç¼ºå¤±å€¼
        valid_data = df_copy.dropna(subset=[x_field, y_field])
        if len(valid_data) < len(df_copy):
            print(f"è­¦å‘Š: ç§»é™¤äº†{len(df_copy)-len(valid_data)}è¡Œå«ç¼ºå¤±å€¼çš„æ•°æ®")
        
        # ä¸ºæ•£ç‚¹å›¾è¿”å›æ‰€æœ‰æ•°æ®ç‚¹
        return {
            "type": "scatter",
            "datasets": [{
                "label": y_field,
                "data": [{"x": x, "y": y} for x, y in zip(valid_data[x_field].tolist(), valid_data[y_field].tolist())],
                "backgroundColor": 'rgba(54, 162, 235, 0.7)',
                "borderColor": 'rgba(54, 162, 235, 1.0)',
                "borderWidth": 1,
                "pointRadius": 4,
                "pointHoverRadius": 6
            }]
        }
        
    def _handle_distribution_plot(self, df: pd.DataFrame, chart_type: str, x_field: str, y_field: str) -> Dict[str, Any]:
        """å¤„ç†åˆ†å¸ƒå›¾ï¼ˆboxplotã€violinã€histogramï¼‰æ•°æ®"""
        # è·å–å”¯ä¸€çš„xå€¼ä½œä¸ºæ ‡ç­¾
        unique_x = df[x_field].unique()
        labels = [str(x) for x in unique_x]
        
        # ä¸ºæ¯ä¸ªxå€¼åˆ›å»ºå¯¹åº”çš„yå€¼æ•°ç»„
        datasets = []
        for x_val in unique_x:
            y_values = df[df[x_field] == x_val][y_field].tolist()
            datasets.append({
                "label": str(x_val),
                "data": y_values
            })
        
        return {
            "type": chart_type,
            "labels": labels,
            "datasets": datasets
        }
        
    def resolve_chart_data(self, df: pd.DataFrame, config: Dict[str, Any] = None):
        """
        æ ¹æ®é…ç½®ä»DataFrameä¸­æå–æ•°æ®
        
        å‚æ•°:
            df: DataFrameå¯¹è±¡
            config: å›¾è¡¨é…ç½®
            
        è¿”å›:
            å›¾è¡¨æ•°æ®å¯¹è±¡
        """
        if config is None:
            config = {}
            
        try:
            # æå–é…ç½®
            chart_type = config.get("chart_type", "bar")
            x_field = config.get("x_field")
            y_field = config.get("y_field")
            hue_field = config.get("hue_column")
            
            # ä¿®å¤: å®‰å…¨å¤„ç†agg_methodï¼Œç¡®ä¿Noneå€¼ä¸ä¼šå¯¼è‡´é”™è¯¯
            agg_method_raw = config.get("agg_method")
            if agg_method_raw is None:
                # æ ¹æ®å›¾è¡¨ç±»å‹è®¾ç½®é»˜è®¤èšåˆæ–¹æ³•
                if chart_type in ["boxplot", "violin", "histogram", "scatter"]:
                    agg_method = "none"  # è¿™äº›ç±»å‹ä¸éœ€è¦èšåˆ
                else:
                    agg_method = "sum"   # é»˜è®¤ä½¿ç”¨sumä½œä¸ºèšåˆæ–¹æ³•
            else:
                agg_method = str(agg_method_raw).lower()
            
            is_stacked = config.get("is_stacked", False)
            
            # å¤åˆ¶æ•°æ®ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
            df_copy = df.copy()
            
            # å¤„ç†ç‰¹æ®Šå›¾è¡¨ç±»å‹
            if chart_type in ["boxplot", "violin", "histogram", "scatter"]:
                result = self._handle_special_chart_types(df_copy, chart_type, x_field, y_field)
                if result is not None:
                    return result
            
            # å¤„ç†æ´¾ç”Ÿåˆ— - å¦‚æœé…ç½®ä¸­åŒ…å«derived_columns
            if "derived_columns" in config and isinstance(config["derived_columns"], list):
                print("å‘ç°æ´¾ç”Ÿåˆ—å®šä¹‰ï¼Œå‡†å¤‡å¤„ç†...")
                for derived_col in config["derived_columns"]:
                    col_name = derived_col.get("name")
                    source_col = derived_col.get("source_column")
                    derivation_type = derived_col.get("derivation_type", "").lower()
                    parameters = derived_col.get("parameters", {})
                    
                    if not col_name or not source_col:
                        print(f"è­¦å‘Š: æ´¾ç”Ÿåˆ—å®šä¹‰ä¸å®Œæ•´ï¼Œè·³è¿‡: {derived_col}")
                        continue
                    
                    # éªŒè¯æºåˆ—å­˜åœ¨
                    if source_col not in df_copy.columns:
                        print(f"è­¦å‘Š: æºåˆ— '{source_col}' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ´¾ç”Ÿåˆ— '{col_name}'")
                        continue
                    
                    try:
                        # æ ¹æ®ä¸åŒçš„æ´¾ç”Ÿç±»å‹å¤„ç†
                        if derivation_type == "bin":
                            # å¤„ç†åˆ†ç®±æ“ä½œ
                            bins = parameters.get("bins")
                            labels = parameters.get("labels")
                            right = parameters.get("right", True)
                            
                            if isinstance(bins, list) and isinstance(labels, list):
                                print(f"å¯¹åˆ— '{source_col}' è¿›è¡Œåˆ†ç®±æ“ä½œï¼Œåˆ›å»ºæ´¾ç”Ÿåˆ— '{col_name}'")
                                df_copy[col_name] = pd.cut(df_copy[source_col], 
                                                          bins=bins, 
                                                          labels=labels, 
                                                          right=right)
                                print(f"âœ… æˆåŠŸåˆ›å»ºåˆ†ç®±åˆ—: {col_name}")
                            else:
                                print(f"è­¦å‘Š: åˆ†ç®±æ“ä½œç¼ºå°‘å¿…è¦å‚æ•°ï¼Œè·³è¿‡")
                        
                        elif derivation_type == "transform":
                            # å¤„ç†å˜æ¢æ“ä½œ
                            transform_type = parameters.get("type", "").lower()
                            
                            if transform_type == "log":
                                df_copy[col_name] = np.log(df_copy[source_col])
                                print(f"âœ… æˆåŠŸåˆ›å»ºå¯¹æ•°å˜æ¢åˆ—: {col_name}")
                            elif transform_type == "sqrt":
                                df_copy[col_name] = np.sqrt(df_copy[source_col])
                                print(f"âœ… æˆåŠŸåˆ›å»ºå¹³æ–¹æ ¹å˜æ¢åˆ—: {col_name}")
                            elif transform_type == "zscore":
                                df_copy[col_name] = (df_copy[source_col] - df_copy[source_col].mean()) / df_copy[source_col].std()
                                print(f"âœ… æˆåŠŸåˆ›å»ºZåˆ†æ•°æ ‡å‡†åŒ–åˆ—: {col_name}")
                            else:
                                print(f"è­¦å‘Š: ä¸æ”¯æŒçš„å˜æ¢ç±»å‹: {transform_type}")
                        
                        elif derivation_type == "calculate":
                            # å¤„ç†è®¡ç®—æ´¾ç”Ÿåˆ—
                            expression = parameters.get("expression")
                            if expression:
                                # å®‰å…¨åœ°è¯„ä¼°è¡¨è¾¾å¼ (ä»…æ”¯æŒç®€å•çš„æ•°å­¦è¿ç®—)
                                if "df[" in expression:
                                    locals_dict = {"df": df_copy, "np": np}
                                    df_copy[col_name] = eval(expression, {"__builtins__": {}}, locals_dict)
                                    print(f"âœ… æˆåŠŸåˆ›å»ºè®¡ç®—åˆ—: {col_name}")
                                else:
                                    print(f"è­¦å‘Š: è®¡ç®—è¡¨è¾¾å¼æ ¼å¼æ— æ•ˆ: {expression}")
                            else:
                                print(f"è­¦å‘Š: è®¡ç®—æ´¾ç”Ÿåˆ—ç¼ºå°‘è¡¨è¾¾å¼å‚æ•°")
                        else:
                            print(f"è­¦å‘Š: æœªçŸ¥çš„æ´¾ç”Ÿç±»å‹: {derivation_type}")
                    
                    except Exception as e:
                        print(f"åˆ›å»ºæ´¾ç”Ÿåˆ— '{col_name}' æ—¶å‡ºé”™: {str(e)}")
                        import traceback
                        traceback.print_exc()
            
            # éªŒè¯å­—æ®µå­˜åœ¨
            try:
                self._validate_fields(df_copy, config)
            except ValueError as e:
                print(f"è­¦å‘Š: {str(e)}")
            
            # æ ¹æ®å›¾è¡¨ç±»å‹å¤„ç†æ•°æ®
            if chart_type == "pie":
                return self._prepare_pie_data(df_copy, x_field, y_field, agg_method)
            elif hue_field and hue_field in df_copy.columns:
                return self._prepare_grouped_data(df_copy, x_field, y_field, hue_field, agg_method, is_stacked)
            else:
                return self._prepare_single_series_data(df_copy, x_field, y_field, agg_method)
            
        except Exception as e:
            print(f"å¤„ç†æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return []
    
    def _validate_fields(self, df: pd.DataFrame, config: Dict[str, Any]):
        """éªŒè¯å­—æ®µæ˜¯å¦å­˜åœ¨äºDataFrameä¸­"""
        if not isinstance(df, pd.DataFrame):
            print("âš ï¸ è¾“å…¥æ•°æ®ä¸æ˜¯DataFrameç±»å‹")
            return False
            
        required_fields = []
        if config.get("x_field"):
            required_fields.append(config["x_field"])
        if config.get("y_field"):
            required_fields.append(config["y_field"])
        if config.get("hue_column"):
            required_fields.append(config["hue_column"])
            
        missing_fields = [field for field in required_fields if field not in df.columns]
        if missing_fields:
            print(f"âš ï¸ ä»¥ä¸‹å­—æ®µåœ¨DataFrameä¸­ä¸å­˜åœ¨: {missing_fields}")
            return False
            
        return True
    
    def _prepare_pie_data(self, df: pd.DataFrame, x_field: str, y_field: str, agg_method: str):
        """å‡†å¤‡é¥¼å›¾æ•°æ®ï¼ˆG2æ ¼å¼ï¼‰"""
        if not x_field or x_field not in df.columns:
            raise ValueError("é¥¼å›¾éœ€è¦æœ‰æ•ˆçš„ç±»åˆ«å­—æ®µ")
        
        try:
            # å¦‚æœæ˜¯èšåˆæ“ä½œ
            if y_field and y_field in df.columns:
                if agg_method == "count":
                    data = df.groupby(x_field)[y_field].count()
                elif agg_method == "mean":
                    data = df.groupby(x_field)[y_field].mean()
                elif agg_method in [None, "none"]:
                    print("é¥¼å›¾é€šå¸¸éœ€è¦èšåˆï¼Œä½¿ç”¨sumä½œä¸ºé»˜è®¤èšåˆæ–¹æ³•")
                    data = df.groupby(x_field)[y_field].sum()
                else:  # é»˜è®¤ä½¿ç”¨sum
                    data = df.groupby(x_field)[y_field].sum()
            else:
                # å¦‚æœåªæœ‰xå­—æ®µï¼Œä½¿ç”¨è®¡æ•°
                data = df[x_field].value_counts()
            
            # ç›´æ¥è¿”å›G2æ ¼å¼æ•°æ®
            return [
                {"category": str(category), "value": value}
                for category, value in zip(data.index, data.values)
            ]
        except Exception as e:
            print(f"å‡†å¤‡é¥¼å›¾æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›åŸºæœ¬çš„é”™è¯¯æ•°æ®ç»“æ„
            return [
                {"category": "é”™è¯¯", "value": 0},
                {"category": "è¯·æ£€æŸ¥æ•°æ®", "value": 0}
            ]
    
    def _prepare_grouped_data(self, df: pd.DataFrame, x_field: str, y_field: str, hue_field: str, agg_method: str, is_stacked: bool):
        """å‡†å¤‡åˆ†ç»„æ•°æ®ï¼ˆG2æ ¼å¼ï¼‰"""
        if not x_field or x_field not in df.columns:
            raise ValueError(f"Xè½´å­—æ®µ '{x_field}' ä¸å­˜åœ¨")
        if not hue_field or hue_field not in df.columns:
            raise ValueError(f"åˆ†ç»„å­—æ®µ '{hue_field}' ä¸å­˜åœ¨")
        
        try:
            # å…‹éš†æ•°æ®ï¼Œé¿å…ä¿®æ”¹åŸæ•°æ®
            df_copy = df.copy()
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in [x_field, y_field, hue_field]:
                if col and col in df.columns:
                    if df[col].apply(lambda x: isinstance(x, (list, dict, tuple))).any():
                        df_copy[col] = df_copy[col].astype(str)
                    elif df[col].dtype == 'object' or not pd.api.types.is_categorical_dtype(df[col]):
                        df_copy[col] = df_copy[col].astype(str)
            
            # å¤„ç†èšåˆ
            pivot_data = None
            if y_field and y_field in df.columns:
                try:
                    if agg_method == "count":
                        pivot_data = pd.crosstab(df_copy[x_field], df_copy[hue_field])
                    else:
                        pivot_data = pd.pivot_table(
                            df_copy,
                            index=x_field,
                            columns=hue_field,
                            values=y_field,
                            aggfunc=agg_method or 'sum'
                        )
                except Exception as e:
                    print(f"æ•°æ®é€è§†è¡¨å¤„ç†å¤±è´¥: {str(e)}")
                    # ä½¿ç”¨æ›´å®‰å…¨çš„æ–¹æ³•
                    grouped = df_copy.groupby([x_field, hue_field])
                    if agg_method == "count":
                        grouped = grouped.size()
                    else:
                        grouped = grouped[y_field].agg(agg_method or 'sum')
                    pivot_data = grouped.unstack(fill_value=0)
            
            if pivot_data is None:
                pivot_data = pd.crosstab(df_copy[x_field], df_copy[hue_field])
            
            # ç›´æ¥è¿”å›G2æ ¼å¼æ•°æ®
            processed_data = []
            for x_val in pivot_data.index:
                for hue_val in pivot_data.columns:
                    processed_data.append({
                        x_field: str(x_val),
                        y_field: float(pivot_data.loc[x_val, hue_val]),
                        hue_field: str(hue_val)
                    })
            
            return processed_data
        
        except Exception as e:
            print(f"å‡†å¤‡åˆ†ç»„æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›åŸºæœ¬çš„é”™è¯¯æ•°æ®ç»“æ„
            return [
                {x_field: "é”™è¯¯", y_field: 0, hue_field: "è¯·æ£€æŸ¥æ•°æ®"}
            ]
    
    def _prepare_single_series_data(self, df: pd.DataFrame, x_field: str, y_field: str, agg_method: str):
        """å‡†å¤‡å•ç³»åˆ—æ•°æ®ï¼ˆG2æ ¼å¼ï¼‰"""
        if x_field is None or x_field not in df.columns:
            print(f"è­¦å‘Š: Xè½´å­—æ®µ '{x_field}' ä¸å­˜åœ¨æˆ–ä¸ºNoneï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºXè½´")
            temp_df = df.copy()
            temp_df['index_as_x'] = range(len(df))
            df = temp_df
            x_field = 'index_as_x'
        
        try:
            df_copy = df.copy()
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            for col in [x_field, y_field]:
                if col and col in df.columns:
                    if df[col].dtype == 'object':
                        df_copy[col] = df_copy[col].astype(str)
            
            # å¤„ç†èšåˆ
            grouped = None
            if y_field and y_field in df.columns:
                if agg_method == "mean":
                    grouped = df_copy.groupby(x_field)[y_field].mean()
                elif agg_method == "count":
                    grouped = df_copy.groupby(x_field)[y_field].count()
                elif agg_method == "sum":
                    grouped = df_copy.groupby(x_field)[y_field].sum()
                elif agg_method in [None, "none"]:
                    print("ä¸ä½¿ç”¨èšåˆæ–¹æ³•ï¼Œç›´æ¥ä½¿ç”¨åŸå§‹æ•°æ®")
                    grouped = df_copy.groupby(x_field)[y_field].mean()
                else:
                    grouped = df_copy.groupby(x_field)[y_field].sum()
            
            if grouped is None:
                print(f"è­¦å‘Š: Yè½´å­—æ®µ '{y_field}' ä¸å­˜åœ¨æˆ–ä¸ºNoneï¼Œä½¿ç”¨è®¡æ•°ä½œä¸ºYè½´")
                grouped = df_copy[x_field].value_counts().sort_index()
            
            # ç›´æ¥è¿”å›G2æ ¼å¼æ•°æ®
            return [
                {x_field: str(x), y_field: float(y)}
                for x, y in zip(grouped.index, grouped.values)
            ]
        
        except Exception as e:
            print(f"å‡†å¤‡å•ç³»åˆ—æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # è¿”å›åŸºæœ¬çš„é”™è¯¯æ•°æ®ç»“æ„
            return [
                {x_field: "é”™è¯¯", y_field: 0},
                {x_field: "è¯·æ£€æŸ¥æ•°æ®", y_field: 0}
            ]
    
    def convert_to_antv_config(self, config: Dict[str, Any], chart_data=None) -> Dict[str, Any]:
        """
        å°†æå–çš„é…ç½®è½¬æ¢ä¸ºAntV G2é…ç½®
        
        å‚æ•°:
            config: æå–çš„å›¾è¡¨é…ç½®
            chart_data: G2æ ¼å¼çš„å›¾è¡¨æ•°æ®
            
        è¿”å›:
            AntV G2é…ç½®å¯¹è±¡
        """
        chart_type = config.get("chart_type", "bar")
        title = config.get("title", "")
        x_field = config.get("x_field", "")
        y_field = config.get("y_field", "")
        hue_field = config.get("hue_column")
        is_stacked = config.get("is_stacked", False)
        
        # é¢œè‰²é…ç½®
        colors = [
            '#FF6384',  # çº¢è‰²
            '#36A2EB',  # è“è‰²
            '#FFCE56',  # é»„è‰²
            '#4BC0C0',  # ç»¿è‰²
            '#9966FF',  # ç´«è‰²
            '#FF9F40',  # æ©™è‰²
            '#C7C7C7'   # ç°è‰²
        ]
        
        # æ˜ å°„å›¾è¡¨ç±»å‹åˆ°G2ç±»å‹
        type_map = {
            "bar": "interval",
            "line": "line",
            "scatter": "point",
            "pie": "pie",
            "boxplot": "box",
            "histogram": "histogram",
            "heatmap": "heatmap"
        }
        g2_type = type_map.get(chart_type, "interval")
        
        # æ„å»ºåŸºç¡€G2é…ç½®
        g2_config = {
            "type": g2_type,
            "data": chart_data or [],
            "title": title,
            "autoFit": True,
            "animation": True
        }
        
        # æ ¹æ®å›¾è¡¨ç±»å‹æ·»åŠ ç‰¹å®šé…ç½®
        if chart_type == "pie":
            g2_config.update({
                "angleField": "value",
                "colorField": "category",
                "radius": 0.8,
                "label": {
                    "type": "outer",
                    "content": "{name}: {percentage}"
                },
                "color": colors
            })
        elif chart_type == "scatter":
            g2_config.update({
                "xField": x_field,
                "yField": y_field,
                "shape": "circle",
                "pointStyle": {
                    "fillOpacity": 0.7,
                    "stroke": "#ffffff",
                    "lineWidth": 0.5
                },
                "tooltip": {
                    "showMarkers": False
                },
                "state": {
                    "active": {
                        "style": {
                            "shadowBlur": 4,
                            "stroke": "#000",
                            "fill": "red"
                        }
                    }
                }
            })
        else:
            # éé¥¼å›¾é€šç”¨é…ç½®
            g2_config.update({
                "xField": x_field,
                "yField": y_field
            })
            
            # æ·»åŠ åˆ†ç»„å­—æ®µ
            if hue_field:
                g2_config["seriesField"] = hue_field
                g2_config["color"] = colors
            else:
                g2_config["color"] = colors[0]
            
            # å †å é…ç½®
            if is_stacked and chart_type == "bar":
                g2_config["isStack"] = True
            
            # å›¾è¡¨æ ·å¼é…ç½®
            if chart_type == "bar" or chart_type == "column":
                g2_config["columnStyle"] = {
                    "fillOpacity": 0.7,
                    "lineWidth": 1
                }
            
            if chart_type == "line":
                g2_config["lineStyle"] = {
                    "lineWidth": 2
                }
                g2_config["point"] = {
                    "size": 5,
                    "shape": 'circle',
                    "style": {
                        "lineWidth": 1
                    }
                }
        
        # æ·»åŠ å›¾ä¾‹é…ç½®
        g2_config["legend"] = {
            "position": "right"
        }
        
        # æ·»åŠ å·¥å…·æç¤ºé…ç½®
        g2_config["tooltip"] = {
            "showMarkers": True,
            "showCrosshairs": chart_type == "line",
            "shared": True
        }
        
        # æ·»åŠ äº¤äº’é…ç½®
        g2_config["interactions"] = [
            {"type": "element-active"},
            {"type": "legend-active"},
            {"type": "legend-filter"}
        ]
        
        return g2_config