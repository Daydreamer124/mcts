import copy
import json
import re,os,traceback
from typing import Dict, List, Any, Optional
from storyteller.algorithm.utils.DatasetContextGenerator import DatasetContextGenerator  # å¼•å…¥æ•°æ®é›†è§£æå™¨
from storyteller.algorithm.mcts_node import *
from storyteller.llm_call.openai_llm import call_openai
from storyteller.llm_call.prompt_factory import get_prompt
from typing import List, Dict, Any
import pandas as pd
from enum import Enum
import base64
from PIL import Image
import io,requests
from openai import OpenAI
from .utils.html2image import convert_html_file_to_image
from storyteller.algorithm.mcts_node import ReportGenerationState
from llmx import llm, TextGenerator
from lida.components.manager import Manager
from storyteller.algorithm.utils.universalsc import run_universal_self_consistency  # å¯¼å…¥universalscåŠŸèƒ½
from storyteller.algorithm.utils.unified_framework import unified_generation_framework  # å¯¼å…¥ç»Ÿä¸€æ¡†æ¶
import time
from tqdm import tqdm
import glob




class DataStorytellingAction:
    def __init__(self, action_id: str, description: str):
        self.action_id = action_id
        self.description = description# é»˜è®¤çš„ä¸‹ä¸€ä¸ªçŠ¶æ€
        
        # æ·»åŠ  MCTS ç»Ÿè®¡å±æ€§
        #self.Q = 0.0  # ç´¯ç§¯å¥–åŠ±
        #self.N = 0    # è®¿é—®æ¬¡æ•°
  

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
        
            raise NotImplementedError
        
    
class Query2Chapters(DataStorytellingAction):
    def __init__(self):
        super().__init__("A1", "å®šä¹‰ç« èŠ‚ç»“æ„") 
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶

    def generate_chapter_prompt(self, node, **kwargs):
        """ç”Ÿæˆç« èŠ‚æç¤ºè¯"""
        query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
        data_context = node.report.data_context
        
        # ä½¿ç”¨é¢„è®¾çš„æç¤ºæ¨¡æ¿
        prompt_args = {
            "QUERY": query,
            "DATA_CONTEXT": data_context
        }
        
        return get_prompt("Query2Chapters", prompt_args)
    
    def apply_chapters(self, node, action, cluster, **kwargs):
        """å°†ç« èŠ‚åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            chapters = cluster.get("chapters", [])
            
            if not chapters:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“˜ ä¸ºèšç±» {cluster_id} åº”ç”¨ç« èŠ‚æ–¹æ¡ˆ")
            print(f"   ç« èŠ‚ç»“æ„: {chapters}")
            
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # æ¸…ç©ºç°æœ‰ç« èŠ‚
            child_node.report.chapters = []
            
            # æ·»åŠ ç« èŠ‚
            for title in chapters:
                child_node.report.add_chapter(Chapter(title=title))
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.a1
            
            print(f"âœ… æˆåŠŸæ·»åŠ èšç±» {cluster_id} çš„ç« èŠ‚æ–¹æ¡ˆ")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨ç« èŠ‚æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """
        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢å’Œæ•°æ®ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ç»Ÿä¸€æ¡†æ¶ç”Ÿæˆå¤šæ ·åŒ–ç« èŠ‚ç»“æ„
        """
        if self.use_unified_framework:
            return unified_generation_framework(
                node=node,
                action=self,
                llm_kwargs=llm_kwargs,
                action_type="chapters",
                prompt_generator=self.generate_chapter_prompt,
                node_applier=self.apply_chapters,
                n=4
            )
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹æ³•çš„å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            # ä½¿ç”¨ clarified_queryï¼ˆå¦‚æœæœ‰ï¼‰æˆ–åŸå§‹æŸ¥è¯¢
            query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
            data_context = node.report.data_context
            print(data_context)
            # è¿è¡ŒUSCæµç¨‹è·å–èšç±»ç»“æœ
            clusters = run_universal_self_consistency(query, data_context, llm_kwargs, n=4)
            print(f"âœ… å®Œæˆç« èŠ‚èšç±»ï¼Œå¾—åˆ° {len(clusters)} ä¸ªèšç±»")
            
            # ä»æ¯ä¸ªèšç±»ä¸­åˆ›å»ºå­èŠ‚ç‚¹
            nodes = []
            for cluster in clusters:
                cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
                chapters = cluster.get("chapters", [])
                
                # è·³è¿‡æ²¡æœ‰ç« èŠ‚çš„èšç±»
                if not chapters:
                    print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡")
                    continue
        
                print(f"ğŸ“˜ ä¸ºèšç±» {cluster_id} åˆ›å»ºå­èŠ‚ç‚¹")
                print(f"   ç« èŠ‚ç»“æ„: {chapters}")
                
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # æ¸…ç©ºç°æœ‰ç« èŠ‚
                child_node.report.chapters = []
                
                # æ·»åŠ ç« èŠ‚
                for title in chapters:
                        child_node.report.add_chapter(Chapter(title=title))
                
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.a1
                
                # æ·»åŠ åˆ°èŠ‚ç‚¹åˆ—è¡¨
                nodes.append(child_node)
                print(f"âœ… æˆåŠŸæ·»åŠ èšç±» {cluster_id} çš„ç« èŠ‚æ–¹æ¡ˆ")
        
        return nodes



class Chapters2Tasks(DataStorytellingAction):
    def __init__(self):
        super().__init__("A2", "æ ¹æ®ç« èŠ‚æ–¹æ¡ˆåˆ’åˆ†ç« èŠ‚ä»»åŠ¡æ–¹æ¡ˆ")
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶

    def generate_tasks_prompt(self, node, **kwargs):
        """ç”Ÿæˆä»»åŠ¡æç¤ºè¯"""
        # è·å–æ•°æ®é›†ä¿¡æ¯
        data_context = node.report.data_context
        query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
        
        # æ„å»ºç« èŠ‚åˆ—è¡¨
        chapters_list = []
        for i, chapter in enumerate(node.report.chapters):
            # å®‰å…¨è·å–æ ‡é¢˜
            if isinstance(chapter, dict):
                # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                if 'title' in chapter:
                    # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                    if isinstance(chapter['title'], dict):
                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                        title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                    else:
                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                        title_text = chapter['title']
                else:
                    # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    title_text = f"ç« èŠ‚{i+1}"
            else:
                # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                title_attr = getattr(chapter, 'title', None)
                if isinstance(title_attr, dict):
                    # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                    title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                else:
                    # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                    title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
            
            chapters_list.append(title_text)
        
        # ç”Ÿæˆ LLM æç¤ºè¯
        prompt_args = {
            "QUERY": query,
            "DATA_CONTEXT": data_context,
            "CHAPTERS": json.dumps(chapters_list, ensure_ascii=False)
        }
        
        return get_prompt("Chapters2Tasks", prompt_args)
    
    def apply_tasks(self, node, action, cluster, **kwargs):
        """å°†ä»»åŠ¡åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–èšç±»ä¸­çš„ç« èŠ‚ä»»åŠ¡
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            chapters_info = cluster.get("chapters", [])
            
            if not chapters_info:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ä»»åŠ¡å†…å®¹ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“‹ ä¸ºèšç±» {cluster_id} åº”ç”¨ä»»åŠ¡æ–¹æ¡ˆ")
            
            # åˆ›å»ºç« èŠ‚æ ‡é¢˜åˆ°ç´¢å¼•çš„æ˜ å°„
            chapter_title_to_index = {}
            for i, chapter in enumerate(child_node.report.chapters):
                # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                if isinstance(chapter, dict):
                    # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                    if 'title' in chapter:
                        # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                        if isinstance(chapter['title'], dict):
                            # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                            title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                        else:
                            # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                            title_text = chapter['title']
                    else:
                        # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        title_text = f"ç« èŠ‚{i+1}"
                else:
                    # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                    title_attr = getattr(chapter, 'title', None)
                    if isinstance(title_attr, dict):
                        # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                        title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                    else:
                        # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                        title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                
                # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                if not isinstance(title_text, str):
                    title_text = str(title_text)
                    
                # å­˜å‚¨å°å†™æ ‡é¢˜æ–‡æœ¬åˆ°ç´¢å¼•çš„æ˜ å°„
                chapter_title_to_index[title_text.lower()] = i
            
            # è·Ÿè¸ªå“ªäº›ç« èŠ‚å·²ç»åˆ†é…äº†ä»»åŠ¡
            chapters_with_tasks = set()
            
            # å¤„ç†æ¯ä¸ªç« èŠ‚
            for chapter_info in chapters_info:
                raw_title = chapter_info.get("title", "")
                
                # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                if isinstance(raw_title, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬
                    title_text = raw_title.get('title', '') or raw_title.get('text', '')
                else:
                    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                    title_text = raw_title
                
                # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                if not isinstance(title_text, str):
                    title_text = str(title_text) if title_text is not None else ""
                    
                tasks = chapter_info.get("tasks", [])
                
                # æŸ¥æ‰¾åŒ¹é…çš„ç« èŠ‚
                chapter_idx = -1
                title_lower = title_text.lower()  # ç°åœ¨å¯ä»¥å®‰å…¨è°ƒç”¨lower()
                
                # ç²¾ç¡®åŒ¹é…
                if title_lower in chapter_title_to_index:
                    chapter_idx = chapter_title_to_index[title_lower]
                else:
                    # æ¨¡ç³ŠåŒ¹é…
                    for i, chapter in enumerate(child_node.report.chapters):
                        # å®‰å…¨è·å–ç« èŠ‚æ ‡é¢˜
                        if isinstance(chapter, dict):
                            if 'title' in chapter:
                                if isinstance(chapter['title'], dict):
                                    search_title = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                else:
                                    search_title = chapter['title']
                            else:
                                search_title = f"ç« èŠ‚{i+1}"
                        else:
                            title_attr = getattr(chapter, 'title', None)
                            if isinstance(title_attr, dict):
                                search_title = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                            else:
                                search_title = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                        
                        # ç¡®ä¿search_titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                        if not isinstance(search_title, str):
                            search_title = str(search_title)
                            
                        search_title_lower = search_title.lower()
                        if title_lower in search_title_lower or search_title_lower in title_lower:
                            chapter_idx = i
                            break
                
                if chapter_idx >= 0 and chapter_idx < len(child_node.report.chapters):
                    chapter = child_node.report.chapters[chapter_idx]
                    
                    # æ¸…ç©ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
                    chapter.visualization_tasks = []
                    
                    # æ·»åŠ ä»»åŠ¡
                    for task in tasks:
                        task_id = task.get("task_id", "")
                        description = task.get("task_description", "")
                        chart_type = task.get("chart_type", ["Bar Chart"])
                        
                        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                        task_obj = {
                            "task_id": task_id,
                            "task_description": description,
                            "chart_type": chart_type,
                            "status": "pending",  # æ·»åŠ çŠ¶æ€å­—æ®µ
                            "visualization_success": False  # æ·»åŠ å¯è§†åŒ–æˆåŠŸæ ‡å¿—
                        }
                        
                        # æ·»åŠ åˆ°ç« èŠ‚çš„ä»»åŠ¡åˆ—è¡¨
                        if not hasattr(chapter, 'visualization_tasks'):
                            chapter.visualization_tasks = []
                        chapter.visualization_tasks.append(task_obj)
                        
                        # æ‰“å°ä»»åŠ¡çŠ¶æ€
                        print(f"   - ä»»åŠ¡ID: '{task_id}'")
                        print(f"   - ä»»åŠ¡æè¿°: '{description}'")
                        print(f"   - å›¾è¡¨ç±»å‹: {chart_type}")
                        print(f"   - çŠ¶æ€: {task_obj.get('status')}")
                    
                    # è®°å½•å·²åˆ†é…ä»»åŠ¡çš„ç« èŠ‚
                    chapters_with_tasks.add(chapter_idx)
                    
                    # æ‰“å°è°ƒè¯•ä¿¡æ¯
                    print(f"âœ… ä¸ºç« èŠ‚ {chapter_idx+1} ({chapter.title}) ç”Ÿæˆäº† {len(tasks)} ä¸ªå¯è§†åŒ–ä»»åŠ¡")
                else:
                    print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é…çš„ç« èŠ‚: {title_text}")
            
            # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚æ˜¯å¦éƒ½æœ‰ä»»åŠ¡
            all_chapters_have_tasks = True
            for i, chapter in enumerate(child_node.report.chapters):
                if i not in chapters_with_tasks:
                    print(f"âš ï¸ ç« èŠ‚ {i+1} ({chapter.title}) æ²¡æœ‰ä»»åŠ¡")
                    all_chapters_have_tasks = False
            
            # åªæœ‰å½“æ‰€æœ‰ç« èŠ‚éƒ½æœ‰ä»»åŠ¡æ—¶ï¼Œæ‰è¿”å›è¿™ä¸ªèŠ‚ç‚¹
            if all_chapters_have_tasks:
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.a2
                print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„ä»»åŠ¡æ–¹æ¡ˆ")
                return [child_node]
            else:
                print(f"âš ï¸ èšç±» {cluster_id} çš„ä»»åŠ¡æ–¹æ¡ˆä¸å®Œæ•´ï¼Œè·³è¿‡")
                return None
                
        except Exception as e:
            print(f"âŒ åº”ç”¨ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šç§ä»»åŠ¡æ–¹æ¡ˆ"""
        if self.use_unified_framework:
            return unified_generation_framework(
                node=node,
                action=self,
                llm_kwargs=llm_kwargs,
                action_type="tasks",
                prompt_generator=self.generate_tasks_prompt,
                node_applier=self.apply_tasks,
                n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“
            )
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹æ³•çš„å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            children_nodes = []
        
        try:
            # è·å–æ•°æ®é›†ä¿¡æ¯
            data_context = node.report.data_context
            
            # ä¸ºæ¯ä¸ªç« èŠ‚æ–¹æ¡ˆåˆ›å»º2-3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå­èŠ‚ç‚¹
            # åˆ›å»ºåŸºç¡€èŠ‚ç‚¹çš„å¤šä¸ªå‰¯æœ¬
            for variant_idx in range(3):  # ç”Ÿæˆ3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # ç”Ÿæˆ LLM æç¤ºè¯
                prompt_text = get_prompt("Chapters2Tasks", {
                    "QUERY": node.original_query,
                    "DATA_CONTEXT": data_context,
                    "CHAPTERS": json.dumps([{
                        "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{i+1}")
                    } for i, chapter in enumerate(child_node.report.chapters)], ensure_ascii=False)
                })
                
                # ä½¿ç”¨ä¸åŒçš„æ¸©åº¦ï¼Œä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„ä»»åŠ¡æ–¹æ¡ˆ
                llm_kwargs_temp = llm_kwargs.copy()
                llm_kwargs_temp['temperature'] = 0.3 + variant_idx * 0.25  # 0.3, 0.55, 0.8
                
                print(f"\nğŸ”„ ç”Ÿæˆä»»åŠ¡æ–¹æ¡ˆå˜ä½“ {variant_idx+1}/3 (æ¸©åº¦: {llm_kwargs_temp['temperature']})")
                
                responses = call_openai(prompt_text, **llm_kwargs_temp)
                if not responses:
                    print(f"âŒ å˜ä½“ {variant_idx+1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                    continue
                
                response_text = responses[0]
                
                try:
                    # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå– JSON éƒ¨åˆ†
                    json_text = self.extract_json_from_text(response_text)
                    print(f"åŸå§‹å“åº”: {json_text}")
                    
                    # è§£æ JSON
                    response_json = json.loads(json_text)
                    
                    # å¤„ç†æ¯ä¸ªç« èŠ‚çš„å¯è§†åŒ–ä»»åŠ¡
                    if "chapters" in response_json:
                        # åˆ›å»ºç« èŠ‚æ ‡é¢˜åˆ°ç´¢å¼•çš„æ˜ å°„
                        chapter_title_to_index = {}
                        for i, chapter in enumerate(child_node.report.chapters):
                            # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                            if isinstance(chapter, dict):
                                # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                                if 'title' in chapter:
                                    # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                                    if isinstance(chapter['title'], dict):
                                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                                        title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                    else:
                                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                                        title_text = chapter['title']
                                else:
                                    # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                    title_text = f"ç« èŠ‚{i+1}"
                            else:
                                # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                                title_attr = getattr(chapter, 'title', None)
                                if isinstance(title_attr, dict):
                                    # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                                    title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                                else:
                                    # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                                    title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                            
                            # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if not isinstance(title_text, str):
                                title_text = str(title_text)
                                
                            # å­˜å‚¨å°å†™æ ‡é¢˜æ–‡æœ¬åˆ°ç´¢å¼•çš„æ˜ å°„
                            chapter_title_to_index[title_text.lower()] = i
                        
                        # å¤„ç†æ¯ä¸ªç« èŠ‚
                        for chapter_info in response_json["chapters"]:
                            raw_title = chapter_info.get("title", "")
                            # è°ƒè¯•æ‰“å°
                            #print(f"DEBUG - è·å–åˆ°çš„ title ç±»å‹: {type(raw_title)}")
                            #print(f"DEBUG - title å†…å®¹: {raw_title}")
                            
                            # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                            if isinstance(raw_title, dict):
                                # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬
                                title_text = raw_title.get('title', '') or raw_title.get('text', '')
                            else:
                                # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                                title_text = raw_title
                            
                            # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if not isinstance(title_text, str):
                                title_text = str(title_text) if title_text is not None else ""
                                
                            tasks = chapter_info.get("tasks", [])
                            
                            # æŸ¥æ‰¾åŒ¹é…çš„ç« èŠ‚
                            chapter_idx = -1
                            title_lower = title_text.lower()  # ç°åœ¨å¯ä»¥å®‰å…¨è°ƒç”¨lower()
                            
                            # ç²¾ç¡®åŒ¹é…
                            if title_lower in chapter_title_to_index:
                                chapter_idx = chapter_title_to_index[title_lower]
                            else:
                                # æ¨¡ç³ŠåŒ¹é…
                                for i, chapter in enumerate(child_node.report.chapters):
                                    # å®‰å…¨è·å–ç« èŠ‚æ ‡é¢˜
                                    if isinstance(chapter, dict):
                                        if 'title' in chapter:
                                            if isinstance(chapter['title'], dict):
                                                search_title = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                            else:
                                                search_title = chapter['title']
                                        else:
                                            search_title = f"ç« èŠ‚{i+1}"
                                    else:
                                        title_attr = getattr(chapter, 'title', None)
                                        if isinstance(title_attr, dict):
                                            search_title = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                                        else:
                                            search_title = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                                    
                                    # ç¡®ä¿search_titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                                    if not isinstance(search_title, str):
                                        search_title = str(search_title)
                                        
                                    search_title_lower = search_title.lower()
                                    if title_lower in search_title_lower or search_title_lower in title_lower:
                                        chapter_idx = i
                                        break
                            
                            if chapter_idx >= 0 and chapter_idx < len(child_node.report.chapters):
                                chapter = child_node.report.chapters[chapter_idx]
                                
                                # æ¸…ç©ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
                                chapter.visualization_tasks = []
                                
                                # æ·»åŠ ä»»åŠ¡
                                for task in tasks:
                                    task_id = task.get("task_id", "")
                                    description = task.get("task_description", "")
                                    chart_type = task.get("chart_type", ["Bar Chart"])
                                    
                                    # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                                    task_obj = {
                                        "task_id": task_id,
                                        "task_description": description,
                                        "chart_type": chart_type,
                                        "status": "pending",  # æ·»åŠ çŠ¶æ€å­—æ®µ
                                        "visualization_success": False  # æ·»åŠ å¯è§†åŒ–æˆåŠŸæ ‡å¿—
                                    }
                                    
                                    # æ·»åŠ åˆ°ç« èŠ‚çš„ä»»åŠ¡åˆ—è¡¨
                                    if not hasattr(chapter, 'visualization_tasks'):
                                        chapter.visualization_tasks = []
                                    chapter.visualization_tasks.append(task_obj)
                                    
                                    # æ‰“å°ä»»åŠ¡çŠ¶æ€
                                    print(f"   - ä»»åŠ¡ID: '{task_id}'")
                                    print(f"   - ä»»åŠ¡æè¿°: '{description}'")
                                    print(f"   - å›¾è¡¨ç±»å‹: {chart_type}")
                                    print(f"   - çŠ¶æ€: {task_obj.get('status')}")
                                
                                # æ‰“å°è°ƒè¯•ä¿¡æ¯
                                print(f"âœ… å˜ä½“ {variant_idx+1} - ç« èŠ‚ {chapter_idx+1} ({chapter.title}) ç”Ÿæˆäº† {len(tasks)} ä¸ªå¯è§†åŒ–ä»»åŠ¡")
                                print(f"å½“å‰ç« èŠ‚ä»»åŠ¡åˆ—è¡¨: {[t.get('task_id') for t in chapter.visualization_tasks]}")
                            else:
                                print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é…çš„ç« èŠ‚: {title_text}")
                        
                        # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚æ˜¯å¦éƒ½æœ‰ä»»åŠ¡
                        all_chapters_have_tasks = True
                        for i, chapter in enumerate(child_node.report.chapters):
                            if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                                print(f"âš ï¸ å˜ä½“ {variant_idx+1} - ç« èŠ‚ {i+1} ({chapter.title}) æ²¡æœ‰ä»»åŠ¡")
                                all_chapters_have_tasks = False
                            else:
                                print(f"âœ“ å˜ä½“ {variant_idx+1} - ç« èŠ‚ {i+1} ({chapter.title}) æœ‰ {len(chapter.visualization_tasks)} ä¸ªä»»åŠ¡")
                        
                        # åªæœ‰å½“æ‰€æœ‰ç« èŠ‚éƒ½æœ‰ä»»åŠ¡æ—¶ï¼Œæ‰æ·»åŠ è¿™ä¸ªå˜ä½“
                        if all_chapters_have_tasks:
                            children_nodes.append(child_node)
                            print(f"âœ… ä»»åŠ¡æ–¹æ¡ˆå˜ä½“ {variant_idx+1} å·²æ·»åŠ åˆ°å€™é€‰åˆ—è¡¨")
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON è§£æé”™è¯¯: {str(e)}")
                    print(f"âš ï¸ å˜ä½“ {variant_idx+1} æ— æ³•è§£æ JSONï¼Œè·³è¿‡")
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„æ–¹æ¡ˆï¼Œè¿”å›åŸå§‹èŠ‚ç‚¹çš„å‰¯æœ¬
            if not children_nodes:
                print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„ä»»åŠ¡æ–¹æ¡ˆï¼Œè¿”å›åŸå§‹èŠ‚ç‚¹")
                fallback_node = copy.deepcopy(node)
                fallback_node.parent_node = node
                fallback_node.parent_action = self
                fallback_node.depth = node.depth + 1
                children_nodes.append(fallback_node)
            
            print(f"ğŸ”¢ æ€»å…±ç”Ÿæˆäº† {len(children_nodes)} ä¸ªæœ‰æ•ˆçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¯è§†åŒ–ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            # ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿè¿”å›è‡³å°‘ä¸€ä¸ªå­èŠ‚ç‚¹
            if not children_nodes:
                fallback_node = copy.deepcopy(node)
                fallback_node.parent_node = node
                fallback_node.parent_action = self
                fallback_node.depth = node.depth + 1
                children_nodes.append(fallback_node)
        
        # ä¸ºæ‰€æœ‰ç”Ÿæˆçš„èŠ‚ç‚¹è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
        for child_node in children_nodes:
            child_node.node_type = ReportGenerationState.a2
        
        return children_nodes

    def extract_json_from_text(self, response_text):
        """ä»æ–‡æœ¬ä¸­æå– JSON éƒ¨åˆ†"""
        try:
            # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            json.loads(response_text)
            return response_text
        except:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå– JSON éƒ¨åˆ†
            import re
            
            # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
            response_text = re.sub(r'^```(?:json)?\s*', '', response_text)
            response_text = re.sub(r'\s*```$', '', response_text)
            
            # æŸ¥æ‰¾ JSON å¯¹è±¡
            json_pattern = r'\{.*\}'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            
            if json_match:
                return json_match.group(0)
            
            return response_text



class Tasks2Charts(DataStorytellingAction):
    def __init__(self):
        super().__init__("A3", "ç”Ÿæˆå¯è§†åŒ–")
        # åˆå§‹åŒ–å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·
        try:
            from storyteller.algorithm.utils.ChartSimilarity import ChartSimilarity
            self.similarity_tool = ChartSimilarity()
            self.similarity_threshold = 0.90  # ç›¸ä¼¼åº¦é˜ˆå€¼
            self.use_similarity_check = self.similarity_tool.initialized
            print("âœ… å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.use_similarity_check = False
            
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = self
        child_node.depth = node.depth + 1

        try:
            # é€’å¢è¿­ä»£å· - ç¡®ä¿æ¯æ¬¡åˆ›å»ºæ–°èŠ‚ç‚¹æ—¶è¿­ä»£å·åŠ 1
            #child_node.report.current_iteration += 1
            current_iteration = child_node.report.current_iteration
            print(f"âœ… å½“å‰è¿­ä»£å·: {current_iteration}")
            
            # ç¡®å®šå½“å‰è¿­ä»£å·å’Œä¿å­˜è·¯å¾„
            iteration_dir = os.path.join("storyteller", "output", "iterations", f"iteration_{current_iteration}")
            os.makedirs(iteration_dir, exist_ok=True)
            charts_dir = os.path.join(iteration_dir, "charts")
            os.makedirs(charts_dir, exist_ok=True)
           
            # åˆ›å»ºä¸€ä¸ªé¢å¤–çš„ JSON é…ç½®ç›®å½•
            json_dir = os.path.join(iteration_dir, "chart_configs")
            os.makedirs(json_dir, exist_ok=True)
             
            # è·å–æ•°æ®é›†
            dataset_path = node.report.dataset_path
            df = pd.read_csv(dataset_path)

            # éå†æ‰€æœ‰ç« èŠ‚
            for chapter_idx, chapter in enumerate(child_node.report.chapters):
                print(f"\nğŸ“Š æ­£åœ¨å¤„ç†ç¬¬ {chapter_idx + 1} ç« ...")
                print(f"ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
                print(f"ç« èŠ‚çš„å¯è§†åŒ–ä»»åŠ¡æ•°é‡: {len(getattr(chapter, 'visualization_tasks', []))}")
                
                # åˆå§‹åŒ–ç« èŠ‚å›¾è¡¨åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if not hasattr(chapter, 'charts'):
                    chapter.charts = []
                
                # æ”¶é›†æ‰€æœ‰ç« èŠ‚çš„å›¾è¡¨ç”¨äºç›¸ä¼¼åº¦æ£€æŸ¥
                all_charts = []
                for ch in child_node.report.chapters:
                    if hasattr(ch, 'charts'):
                        all_charts.extend(ch.charts)
                
                # éå†ç« èŠ‚ä¸­çš„æ‰€æœ‰å¯è§†åŒ–ä»»åŠ¡
                for task in chapter.visualization_tasks:
                    print(f"\nğŸ” å¤„ç†ä»»åŠ¡:")
                    print(f"- ä»»åŠ¡ID: {task.get('task_id', '')}")
                    print(f"- ä»»åŠ¡æè¿°: {task.get('task_description', '')}")
                    print(f"- å›¾è¡¨ç±»å‹: {task.get('chart_type', ['Bar Chart'])[0]}")
                    
                    task_id = task.get('task_id', "")
                    description = task.get('task_description')
                    chart_type = task.get('chart_type', ["Bar Chart"])[0]

                    # ä½¿ç”¨ä»»åŠ¡IDä½œä¸ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ä»»åŠ¡æè¿°
                    file_name = task_id if task_id else description
                    if not file_name:
                        file_name = f"chart_{chapter_idx}_{len(chapter.charts)}"
                    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                    file_name = re.sub(r'[<>:"/\\|?*]', '_', file_name)
                    chart_path = os.path.join(charts_dir, f"{file_name}.png")

                    
                    from lida.datamodel import Goal, Summary
                    from lida.components.manager import Manager
                    # åˆ›å»º Goal å¯¹è±¡ - ä½¿ç”¨ description æ›¿ä»£ task_name
                    #goal = Goal(question=task_id, visualization=chart_type, rationale=description) !!åŸå…ˆæ˜¯è¿™ä¸ª
                    goal = Goal(question=task_id, visualization=description, rationale=description)
                    # åˆ›å»º Summary å¯¹è±¡
                    # è¯»å–æ•°æ®æ‘˜è¦ JSON æ–‡ä»¶
                    data_summary = {}
                    json_path = os.path.join("storyteller", "dataset", "data_context.json")
                    print(f"å°è¯•è¯»å–æ•°æ®æ‘˜è¦ JSON: {json_path}")
                    
                    try:
                        with open(json_path, 'r', encoding='utf-8') as f:
                            data_summary = json.load(f)
                        print("âœ“ æˆåŠŸè¯»å–æ•°æ®æ‘˜è¦ JSON")
                    except Exception as e:
                        print(f"âœ— è¯»å–æ•°æ®æ‘˜è¦ JSON å¤±è´¥: {str(e)}")
                        # å¦‚æœæ— æ³•è¯»å– JSON æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        data_summary = {
                            "name": node.report.original_query,
                            "dataset_description": node.report.data_context,
                            "fields_info": {col: {"dtype": str(dtype)} for col, dtype in zip(df.columns, df.dtypes)}
                        }

                    # åˆ›å»º Summary å¯¹è±¡ï¼Œä½¿ç”¨ä» JSON æ–‡ä»¶ä¸­æå–çš„ä¿¡æ¯
                    summary = Summary(
                        name=data_summary.get("name", "è´­ç‰©æ•°æ®åˆ†æ"),
                        file_name=dataset_path,
                        dataset_description=str(data_summary.get("dataset_description", "è´­ç‰©æ•°æ®é›†")),
                        field_names=list(data_summary.get("fields_info", {}).keys()) if "fields_info" in data_summary else df.columns.tolist(),
                        fields=[info.get("dtype", "unknown") for info in data_summary.get("fields_info", {}).values()] if "fields_info" in data_summary else [str(dtype) for dtype in df.dtypes.tolist()]
                    )
                    
                    # åˆ›å»ºè‡ªå®šä¹‰çš„æ–‡æœ¬ç”Ÿæˆå™¨
                    #text_gen = llm(provider="openai", model="gpt-4-32k")
                    text_gen = llm(
                        provider="openai", 
                        model="gpt-4o"
                    )

                    # åˆ›å»º LIDA ç®¡ç†å™¨
                    manager = Manager(text_gen=text_gen)

                    # ç”Ÿæˆå¯è§†åŒ–
                    print(f"æ­£åœ¨ä¸ºä»»åŠ¡ '{description}' ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                    visualization = manager.visualize(summary, goal, library="matplotlib")

                    # å¤„ç†å¯è§†åŒ–ç»“æœ
                    if isinstance(visualization, list) and len(visualization) > 0:
                        visualization = visualization[0]

                    if hasattr(visualization, 'status') and visualization.status:
                        print("âœ“ æˆåŠŸç”Ÿæˆå¯è§†åŒ–ç»“æœ")

                        # ä¿å­˜å›¾è¡¨
                        if hasattr(visualization, 'savefig'):
                            visualization.savefig(chart_path)
                            print(f"âœ“ å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}")
                            
                            # é¢å¤–ç”Ÿæˆ Chart.js é…ç½® JSON æ–‡ä»¶
                            try:
                                # æå–å›¾è¡¨ä½¿ç”¨çš„å®é™…æ•°æ®
                                # chart_data = self._extract_actual_data(visualization)
                                chart_config = self._extract_chart_config(visualization, task_id, description, df, use_antv=True)
                                
                                # å°†æå–çš„å®é™…æ•°æ®æ·»åŠ åˆ°é…ç½®ä¸­
                                #if chart_data:
                                #    chart_config['data'] = chart_data
                                #    print(f"âœ“ æˆåŠŸæå–å›¾è¡¨å®é™…æ•°æ®")
                                
                                # è·å– JSON é…ç½®ç›®å½•
                                json_dir = os.path.join(os.path.dirname(charts_dir), "chart_configs")
                                os.makedirs(json_dir, exist_ok=True)
                                
                                # ä¿å­˜ JSON é…ç½®
                                json_file_name = f"{file_name}.json"
                                json_path = os.path.join(json_dir, json_file_name)
                                with open(json_path, "w", encoding="utf-8") as f:
                                    json.dump(chart_config, f, ensure_ascii=False, indent=2)
                                print(f"âœ“ å›¾è¡¨é…ç½® JSON å·²ä¿å­˜åˆ°: {json_path}")
                            except Exception as e:
                                print(f"âš ï¸ ä¿å­˜å›¾è¡¨é…ç½® JSON æ—¶å‡ºé”™: {str(e)}")
                                traceback.print_exc()
                                json_path = None
                                
                            # é¢å¤–ä¿å­˜å›¾è¡¨æ•°æ®ä¸ºCSVï¼Œä»¥ä¾¿åç»­åˆ†æ
                            try:
                                csv_dir = os.path.join(os.path.dirname(charts_dir), "chart_data")
                                os.makedirs(csv_dir, exist_ok=True)
                                csv_file_name = f"{file_name}.csv"
                                csv_path = os.path.join(csv_dir, csv_file_name)
                                
                                # å°è¯•ä»å¯è§†åŒ–å¯¹è±¡ä¸­æå–å®é™…ä½¿ç”¨çš„æ•°æ®
                                if hasattr(visualization, '_data') and isinstance(visualization._data, pd.DataFrame):
                                    visualization._data.to_csv(csv_path, index=False)
                                    print(f"âœ“ å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                elif hasattr(visualization, 'data') and isinstance(visualization.data, pd.DataFrame):
                                    visualization.data.to_csv(csv_path, index=False)
                                    print(f"âœ“ å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                # else:
                                    # å°è¯•ä»ä»£ç ä¸­æå–å’Œåˆ†ææ•°æ®
                                    #last_df_var = self._find_last_dataframe_variable(visualization.code)
                                    #if last_df_var:
                                        # è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®ä»£ç ä¸­çš„å˜é‡
                                        # æ‰€ä»¥åªèƒ½ä¿å­˜ä¸€ä¸ªæŒ‡ç¤ºæ–‡ä»¶ï¼Œæç¤ºchart_configä½¿ç”¨ä»€ä¹ˆå˜é‡
                                        #with open(csv_path + ".info", "w") as f:
                                        #    f.write(f"Last DataFrame variable: {last_df_var}")
                                        #print(f"âœ“ å›¾è¡¨æ•°æ®å˜é‡ä¿¡æ¯å·²ä¿å­˜: {last_df_var}")
                            except Exception as e:
                                print(f"âš ï¸ ä¿å­˜å›¾è¡¨æ•°æ® CSV æ—¶å‡ºé”™: {str(e)}")
                                traceback.print_exc()
                            
                            # æ£€æŸ¥å›¾è¡¨ç›¸ä¼¼åº¦
                            if self.use_similarity_check and all_charts:
                                # æ”¶é›†å·²æœ‰å›¾è¡¨çš„è·¯å¾„åˆ—è¡¨
                                existing_chart_paths = []
                                for chart in all_charts:
                                    if hasattr(chart, 'url') and chart.url:
                                        existing_chart_paths.append(chart.url)
                                
                                if existing_chart_paths:
                                    # ä½¿ç”¨batch_compareè®¡ç®—ç›¸ä¼¼åº¦
                                    is_too_similar, max_similarity, similar_chart_path, all_similarities = self.similarity_tool.batch_compare(
                                        chart_path, existing_chart_paths, self.similarity_threshold
                                    )
                                    
                                    if is_too_similar:
                                        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å›¾è¡¨å¯¹è±¡
                                        similar_chart = None
                                        for chart in all_charts:
                                            if hasattr(chart, 'url') and chart.url == similar_chart_path:
                                                similar_chart = chart
                                                break
                                        
                                        similar_task_id = getattr(similar_chart, 'task_id', 'æœªçŸ¥ä»»åŠ¡') if similar_chart else 'æœªçŸ¥ä»»åŠ¡'
                                        
                                        print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„å›¾è¡¨ä¸ç°æœ‰å›¾è¡¨ç›¸ä¼¼åº¦è¿‡é«˜ ({max_similarity:.4f})")
                                        print(f"   - ç›¸ä¼¼å›¾è¡¨: {similar_task_id}")
                                        
                                        # åˆ›å»ºsamechartæ–‡ä»¶å¤¹
                                        samechart_dir = os.path.join(charts_dir, "samechart")
                                        os.makedirs(samechart_dir, exist_ok=True)
                                        
                                        # ç§»åŠ¨ç›¸ä¼¼çš„å›¾è¡¨åˆ°samechartæ–‡ä»¶å¤¹
                                        samechart_path = os.path.join(samechart_dir, f"{file_name}.png")
                                        
                                        try:
                                            import shutil
                                            # ç§»åŠ¨å›¾è¡¨åˆ°samechartç›®å½•(è€Œéå¤åˆ¶)
                                            shutil.move(chart_path, samechart_path)
                                            print(f"âœ“ ç›¸ä¼¼å›¾è¡¨å·²ç§»åŠ¨åˆ°: {samechart_path}")
                                            
                                            # åœ¨æ§åˆ¶å°è¾“å‡ºç›¸ä¼¼åº¦ä¿¡æ¯
                                            print(f"ğŸ“Š å›¾è¡¨ç›¸ä¼¼åº¦ä¿¡æ¯:")
                                            print(f"   - ç›¸ä¼¼åº¦å€¼: {max_similarity:.4f}")
                                            print(f"   - ç›¸ä¼¼å›¾è¡¨ä»»åŠ¡: {similar_task_id}")
                                            print(f"   - å½“å‰ä»»åŠ¡: {task_id}")
                                            
                                            # æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆä½†å›¾è¡¨è¢«è·³è¿‡
                                            for vis_task in chapter.visualization_tasks:
                                                if vis_task.get('task_id') == task_id:
                                                    vis_task['visualization_success'] = False
                                                    vis_task['skipped_due_to_similarity'] = True
                                                    print(f"âš ï¸ ä»»åŠ¡ '{task_id}' å› å›¾è¡¨ç›¸ä¼¼åº¦è¿‡é«˜è€Œè¢«è·³è¿‡")
                                                    break
                                                    
                                            # è·³è¿‡å½“å‰ä»»åŠ¡çš„åç»­å¤„ç†
                                            continue
                                            
                                        except Exception as e:
                                            print(f"âš ï¸ ç§»åŠ¨ç›¸ä¼¼å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                                            # å¦‚æœç§»åŠ¨å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è·¯å¾„

                        # åˆ›å»ºå›¾è¡¨å¯¹è±¡
                        print(f"\nğŸ“Š åˆ›å»ºå›¾è¡¨å¯¹è±¡:")
                        print(f"- å›¾è¡¨è·¯å¾„: {chart_path}")
                        print(f"- å›¾è¡¨ç±»å‹: {chart_type}")
                        print(f"- ä»»åŠ¡ID: {task_id}")
                        
                        chart = Chart(
                            url=chart_path,
                            caption="",  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºåˆå§‹è¯´æ˜
                            chart_type=chart_type,
                            task_id=task_id  # task_id å®é™…ä¸Šå°±æ˜¯ä»»åŠ¡æè¿°
                        )
                        
                        # å­˜å‚¨å¯è§†åŒ–ä»£ç ï¼Œä»¥ä¾¿åç»­ä¿®æ”¹
                        if hasattr(visualization, 'code'):
                            chart.code = visualization.code
                        
                        # æ·»åŠ å›¾è¡¨åˆ°ç« èŠ‚
                        if not hasattr(chapter, 'charts'):
                            chapter.charts = []
                            print("åˆå§‹åŒ–ç« èŠ‚çš„å›¾è¡¨åˆ—è¡¨")
                        
                        chapter.charts.append(chart)
                        # æ›´æ–°æ‰€æœ‰å›¾è¡¨åˆ—è¡¨
                        all_charts.append(chart)
                        print(f"âœ“ å›¾è¡¨å·²æ·»åŠ åˆ°ç« èŠ‚ï¼Œå½“å‰ç« èŠ‚å›¾è¡¨æ•°é‡: {len(chapter.charts)}")
                        
                        # å¦‚æœå¤„ç†æˆåŠŸï¼Œä¹Ÿæ ‡è®°ä¸ºå·²å®Œæˆ
                        for vis_task in chapter.visualization_tasks:
                            if vis_task.get('task_id') == task_id:
                                vis_task['visualization_success'] = True
                                print(f"âœ… ä»»åŠ¡ '{task_id}' å·²æˆåŠŸå®Œæˆ")
                                break
                    else:
                        print("âœ— ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥")
                        # å³ä½¿å¤±è´¥ä¹Ÿæ ‡è®°ä¸ºå®Œæˆï¼Œé¿å…æ— é™å¾ªç¯
                        for vis_task in chapter.visualization_tasks:
                            if vis_task.get('task_id') == task_id:
                                # ç¡®ä¿åˆå§‹åŒ– visualization_success å­—æ®µ
                                vis_task['visualization_success'] = False
                                
                                # æ–°å¢ï¼šä¿å­˜å¤±è´¥å›¾è¡¨çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                                if hasattr(visualization, 'code'):
                                    # åˆ›å»ºå¤±è´¥å›¾è¡¨ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                                    failed_code_dir = os.path.join(charts_dir, "failed_code")
                                    os.makedirs(failed_code_dir, exist_ok=True)
                                    
                                    # ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç åˆ°æ–‡ä»¶
                                    code_file_path = os.path.join(failed_code_dir, f"{file_name}_failed.py")
                                    try:
                                        with open(code_file_path, 'w', encoding='utf-8') as f:
                                            f.write(visualization.code)
                                        print(f"âœ… å·²ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç åˆ°: {code_file_path}")
                                        
                                        # åœ¨ä»»åŠ¡ä¸­è®°å½•ä»£ç è·¯å¾„
                                        vis_task['failed_code_path'] = code_file_path
                                    except Exception as e:
                                        print(f"âŒ ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç æ—¶å‡ºé”™: {str(e)}")
                                
                                print(f"âš ï¸ ä»»åŠ¡ '{description}' è™½ç„¶å¤±è´¥ä½†å·²æ ‡è®°ä¸ºå·²å®Œæˆï¼Œé¿å…æ— é™å¾ªç¯")
                                break
            # è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a3
            return [child_node]

        except Exception as e:
            print(f"âŒ å¤„ç†èŠ‚ç‚¹æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            # ç¡®ä¿å³ä½¿å¼‚å¸¸ä¹Ÿè®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a3
            return [child_node]


    def _extract_chart_config(self, visualization, task_id, description, df, use_antv=False):
        """ä»å¯è§†åŒ–ä»£ç ä¸­æå–å›¾è¡¨é…ç½®
        
        å‚æ•°:
            visualization: åŒ…å«å¯è§†åŒ–ä»£ç çš„å­—å…¸
            task_id: ä»»åŠ¡ID
            description: ä»»åŠ¡æè¿°
            df: æ•°æ®DataFrame
            use_antv: æ˜¯å¦ä½¿ç”¨AntV G2é…ç½®ï¼ˆé»˜è®¤ä¸ºFalseï¼Œä½¿ç”¨Chart.jsï¼‰
            
        è¿”å›:
            å›¾è¡¨é…ç½®å­—å…¸
        """
        chart_config = {}
        
        try:
            # ç¡®ä¿æœ‰å¯è§†åŒ–ä»£ç 
            if not hasattr(visualization, 'code'):
                raise ValueError("å¯è§†åŒ–å¯¹è±¡æ²¡æœ‰ä»£ç å±æ€§")
            
            code = visualization.code
            print("\nğŸ“‹ åˆ†æå¯è§†åŒ–ä»£ç :")
            print("-" * 50)
            print(code)
            print("-" * 50)
            
            # æ‰“å°DataFrameä¿¡æ¯ï¼Œå¸®åŠ©ç†è§£æ•°æ®ç»“æ„
            print("\nğŸ“Š DataFrameä¿¡æ¯:")
            print(f"å½¢çŠ¶: {df.shape}")
            print(f"åˆ—å: {df.columns.tolist()}")
            print(f"æ•°æ®ç±»å‹:\n{df.dtypes}")
            print("\nå‰5è¡Œæ•°æ®:")
            print(df.head(5).to_string())
            print("-" * 50)
            
            # è·å–æ•°æ®ä¸Šä¸‹æ–‡ä¿¡æ¯
            data_context = None
            try:
                # å°è¯•è¯»å–æ•°æ®æ‘˜è¦JSONæ–‡ä»¶
                json_path = os.path.join("storyteller", "dataset", "data_context.json")
                if os.path.exists(json_path):
                    with open(json_path, 'r', encoding='utf-8') as f:
                        data_summary = json.load(f)
                        data_context = data_summary.get("dataset_description", "")
                        print(f"âœ… ä»JSONæ–‡ä»¶è¯»å–åˆ°æ•°æ®ä¸Šä¸‹æ–‡: {data_context[:100]}...")
            except Exception as e:
                print(f"âš ï¸ è¯»å–æ•°æ®ä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {str(e)}")
            
            # å¯¼å…¥ASTè§£æå™¨å’Œé…ç½®è½¬æ¢å‡½æ•°
            if use_antv:
                from storyteller.algorithm.utils.chart_config_extractor import ChartConfigExtractor, convert_to_antv_config as convert_config
                config_type = "AntV G2"
            else:
                from storyteller.algorithm.utils.chart_config_extractor import ChartConfigExtractor, convert_to_chartjs_config as convert_config
                config_type = "Chart.js"
            
            # åˆ›å»ºæå–å™¨å¹¶è§£æä»£ç 
            extractor = ChartConfigExtractor()
            ast_config = extractor.extract_from_code(code)
            
            print(f"\nğŸ” ASTè§£æç»“æœ (ç”¨äº{config_type}):")
            for key, value in ast_config.items():
                print(f"- {key}: {value}")
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰çš„é™æ€åˆ†æ
            #if "error" in ast_config:
            #    print(f"âš ï¸ ASTè§£æå¤±è´¥ï¼Œå›é€€åˆ°é™æ€åˆ†æ: {ast_config['error']}")
            #    return self._extract_chart_config_fallback(visualization, task_id, description, df, use_antv)
            
            # æå–ASTé…ç½®å¹¶ä¿®æ­£å­—æ®µä¿¡æ¯
            if "error" not in ast_config:
                # ä½¿ç”¨extractorå®ä¾‹ç›´æ¥è°ƒç”¨resolve_chart_dataï¼Œå¹¶ä¼ å…¥data_context
                try:
                    chart_data = extractor.resolve_chart_data(df, ast_config)
                    print(f"âœ“ ä½¿ç”¨ASTè§£æå™¨çš„resolve_chart_dataæ–¹æ³•ç”Ÿæˆå›¾è¡¨æ•°æ®")
                    # ä¿å­˜åŸå§‹ä»£ç ä»¥ä¾¿åç»­å¤„ç†
                    ast_config["code"] = code
                except Exception as e:
                    print(f"âš ï¸ ä½¿ç”¨resolve_chart_dataæ–¹æ³•æ—¶å‡ºé”™: {e}")
                    chart_data = None
            
            # è½¬æ¢ä¸ºç›®æ ‡é…ç½®ï¼ˆChart.jsæˆ–AntV G2ï¼‰ï¼Œä¼ å…¥data_context
            chart_config = convert_config(ast_config, df)
            
            # è®¾ç½®æ ‡é¢˜
            if not chart_config.get("title") or chart_config["title"] == "Chart":
                chart_config["title"] = description
            
            # æ ¹æ®å›¾è¡¨åº“ç±»å‹è¾“å‡ºä¸åŒçš„æ—¥å¿—ä¿¡æ¯
            if use_antv:
                print(f"\nâœ“ æˆåŠŸç”ŸæˆAntV G2é…ç½®:")
                print(f"- å›¾è¡¨ç±»å‹: {chart_config['type']}")
                print(f"- å›¾è¡¨æ ‡é¢˜: {chart_config['title']}")
                print(f"- Xè½´å­—æ®µ: {chart_config['xField']}")
                print(f"- Yè½´å­—æ®µ: {chart_config['yField']}")
                print(f"- æ•°æ®ç‚¹æ•°é‡: {len(chart_config['data'])}")
                series_field = chart_config.get('seriesField', None)
                if series_field:
                    print(f"- åˆ†ç»„å­—æ®µ: {series_field}")
                    print(f"- æ˜¯å¦å †å : {'æ˜¯' if chart_config.get('isStack', False) else 'å¦'}")
            else:
                print(f"\nâœ“ æˆåŠŸç”ŸæˆChart.jsé…ç½®:")
                print(f"- å›¾è¡¨ç±»å‹: {chart_config['type']}")
                print(f"- å›¾è¡¨æ ‡é¢˜: {chart_config['title']}")
                print(f"- Xè½´å­—æ®µ: {chart_config.get('x_field', '')}")
                print(f"- Yè½´å­—æ®µ: {chart_config.get('y_field', '')}")
                print(f"- æ•°æ®ç‚¹æ•°é‡: {len(chart_config['data']['labels'])}")
                print(f"- æ•°æ®é›†æ•°é‡: {len(chart_config['data']['datasets'])}")
                print(f"- æ˜¯å¦å †å æŸ±çŠ¶å›¾: {'æ˜¯' if chart_config.get('options', {}).get('scales', {}).get('y', {}).get('stacked', False) else 'å¦'}")
            
        except Exception as e:
            print(f"âš ï¸ æå–å›¾è¡¨é…ç½®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å›é€€åˆ°åŸæœ‰æ–¹æ³•
            # chart_config = self._extract_chart_config_fallback(visualization, task_id, description, df, use_antv)
        
        return chart_config

class ReviseVis(DataStorytellingAction):
    def __init__(self):
        super().__init__("A4", "å¯¹æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨è¿›è¡ŒReviseåˆ¤æ–­")
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨"""
        # åˆ›å»ºå­èŠ‚ç‚¹
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = self
        child_node.depth = node.depth + 1
        
        try:
            # éå†æ‰€æœ‰ç« èŠ‚
            for chapter_idx, chapter in enumerate(child_node.report.chapters):
                # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å¯è§†åŒ–ä»»åŠ¡
                if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                    print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡")
                    continue
                    
                for task in chapter.visualization_tasks:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ˜¯ç”ŸæˆæˆåŠŸçš„æˆ–è€…å› ç›¸ä¼¼åº¦è·³è¿‡çš„
                    if task.get('visualization_success', False) == True:
                        continue
                        
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å› ç›¸ä¼¼åº¦é«˜è€Œè¢«è·³è¿‡çš„ï¼Œå¦‚æœæ˜¯åˆ™ä¸éœ€è¦ä¿®å¤
                    if task.get('skipped_due_to_similarity', False) == True:
                        print(f"âš ï¸ ä»»åŠ¡ '{task.get('task_id', '')}' å› ç›¸ä¼¼åº¦è¿‡é«˜è€Œè¢«è·³è¿‡ï¼Œä¸éœ€è¦ä¿®å¤")
                        continue
                        
                    task_id = task.get('task_id', "")
                    description = task.get('task_description', "")
                    
                    print(f"æ­£åœ¨ä¿®æ”¹ä»»åŠ¡ '{task_id}' çš„å›¾è¡¨...")
            
                    selected_chart = None
                    print(f"\nğŸ” åœ¨ç« èŠ‚ä¸­æŸ¥æ‰¾å›¾è¡¨:")
                    print(f"- ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
                    print(f"- ç« èŠ‚ä¸­çš„å›¾è¡¨æ•°é‡: {len(getattr(chapter, 'charts', []))}")
                    
                    for c in chapter.charts:
                        print(f"- æ£€æŸ¥å›¾è¡¨: task_id={getattr(c, 'task_id', 'None')}")
                        if hasattr(c, 'task_id') and c.task_id == task_id:
                            selected_chart = c
                            print(f"âœ“ æ‰¾åˆ°åŒ¹é…çš„å›¾è¡¨")
                            break
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾è¡¨ï¼Œè·³è¿‡æ­¤ä»»åŠ¡
                    if not selected_chart:
                        print(f"âš ï¸ æ‰¾ä¸åˆ°ä¸ä»»åŠ¡ '{task_id}' åŒ¹é…çš„å›¾è¡¨ï¼Œè·³è¿‡")
                        continue
                
                    try:
                        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„
                        dataset_path = node.report.dataset_path
                        
                        # è¯»å–æ•°æ®
                        df = pd.read_csv(dataset_path)
                        
                        # åˆ›å»º LIDA ç®¡ç†å™¨
                        from lida.components.manager import Manager
                        from lida.datamodel import Summary
                        
                        # åˆ›å»ºè‡ªå®šä¹‰çš„æ–‡æœ¬ç”Ÿæˆå™¨
                        text_gen = llm(provider="openai", model="gpt-4o")
                        manager = Manager(text_gen=text_gen)
                        
                        # è¯»å–æ•°æ®æ‘˜è¦ JSON æ–‡ä»¶
                        data_summary = {}
                        json_path = os.path.join("storyteller", "dataset", "data_context.json")
                        print(f"å°è¯•è¯»å–æ•°æ®æ‘˜è¦ JSON: {json_path}")
                        
                        try:
                            with open(json_path, 'r', encoding='utf-8') as f:
                                data_summary = json.load(f)
                            print("âœ“ æˆåŠŸè¯»å–æ•°æ®æ‘˜è¦ JSON")
                        except Exception as e:
                            print(f"âœ— è¯»å–æ•°æ®æ‘˜è¦ JSON å¤±è´¥: {str(e)}")
                            # å¦‚æœæ— æ³•è¯»å– JSON æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            data_summary = {
                                "name": node.report.original_query,
                                "dataset_description": node.report.data_context,
                                "fields_info": {col: {"dtype": str(dtype)} for col, dtype in zip(df.columns, df.dtypes)}
                            }
                        
                        # åˆ›å»º Summary å¯¹è±¡ï¼Œç›´æ¥ä» JSON æ–‡ä»¶ä¸­æå–å¿…è¦å‚æ•°
                        summary = Summary(
                            name=data_summary.get("name", "æ•°æ®åˆ†æ"),
                            file_name=dataset_path,  # ä½¿ç”¨åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„
                            dataset_description=str(data_summary.get("dataset_description", "è´­ç‰©æ•°æ®é›†")),
                            field_names=list(data_summary.get("fields_info", {}).keys()) if "fields_info" in data_summary else df.columns.tolist(),
                            fields=[info.get("dtype", "unknown") for info in data_summary.get("fields_info", {}).values()] if "fields_info" in data_summary else [str(dtype) for dtype in df.dtypes.tolist()]
                        )
                        
                        # ç”Ÿæˆç¼–è¾‘æŒ‡ä»¤
                        edit_instruction = "ä¿®æ”¹å›¾è¡¨é”™è¯¯ï¼Œæ¯”å¦‚ä¿®æ”¹ä¸ºæ›´åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼Œè®©å›¾è¡¨æ›´åŠ ç¾è§‚ï¼Œæ¸…æ™°"
                        #print(f"ç”Ÿæˆçš„ç¼–è¾‘æŒ‡ä»¤: {edit_instruction}")
                        
                        # ä½¿ç”¨ LIDA çš„ edit åŠŸèƒ½ä¿®æ”¹å›¾è¡¨
                        print(f"æ­£åœ¨ä¿®æ”¹ä»»åŠ¡ '{description}' çš„å›¾è¡¨...")
                        edited_visualization = manager.edit(
                            code=selected_chart.code,
                            summary=summary,
                            instructions=edit_instruction,
                            library="matplotlib"
                        )
                        
                        # å¤„ç†ç¼–è¾‘åçš„å¯è§†åŒ–ç»“æœ
                        if edited_visualization is None:
                            print("âœ— ç¼–è¾‘å¯è§†åŒ–å›¾è¡¨å¤±è´¥: è¿”å›ç»“æœä¸ºNone")
                        elif isinstance(edited_visualization, list) and len(edited_visualization) > 0:
                            edited_visualization = edited_visualization[0]
                            print("âœ“ ä½¿ç”¨ç¬¬ä¸€ä¸ªç¼–è¾‘ç»“æœè¿›è¡Œå¤„ç†")
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ç¼–è¾‘ç»“æœ
                        if hasattr(edited_visualization, 'status') and edited_visualization.status:
                            print("âœ“ æˆåŠŸä¿®æ”¹å¯è§†åŒ–å›¾è¡¨")
                            
                            # æ‰¾åˆ°å½“å‰å›¾è¡¨æ‰€åœ¨çš„è¿­ä»£ç›®å½•
                            original_chart_path = selected_chart.url
                            chart_dir = os.path.dirname(original_chart_path)
                            
                            # å°†ä¿®æ”¹åçš„å›¾è¡¨ä¿å­˜åˆ°åŒä¸€ç›®å½•ä¸‹
                            edited_chart_name = f"{task_id}_edited.png"
                            edited_chart_path = os.path.join(chart_dir, edited_chart_name)
                            
                            # ä¿å­˜ä¿®æ”¹åçš„å›¾è¡¨
                            if hasattr(edited_visualization, 'savefig'):
                                edited_visualization.savefig(edited_chart_path)
                                print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨å·²ä¿å­˜åˆ°: {edited_chart_path}")

                                
                                # é¢å¤–ç”Ÿæˆ Chart.js é…ç½® JSON æ–‡ä»¶
                                try:
                                    # å€Ÿç”¨ Tasks2Charts ç±»ä¸­çš„æ–¹æ³•æ¥æå–å›¾è¡¨é…ç½®
                                    from storyteller.algorithm.mcts_action import Tasks2Charts
                                    tasks2charts = Tasks2Charts()
                                    
                                    # æå–å›¾è¡¨ä½¿ç”¨çš„å®é™…æ•°æ®
                                    chart_data = tasks2charts._extract_actual_data(edited_visualization)
                                    chart_config = tasks2charts._extract_chart_config(edited_visualization, task_id, description, df)
                                    
                                    # å°†æå–çš„å®é™…æ•°æ®æ·»åŠ åˆ°é…ç½®ä¸­
                                    if chart_data:
                                        chart_config['data'] = chart_data
                                        print(f"âœ“ æˆåŠŸæå–å›¾è¡¨å®é™…æ•°æ®")
                                    
                                    # è·å– JSON é…ç½®ç›®å½•
                                    json_dir = os.path.join(os.path.dirname(chart_dir), "chart_configs")
                                    os.makedirs(json_dir, exist_ok=True)
                                    
                                    # ä¿å­˜ JSON é…ç½®
                                    json_file_name = f"{task_id}_edited.json"
                                    json_path = os.path.join(json_dir, json_file_name)
                                    with open(json_path, "w", encoding="utf-8") as f:
                                        json.dump(chart_config, f, ensure_ascii=False, indent=2)
                                    print(f"âœ“ å›¾è¡¨é…ç½® JSON å·²ä¿å­˜åˆ°: {json_path}")
                                    
                                    # é¢å¤–ä¿å­˜å›¾è¡¨æ•°æ®ä¸ºCSVï¼Œä»¥ä¾¿åç»­åˆ†æ
                                    try:
                                        csv_dir = os.path.join(os.path.dirname(chart_dir), "chart_data")
                                        os.makedirs(csv_dir, exist_ok=True)
                                        csv_file_name = f"{task_id}_edited.csv"
                                        csv_path = os.path.join(csv_dir, csv_file_name)
                                        
                                        # å°è¯•ä»å¯è§†åŒ–å¯¹è±¡ä¸­æå–å®é™…ä½¿ç”¨çš„æ•°æ®
                                        if hasattr(edited_visualization, '_data') and isinstance(edited_visualization._data, pd.DataFrame):
                                            edited_visualization._data.to_csv(csv_path, index=False)
                                            print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                        elif hasattr(edited_visualization, 'data') and isinstance(edited_visualization.data, pd.DataFrame):
                                            edited_visualization.data.to_csv(csv_path, index=False)
                                            print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                        # else:
                                            # å°è¯•ä»ä»£ç ä¸­æå–å’Œåˆ†ææ•°æ®
                                            #last_df_var = tasks2charts._find_last_dataframe_variable(edited_visualization.code)
                                            #if last_df_var:
                                                # è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®ä»£ç ä¸­çš„å˜é‡
                                                # æ‰€ä»¥åªèƒ½ä¿å­˜ä¸€ä¸ªæŒ‡ç¤ºæ–‡ä»¶ï¼Œæç¤ºchart_configä½¿ç”¨ä»€ä¹ˆå˜é‡
                                                #with open(csv_path + ".info", "w") as f:
                                                #    f.write(f"Last DataFrame variable: {last_df_var}")
                                                #print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å˜é‡ä¿¡æ¯å·²ä¿å­˜: {last_df_var}")
                                    except Exception as e:
                                        print(f"âš ï¸ ä¿å­˜ä¿®æ”¹åçš„å›¾è¡¨æ•°æ® CSV æ—¶å‡ºé”™: {str(e)}")
                                        traceback.print_exc()
                                except Exception as e:
                                    print(f"âš ï¸ ä¿å­˜å›¾è¡¨é…ç½® JSON æ—¶å‡ºé”™: {str(e)}")
                                    traceback.print_exc()
                                    json_path = None

                            # åˆ›å»ºæ–°çš„å›¾è¡¨å¯¹è±¡
                            from storyteller.algorithm.mcts_node import Chart
                            edited_chart = Chart(
                                url=edited_chart_path,
                                caption="",  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºåˆå§‹è¯´æ˜
                                chart_type=selected_chart.chart_type,
                                task_id=task_id  # ä½¿ç”¨åŸå§‹ä»»åŠ¡ID/æè¿°
                            )
                            edited_chart.needs_caption = True  # è®¾ç½®éœ€è¦ç”Ÿæˆè¯´æ˜æ–‡å­—çš„æ ‡å¿—
                           
                            # æ·»åŠ JSONé…ç½®è·¯å¾„å±æ€§
                            if 'json_path' in locals() and json_path:
                                edited_chart.json_config_path = json_path
                                print(f"- JSON é…ç½®è·¯å¾„: {json_path}")
                                                        
                            # æ›´æ–°ç« èŠ‚ä¸­çš„å›¾è¡¨
                            for i, c in enumerate(chapter.charts):
                                if hasattr(c, 'task_id') and c.task_id == task_id:
                                    chapter.charts[i] = edited_chart
                                    break
                        else:
                            error_msg = edited_visualization.error if hasattr(edited_visualization, 'error') else "æœªçŸ¥é”™è¯¯"
                            print(f"âœ— ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨å¤±è´¥: {error_msg}")
                    except Exception as e:
                        print(f"âœ— ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        import traceback
                        traceback.print_exc()
            
            # è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a4
            return [child_node]
                
        except Exception as e:
            print(f"âŒ å¤„ç†èŠ‚ç‚¹æ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†çš„ä»»åŠ¡")
            # ç¡®ä¿å³ä½¿å¼‚å¸¸ä¹Ÿè®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a4
            return [child_node]
   
 

class Charts2Captions(DataStorytellingAction):
    def __init__(self):
        super().__init__("A5", "æ ¹æ®æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆæ‰€æœ‰å¯¹åº”Caption")
    
    def _get_image_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸º base64 ç¼–ç """
        try:
            with Image.open(image_path) as img:
                # å°†å›¾ç‰‡è½¬æ¢ä¸º bytes
                img_byte_arr = io.BytesIO()
                img.save(img_byte_arr, format=img.format)
                img_byte_arr = img_byte_arr.getvalue()
                # è½¬æ¢ä¸º base64
                return base64.b64encode(img_byte_arr).decode('utf-8')
        except Exception as e:
            print(f"âŒ å›¾ç‰‡è½¬æ¢å¤±è´¥: {str(e)}")
            return None

    def call_vision_api(self, prompt, image_base64_list, **kwargs):
        """ç»Ÿä¸€å¤„ç†è§†è§‰APIè°ƒç”¨ï¼Œæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªå›¾åƒ"""
        import os
        import requests
        import json
        
        # è·å–ç¯å¢ƒå˜é‡
        base_url = os.environ.get("OPENAI_BASE_URL", "https://api.openai.com/v1")
        api_key = os.environ.get("OPENAI_API_KEY", "")
        
        # æ—¥å¿—è®°å½•
        print(f"ğŸ”„ ç¯å¢ƒå˜é‡çŠ¶æ€: OPENAI_BASE_URL={base_url}, OPENAI_API_KEY={'å·²è®¾ç½®' if api_key else 'æœªè®¾ç½®'}")
        
        # æ„é€ å®Œæ•´çš„API URL
        if base_url.endswith('/chat/completions'):
            url = base_url  # å·²ç»æ˜¯å®Œæ•´URL
        elif base_url.endswith('/v1'):
            url = f"{base_url}/chat/completions"  # æ·»åŠ chat/completionsç«¯ç‚¹
        else:
            # ç¡®ä¿URLä»¥æ–œæ ç»“å°¾
            if not base_url.endswith('/'):
                base_url += '/'
            url = f"{base_url}v1/chat/completions"  # æ·»åŠ v1/chat/completionsè·¯å¾„
            
        print(f"ğŸ”„ ä½¿ç”¨API URL: {url}")
        
        # è®¾ç½®è¯·æ±‚å¤´
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}" if api_key else ""
        }
        
        # å‡†å¤‡å›¾åƒå†…å®¹
        image_contents = []
        for img_base64 in (image_base64_list if isinstance(image_base64_list, list) else [image_base64_list]):
            image_contents.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}"
                }
            })
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "You are a data visualization expert."},
            {"role": "user", "content": [{"type": "text", "text": prompt}, *image_contents]}
        ]
        
        # è®¾ç½®APIè°ƒç”¨å‚æ•°
        model = kwargs.get("model", "gpt-4o")
        temperature = kwargs.get("temperature", 0.7)
        max_tokens = kwargs.get("max_tokens", 4096)
        
        data = {
            "model": model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }
        
        print(f"ğŸ”„ è°ƒç”¨è§†è§‰APIï¼Œæ¨¡å‹: {model}, æ¸©åº¦: {temperature}")
        
        # è°ƒç”¨API
        try:
            response = requests.post(url, headers=headers, data=json.dumps(data))
            response_json = response.json()
            
            if 'choices' in response_json and response_json['choices']:
                return response_json['choices'][0]['message']['content'].strip()
            else:
                print(f"âŒ APIè¿”å›é”™è¯¯æˆ–æ— å“åº”: {response_json}")
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            traceback.print_exc()
        
        return None
    
    def generate_chapter_caption_schemes(self, node, chapter, chapter_idx, charts, num_schemes=3, llm_kwargs=None):
        """ä¸ºå•ä¸ªç« èŠ‚çš„æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¯•æœºåˆ¶"""
        # è¿‡æ»¤å‡ºæˆåŠŸç”Ÿæˆçš„å›¾è¡¨
        successful_charts = []
        for chart in charts:
            # æŸ¥æ‰¾å¯¹åº”çš„visualization_task
            chart_task_id = getattr(chart, 'task_id', '')
            task_success = False
            
            # ä»å¯è§†åŒ–ä»»åŠ¡ä¸­æŸ¥æ‰¾ä¸å›¾è¡¨å…³è”çš„ä»»åŠ¡çŠ¶æ€
            if hasattr(chapter, 'visualization_tasks'):
                for task in chapter.visualization_tasks:
                    if task.get('task_id') == chart_task_id:
                        task_success = task.get('visualization_success', False)
                        break
            
            # åªæ·»åŠ æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
            if task_success:
                successful_charts.append(chart)
        
        # å¦‚æœç« èŠ‚å†…æ²¡æœ‰æˆåŠŸç”Ÿæˆçš„å›¾è¡¨ï¼Œç›´æ¥è¿”å›ç©º
        if not successful_charts:
            print(f"âš ï¸ ç« èŠ‚ {chapter_idx+1} æ²¡æœ‰æˆåŠŸç”Ÿæˆçš„å›¾è¡¨éœ€è¦å¤„ç†")
            return []
        
        print(f"\nğŸ”„ ä¸ºç« èŠ‚ {chapter_idx+1} ç”Ÿæˆ {num_schemes} å¥—è¯´æ˜æ–¹æ¡ˆ")
        print(f"ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
        print(f"éœ€å¤„ç†çš„å›¾è¡¨æ•°é‡: {len(successful_charts)} (ä» {len(charts)} æ€»å›¾è¡¨ä¸­ç­›é€‰)")
        
        # å‡†å¤‡å›¾è¡¨ä¿¡æ¯æ–‡æœ¬å’Œå›¾åƒ
        charts_info = ""
        chart_images = []
        
        for i, chart in enumerate(successful_charts):
            charts_info += f"\nå›¾è¡¨{i}:"
            charts_info += f"\n- ç±»å‹: {chart.chart_type}"
            charts_info += f"\n- ä»»åŠ¡: {chart.task_id}"
            
            # è·å–å›¾è¡¨å›¾åƒæ•°æ®
            image_base64 = self._get_image_base64(chart.url)
            if image_base64:
                chart_images.append(image_base64)
            else:
                print(f"âŒ æ— æ³•è·å–å›¾è¡¨ {i} çš„å›¾åƒæ•°æ®")
        
        if not chart_images:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å›¾è¡¨å›¾åƒæ•°æ®")
            return []
            
        # å®ç°é‡è¯•æœºåˆ¶
        max_retries = 3
        for retry in range(max_retries):
            try:
                # ä½¿ç”¨æ¨¡æ¿æ–‡ä»¶ç”Ÿæˆæç¤ºè¯
                prompt_args = {
                    "QUERY": node.original_query,
                    "CHAPTER_TITLE": getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}'),
                    "DATA_CONTEXT": node.report.data_context,
                    "NUM_SCHEMES": str(num_schemes),
                    "CHARTS_INFO": charts_info,
                    "RETRY_NUM": str(retry + 1)  # å‘Šè¯‰æ¨¡å‹è¿™æ˜¯ç¬¬å‡ æ¬¡å°è¯•
                }
                
                # å¢å¼ºæç¤ºè¯
                prompt = get_prompt("chapter_captions", prompt_args)
                if retry > 0:
                    # å¯¹äºé‡è¯•ï¼Œå¢åŠ æ›´æ˜ç¡®çš„JSONæ ¼å¼è¦æ±‚
                    prompt += f"\n\nã€é‡è¦ã€‘è¿™æ˜¯ç¬¬{retry+1}æ¬¡å°è¯•ï¼Œè¯·åŠ¡å¿…ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚æ‚¨çš„å“åº”å¿…é¡»åŒ…å«å®Œæ•´çš„JSONç»“æ„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                    prompt += """
{
  "schemes": [
    {
      "scheme_id": 1,
      "captions": [
        {
          "chart_idx": 0,
          "caption": "å›¾è¡¨0çš„è¯´æ˜æ–‡å­—"
        },
        {
          "chart_idx": 1,
          "caption": "å›¾è¡¨1çš„è¯´æ˜æ–‡å­—"
        }
      ]
    },
    {
      "scheme_id": 2,
      "captions": [
        {
          "chart_idx": 0,
          "caption": "å¦ä¸€ç§å›¾è¡¨0çš„è¯´æ˜æ–‡å­—"
        },
        {
          "chart_idx": 1,
          "caption": "å¦ä¸€ç§å›¾è¡¨1çš„è¯´æ˜æ–‡å­—"
        }
      ]
    }
  ]
}
"""
                
                # è°ƒç”¨è§†è§‰API
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨APIç”Ÿæˆç« èŠ‚ {chapter_idx+1} çš„è¯´æ˜æ–¹æ¡ˆ... (å°è¯• {retry+1}/{max_retries})")
                # é™ä½æ¸©åº¦ï¼Œæé«˜ç¡®å®šæ€§
                api_kwargs = llm_kwargs.copy() if llm_kwargs else {}
                api_kwargs['temperature'] = max(0.1, 0.7 - retry * 0.2)  # é€æ¸é™ä½æ¸©åº¦
                response_text = self.call_vision_api(prompt, chart_images, **api_kwargs)
                
                if not response_text:
                    print(f"âŒ ç« èŠ‚ {chapter_idx+1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº” (å°è¯• {retry+1}/{max_retries})")
                    if retry < max_retries - 1:
                        print("å°†åœ¨1ç§’åé‡è¯•...")
                        import time
                        time.sleep(1)
                        continue
                    else:
                        return []
                
                # è§£æJSONå“åº”
                print(f"ğŸ” LLMå“åº”ç‰‡æ®µ: {response_text[:200]}...")
                result = self.extract_json_from_text(response_text)
                
                if result and "schemes" in result:
                    schemes = result["schemes"]
                    print(f"âœ… æˆåŠŸä¸ºç« èŠ‚ {chapter_idx+1} ç”Ÿæˆ {len(schemes)} å¥—è¯´æ˜æ–¹æ¡ˆ")
                    return schemes
                
                print(f"âŒ æ— æ³•è§£æç« èŠ‚ {chapter_idx+1} çš„å›¾è¡¨è¯´æ˜æ–¹æ¡ˆ (å°è¯• {retry+1}/{max_retries})")
                if retry < max_retries - 1:
                    print("å°†åœ¨1ç§’åé‡è¯•...")
                    import time
                    time.sleep(1)
                else:
                    print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¯´æ˜æ–¹æ¡ˆ")
                    return []
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆç« èŠ‚å›¾è¡¨è¯´æ˜æ–¹æ¡ˆå‡ºé”™: {str(e)} (å°è¯• {retry+1}/{max_retries})")
                traceback.print_exc()
                if retry < max_retries - 1:
                    print("å°†åœ¨1ç§’åé‡è¯•...")
                    import time
                    time.sleep(1)
                else:
                    print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¯´æ˜æ–¹æ¡ˆ")
                    return []
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return []
    
    def extract_json_from_text(self, text):
        """ä»LLMå“åº”ä¸­æå–JSONï¼Œå…·æœ‰æ›´å¼ºçš„å®¹é”™èƒ½åŠ›"""
        try:
            # å…ˆå°è¯•æŸ¥æ‰¾JSONå—
            match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
            if match:
                json_str = match.group(1)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONå—è§£æå¤±è´¥: {str(e)}ï¼Œå°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ")
                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    json_str = self._fix_json(json_str)
                    return json.loads(json_str)
            
            # å¦‚æœæ²¡æœ‰JSONå—ï¼Œå°è¯•å¯»æ‰¾æ•´ä¸ªæ–‡æœ¬ä¸­çš„JSONå¯¹è±¡
            match = re.search(r'(\{[\s\S]*\})', text)
            if match:
                json_str = match.group(1)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONå¯¹è±¡è§£æå¤±è´¥: {str(e)}ï¼Œå°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ")
                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    json_str = self._fix_json(json_str)
                    return json.loads(json_str)
            
            # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–schemeséƒ¨åˆ†
            schemes_match = re.search(r'"schemes"\s*:\s*(\[[\s\S]*?\])', text)
            if schemes_match:
                schemes_str = schemes_match.group(1)
                print(f"âœ“ æå–åˆ°schemesæ•°ç»„ï¼Œå°è¯•æ„å»ºå®Œæ•´JSON")
                try:
                    # æ„å»ºä¸€ä¸ªæ–°çš„JSON
                    new_json = f'{{"schemes": {schemes_str}}}'
                    return json.loads(new_json)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ æå–çš„schemesè§£æå¤±è´¥: {str(e)}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´ç»“æ„ï¼Œå°è¯•æ‰‹åŠ¨æå–æ¯ä¸ªcaption
            captions = re.findall(r'(?:chart_idx|å›¾è¡¨ç´¢å¼•)["\s:]+(\d+)[\s"]*(?:,|\})[\s\S]*?(?:caption|è¯´æ˜æ–‡å­—)["\s:]+([^"]*?)[",$}]', text)
            if captions:
                print(f"âœ“ æ‰‹åŠ¨æå–åˆ° {len(captions)} ä¸ªcaptionæ¡ç›®")
                manual_scheme = {
                    "scheme_id": 1,
                    "captions": []
                }
                
                for chart_idx_str, caption in captions:
                    try:
                        chart_idx = int(chart_idx_str)
                        manual_scheme["captions"].append({
                            "chart_idx": chart_idx,
                            "caption": caption.strip()
                        })
                    except ValueError:
                        pass
                
                if manual_scheme["captions"]:
                    return {"schemes": [manual_scheme]}
            
            return None
        except Exception as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
            traceback.print_exc()
            return None
    
    def _fix_json(self, json_str):
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        # ä¿®å¤ç¼ºå°‘é€—å·çš„é—®é¢˜
        json_str = re.sub(r'}\s*{', '},{', json_str)
        json_str = re.sub(r']\s*\[', '],[', json_str)
        
        # ä¿®å¤å¤šä½™çš„é€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å±æ€§åæœ‰å¼•å·
        json_str = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_str)
        
        # ä¿®å¤è½¬ä¹‰é—®é¢˜
        json_str = json_str.replace('\\"', '"').replace('\\\\', '\\')
        
        return json_str
    
    def generate_combined_nodes(self, node, all_chapter_schemes, max_nodes=3):
        """ç”Ÿæˆå­èŠ‚ç‚¹ç»„åˆ - ä½¿ç”¨ç®€å•ç­–ç•¥ï¼šå…¨éƒ¨ç« èŠ‚ä½¿ç”¨ç¬¬nå¥—æ–¹æ¡ˆ"""
        if not all_chapter_schemes:
            return []
        
        children_nodes = []
        
        # è®¡ç®—æ¯ä¸ªç« èŠ‚æœ€å¤šæœ‰å‡ å¥—æ–¹æ¡ˆ
        max_schemes = max([len(chapter_data["schemes"]) for chapter_data in all_chapter_schemes], default=0)
        
        # ç­–ç•¥ï¼šæ‰€æœ‰ç« èŠ‚ä½¿ç”¨åŒä¸€å¥—æ–¹æ¡ˆç¼–å·ï¼ˆå…¨éƒ¨ç”¨æ–¹æ¡ˆ1ï¼Œå…¨éƒ¨ç”¨æ–¹æ¡ˆ2...ï¼‰
        for scheme_idx in range(min(max_schemes, max_nodes)):
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            child_node.node_type = ReportGenerationState.a5
            
            caption_applied = False  # è·Ÿè¸ªæ˜¯å¦åº”ç”¨äº†ä»»ä½•è¯´æ˜
            
            # å¯¹æ¯ä¸ªç« èŠ‚åº”ç”¨ç›¸åŒç¼–å·çš„æ–¹æ¡ˆ
            for chapter_data in all_chapter_schemes:
                chapter_idx = chapter_data["chapter_idx"]
                schemes = chapter_data["schemes"]
                
                # å¦‚æœæ­¤ç« èŠ‚æœ‰å¯¹åº”ç¼–å·çš„æ–¹æ¡ˆ
                if 0 <= scheme_idx < len(schemes):
                    scheme = schemes[scheme_idx]
                    chapter = child_node.report.chapters[chapter_idx]
                    
                    print(f"ğŸ”„ ä¸ºå­èŠ‚ç‚¹{scheme_idx+1}åº”ç”¨ç« èŠ‚{chapter_idx+1}çš„æ–¹æ¡ˆ{scheme.get('scheme_id', scheme_idx+1)}")
                    
                    # åº”ç”¨æ­¤æ–¹æ¡ˆä¸­çš„æ‰€æœ‰å›¾è¡¨è¯´æ˜
                    for caption_info in scheme.get("captions", []):
                        chart_idx = caption_info.get("chart_idx")
                        caption = caption_info.get("caption", "")
                        
                    if hasattr(chapter, 'charts') and 0 <= chart_idx < len(chapter.charts):
                        chart = chapter.charts[chart_idx]
                        chart.caption = caption
                        chart.needs_caption = False
                        caption_applied = True
                            
                            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                        if hasattr(chapter, 'visualization_tasks'):
                            for task in chapter.visualization_tasks:
                                if task.get('task_id') == chart.task_id:
                                    task['status'] = 'completed'
                                    task['caption_generated'] = True
                                    break
                            
            if caption_applied:  # åªæœ‰å½“åº”ç”¨äº†è¯´æ˜æ—¶æ‰æ·»åŠ èŠ‚ç‚¹
                child_node.caption_strategy = f"ç»Ÿä¸€æ–¹æ¡ˆ{scheme_idx+1}"
                children_nodes.append(child_node)
                print(f"âœ… æˆåŠŸåˆ›å»ºå­èŠ‚ç‚¹ {scheme_idx+1}ï¼Œä½¿ç”¨ç»Ÿä¸€æ–¹æ¡ˆ {scheme_idx+1}")
        
        return children_nodes

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¸ºå›¾è¡¨ç”Ÿæˆè¯´æ˜æ–‡å­—ï¼ŒæŒ‰ç« èŠ‚å¤„ç†å¹¶ç”Ÿæˆå¤šä¸ªå­èŠ‚ç‚¹"""
        # æ”¶é›†éœ€è¦å¤„ç†çš„ç« èŠ‚åŠå…¶å›¾è¡¨
        chapters_with_charts = []
        for chapter_idx, chapter in enumerate(node.report.chapters):
            if not hasattr(chapter, 'charts') or not chapter.charts:
                continue
                
            # æ”¶é›†éœ€è¦ç”Ÿæˆè¯´æ˜çš„å›¾è¡¨
            charts_needing_captions = []
            for chart in chapter.charts:
                if not hasattr(chart, 'caption') or not chart.caption:
                    # æŸ¥æ‰¾è¯¥å›¾è¡¨å¯¹åº”çš„ä»»åŠ¡çŠ¶æ€
                    chart_task_id = getattr(chart, 'task_id', '')
                    task_success = False
                    
                    # ä»å¯è§†åŒ–ä»»åŠ¡ä¸­æŸ¥æ‰¾ä¸å›¾è¡¨å…³è”çš„ä»»åŠ¡çŠ¶æ€
                    if hasattr(chapter, 'visualization_tasks'):
                        for task in chapter.visualization_tasks:
                            if task.get('task_id') == chart_task_id:
                                task_success = task.get('visualization_success', False)
                                break
                # åªå¤„ç†æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
                if task_success:
                    charts_needing_captions.append(chart)
                else:
                    print(f"âš ï¸ è·³è¿‡å›¾è¡¨ {chart_task_id}ï¼Œå› ä¸ºå®ƒçš„ç”ŸæˆçŠ¶æ€ä¸ºå¤±è´¥")
            if charts_needing_captions:
                chapters_with_charts.append({
                    "chapter_idx": chapter_idx,
                    "chapter": chapter,
                    "charts": charts_needing_captions
                })
                print(f"âœ… ç« èŠ‚ {chapter_idx+1} æœ‰ {len(charts_needing_captions)} ä¸ªå›¾è¡¨éœ€è¦ç”Ÿæˆè¯´æ˜")
        
        if not chapters_with_charts:
            # æ²¡æœ‰éœ€è¦å¤„ç†çš„å›¾è¡¨ï¼Œè¿”å›åŸèŠ‚ç‚¹
            print("æ²¡æœ‰éœ€è¦ç”Ÿæˆè¯´æ˜çš„å›¾è¡¨ï¼Œè¿”å›åŸèŠ‚ç‚¹")
            node.node_type = ReportGenerationState.a5
            return [node]
        
        # å¯¹æ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆ
        all_chapter_schemes = []
        for chapter_info in chapters_with_charts:
            chapter_idx = chapter_info["chapter_idx"]
            chapter = chapter_info["chapter"]
            charts = chapter_info["charts"]
            
            # ä¸ºè¯¥ç« èŠ‚æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆ
            chapter_schemes = self.generate_chapter_caption_schemes(
                node,
                chapter, 
                chapter_idx,
                charts, 
                num_schemes=3,  # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆ3ç§ä¸åŒçš„è¯´æ˜æ–¹æ¡ˆ
                llm_kwargs=llm_kwargs
            )
            
            if chapter_schemes:
                all_chapter_schemes.append({
                    "chapter_idx": chapter_idx,
                    "schemes": chapter_schemes
                })
                print(f"âœ… ç« èŠ‚ {chapter_idx} æˆåŠŸç”Ÿæˆ {len(chapter_schemes)} å¥—è¯´æ˜æ–¹æ¡ˆ")
            else:
                print(f"âŒ ç« èŠ‚ {chapter_idx} ç”Ÿæˆè¯´æ˜æ–¹æ¡ˆå¤±è´¥")
        
        # ç”Ÿæˆå­èŠ‚ç‚¹ç»„åˆ - ä½¿ç”¨ç®€å•ç­–ç•¥ï¼šå…¨éƒ¨ç« èŠ‚ä½¿ç”¨ç¬¬nå¥—æ–¹æ¡ˆ
        children_nodes = self.generate_combined_nodes(node, all_chapter_schemes)
        
        if not children_nodes:
            # å¦‚æœæ²¡æœ‰æˆåŠŸç”Ÿæˆå­èŠ‚ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬èŠ‚ç‚¹
            print("âŒ æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„å­èŠ‚ç‚¹ç»„åˆï¼Œå°†è¿”å›åŸºæœ¬èŠ‚ç‚¹")
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            child_node.node_type = ReportGenerationState.a5
            return [child_node]
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(children_nodes)} ä¸ªå­èŠ‚ç‚¹")
        return children_nodes


class Captions2Summaries(DataStorytellingAction):
    def __init__(self):
        super().__init__("A6", "æ ¹æ®æ¯ä¸ªç« èŠ‚çš„Captionç”Ÿæˆæ¯ä¸ªç« èŠ‚çš„æ€»ç»“")
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_summary_prompt(self, node, chapter_idx=None, **kwargs):
        """ç”Ÿæˆç« èŠ‚æ€»ç»“æç¤ºè¯"""
        # å¦‚æœæŒ‡å®šäº†ç« èŠ‚ç´¢å¼•ï¼Œç”Ÿæˆç‰¹å®šç« èŠ‚çš„æç¤ºè¯
        if chapter_idx is not None and 0 <= chapter_idx < len(node.report.chapters):
            chapter = node.report.chapters[chapter_idx]
            chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
            
            # æ”¶é›†æœ¬ç« èŠ‚æ‰€æœ‰å›¾è¡¨åŠå…¶è¯´æ˜
            visualization_tasks = []
            if hasattr(chapter, 'visualization_tasks'):
                for task in chapter.visualization_tasks:
                    task_info = {
                        'description': task.get('task_description', ''),
                        'charts': []
                    }
                    
                    # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨
                    if hasattr(chapter, 'charts') and chapter.charts:
                        # æŸ¥æ‰¾ä¸ä»»åŠ¡å…³è”çš„å›¾è¡¨
                        for chart in chapter.charts:
                            if hasattr(chart, 'task_id') and chart.task_id == task.get('task_id'):
                                # æ£€æŸ¥è¯¥å›¾è¡¨ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
                                task_success = False
                                for t in chapter.visualization_tasks:
                                    if t.get('task_id') == chart.task_id and t.get('visualization_success', False):
                                        task_success = True
                                        break
                                
                                if task_success:
                                    caption = getattr(chart, 'caption', 'æ— è¯´æ˜æ–‡å­—')
                                    task_info['charts'].append({
                                        'caption': caption
                                    })
                    
                    # åªæ·»åŠ æœ‰å›¾è¡¨çš„ä»»åŠ¡
                    if task_info['charts']:
                        visualization_tasks.append(task_info)
            
            # å‡†å¤‡æç¤ºè¯å‚æ•°
            prompt_args = {
                "QUERY": node.original_query,
                "CHAPTER_TITLE": chapter_title,
                "visualization_tasks": json.dumps(visualization_tasks, ensure_ascii=False, indent=2)
            }
            
            return get_prompt("chapter_summary", prompt_args)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç« èŠ‚ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        return {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "DATA_CONTEXT": node.report.data_context
        }
    
    def apply_summaries(self, node, action, cluster, **kwargs):
        """å°†ç« èŠ‚æ€»ç»“åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        # åˆ›å»ºå­èŠ‚ç‚¹
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = action
        child_node.depth = node.depth + 1
        
        try:
            # ä»èšç±»ä¸­è·å–æ¯ä¸ªç« èŠ‚çš„æ€»ç»“
            if "chapter_summaries" in cluster:
                chapter_summaries = cluster["chapter_summaries"]
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                success_count = 0
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(child_node.report.chapters):
                        chapter = child_node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… å·²åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                if success_count > 0:
                    child_node.node_type = ReportGenerationState.FINALIZED
                    return [child_node]
            
            # å¦‚æœæ²¡æœ‰ä»èšç±»ä¸­è·å–åˆ°æ€»ç»“ï¼Œå°è¯•è‡ªè¡Œå¤„ç†
            print("âš ï¸ æœªä»èšç±»ä¸­è·å–åˆ°ç« èŠ‚æ€»ç»“ï¼Œå°è¯•è‡ªè¡Œå¤„ç†...")
            success = self.process_all_chapters(child_node, **kwargs)
            
            if success:
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            else:
                print("âŒ å¤„ç†ç« èŠ‚æ€»ç»“å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ åº”ç”¨ç« èŠ‚æ€»ç»“æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def generate_chapter_summaries(self, node, llm_kwargs, n=3):
        """ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“"""
        all_chapter_summaries = []
        
        # éå†æ‰€æœ‰ç« èŠ‚
        for chapter_idx, chapter in enumerate(node.report.chapters):
            # å®‰å…¨åœ°è·å–ç« èŠ‚æ ‡é¢˜
            chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
            
            print(f"\nğŸ“‘ æ­£åœ¨ä¸ºç¬¬ {chapter_idx + 1} ç« ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“...")
            print(f"ç« èŠ‚æ ‡é¢˜: {chapter_title}")
            
            # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨åŠè¯´æ˜
            has_captions = False
            if hasattr(chapter, 'charts') and chapter.charts:
                for chart in chapter.charts:
                    if hasattr(chart, 'caption') and chart.caption:
                        has_captions = True
                        break
            
            if not has_captions:
                print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å›¾è¡¨æˆ–è¯´æ˜æ–‡å­—ï¼Œè·³è¿‡")
                continue
                
            # ç”Ÿæˆè¯¥ç« èŠ‚çš„æç¤ºè¯
            prompt = self.generate_summary_prompt(node, chapter_idx=chapter_idx)
            
            # æ”¶é›†è¯¥ç« èŠ‚çš„å¤šä¸ªå€™é€‰æ€»ç»“
            chapter_summaries = []
            
            for i in range(n):
                # ä¸ºæ¯ä¸ªå€™é€‰ä½¿ç”¨ä¸åŒçš„æ¸©åº¦
                llm_kwargs_temp = llm_kwargs.copy()
                llm_kwargs_temp['temperature'] = 0.3 + i * 0.2  # 0.3, 0.5, 0.7
                
                print(f"ğŸ”„ ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1}/{n} (æ¸©åº¦: {llm_kwargs_temp['temperature']})")
                
                responses = call_openai(prompt, **llm_kwargs_temp)
                if responses:
                    summary = responses[0].strip()
                    
                    # æ”¶é›†å€™é€‰æ€»ç»“
                    chapter_summaries.append({
                        "chapter_idx": chapter_idx,
                        "summary": summary,
                        "variant_id": i
                    })
                    
                    print(f"âœ… æˆåŠŸç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1}")
                else:
                    print(f"âŒ ç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1} ç”Ÿæˆå¤±è´¥")
            
            # å¦‚æœæˆåŠŸç”Ÿæˆäº†å€™é€‰æ€»ç»“ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
            if chapter_summaries:
                all_chapter_summaries.append({
                    "chapter_idx": chapter_idx,
                    "chapter_title": chapter_title,
                    "candidate_summaries": chapter_summaries
                })
        
        return all_chapter_summaries
    
    def cluster_chapter_summaries(self, all_chapter_summaries, llm_kwargs):
        """å¯¹æ¯ä¸ªç« èŠ‚çš„å€™é€‰æ€»ç»“è¿›è¡Œèšç±»ï¼Œå¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“"""
        if not all_chapter_summaries:
            return []
        
        try:
            # å‡†å¤‡èšç±»æ•°æ®
            formatting_data = []
            for chapter_data in all_chapter_summaries:
                chapter_idx = chapter_data["chapter_idx"]
                chapter_title = chapter_data["chapter_title"]
                candidates = chapter_data["candidate_summaries"]
                
                # è½¬æ¢ä¸ºèšç±»æ‰€éœ€çš„æ ¼å¼
                formatted_candidates = [
                    {
                        "index": candidate["variant_id"],
                        "chapter_idx": chapter_idx,
                        "summary": candidate["summary"]
                    }
                    for candidate in candidates
                ]
                
                formatting_data.append({
                    "chapter_idx": chapter_idx,
                    "chapter_title": chapter_title,
                    "candidates": formatted_candidates
                })
            
            # ä½¿ç”¨æ¨¡æ¿æ–‡ä»¶ç”Ÿæˆèšç±»æç¤ºè¯
            prompt_args = {
                "CHAPTER_SUMMARIES_DATA": json.dumps(formatting_data, ensure_ascii=False, indent=2)
            }
            
            clustering_prompt = get_prompt("chapter_summary_clustering", prompt_args)
            
            # è°ƒç”¨ LLM è¿›è¡Œèšç±»
            print("\nğŸ” æ­£åœ¨å¯¹ç« èŠ‚æ€»ç»“è¿›è¡Œèšç±»åˆ†æ...")
            responses = call_openai(clustering_prompt, **llm_kwargs)
            
            if not responses:
                print("âŒ èšç±»åˆ†ææ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                return []
            
            # è§£æå“åº”
            clustering_response = responses[0]
            
            # æå– JSON éƒ¨åˆ†
            import re
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', clustering_response)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = clustering_response
            
            try:
                # è§£æ JSON
                clustering_result = json.loads(json_str)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„èšç±»ç»“æœ
                if "clusters" in clustering_result and clustering_result["clusters"]:
                    print(f"âœ… æˆåŠŸè·å– {len(clustering_result['clusters'])} ä¸ªèšç±»")
                    return clustering_result["clusters"]
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æé”™è¯¯: {str(e)}")
                print(f"âŒ åŸå§‹å“åº”:\n{clustering_response}")
        
        except Exception as e:
            print(f"âŒ èšç±»ç« èŠ‚æ€»ç»“æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
        
        return []
    
    def process_all_chapters(self, node, **kwargs):
        """å¤„ç†æ‰€æœ‰ç« èŠ‚ï¼Œä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆæ€»ç»“"""
        llm_kwargs = kwargs.get("llm_kwargs", {})
        
        try:
            # å¦‚æœæ˜¯ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶å¹¶ä¸”æœ‰å¤šä¸ªå€™é€‰æ€»ç»“
            if self.use_unified_framework:
                # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“
                all_chapter_summaries = self.generate_chapter_summaries(node, llm_kwargs)
                
                if not all_chapter_summaries:
                    print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç« èŠ‚çš„å€™é€‰æ€»ç»“")
                    return False
                
                # å¯¹å€™é€‰æ€»ç»“è¿›è¡Œèšç±»å¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“
                clusters = self.cluster_chapter_summaries(all_chapter_summaries, llm_kwargs)
                
                if not clusters:
                    print("âŒ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„èšç±»ç»“æœ")
                    return False
                
                # åº”ç”¨ç¬¬ä¸€ä¸ªèšç±»çš„ç»“æœ
                cluster = clusters[0]
                print(f"âœ… åº”ç”¨èšç±» {cluster.get('cluster_id', 'æœªçŸ¥')} çš„æ€»ç»“ç»“æœ")
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                chapter_summaries = cluster.get("chapter_summaries", [])
                success_count = 0
                
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(node.report.chapters):
                        chapter = node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… å·²åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                return success_count > 0
            else:
                # åŸæœ‰çš„é€»è¾‘ï¼ˆæœªä½¿ç”¨ç»Ÿä¸€æ¡†æ¶ï¼‰
                success_count = 0

                # éå†æ‰€æœ‰ç« èŠ‚
                for chapter_idx, chapter in enumerate(node.report.chapters):
                    # å®‰å…¨åœ°è·å–ç« èŠ‚æ ‡é¢˜
                    chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
                    
                    print(f"\nğŸ“‘ æ­£åœ¨å¤„ç†ç¬¬ {chapter_idx + 1} ç« : {chapter_title}")
                    
                    # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å¯è§†åŒ–ä»»åŠ¡
                    if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                        print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡")
                        continue
                    
                    # æ”¶é›†æœ¬ç« èŠ‚æ‰€æœ‰å›¾è¡¨åŠå…¶è¯´æ˜
                    visualization_tasks = []
                    for task in chapter.visualization_tasks:
                        task_info = {
                            'description': task.get('task_description', ''),
                            'charts': []
                        }
                        
                        # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨
                        if not hasattr(chapter, 'charts') or not chapter.charts:
                            continue
                            
                        # æŸ¥æ‰¾ä¸ä»»åŠ¡å…³è”çš„å›¾è¡¨
                        for chart in chapter.charts:
                            if hasattr(chart, 'task_id') and chart.task_id == task.get('task_id'):
                                caption = getattr(chart, 'caption', 'æ— è¯´æ˜æ–‡å­—')
                                task_info['charts'].append({
                                    'caption': caption
                                })
                        
                        # åªæ·»åŠ æœ‰å›¾è¡¨çš„ä»»åŠ¡
                        if task_info['charts']:
                            visualization_tasks.append(task_info)
                    
                    # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æœ‰æ•ˆçš„å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡æ­¤ç« èŠ‚
                    if not visualization_tasks:
                        print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰æœ‰æ•ˆçš„å¯è§†åŒ–ä»»åŠ¡å›¾è¡¨ï¼Œè·³è¿‡")
                        continue
                    
                    # å‡†å¤‡ prompt
                    prompt_args = {
                        "QUERY": node.original_query,
                        "CHAPTER_TITLE": chapter_title,
                        "visualization_tasks": json.dumps(visualization_tasks, ensure_ascii=False, indent=2)
                    }
                    
                    prompt = get_prompt("chapter_summary", prompt_args)
                    
                    # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
                    responses = call_openai(prompt, **llm_kwargs)
                    if not responses:
                        print(f"âŒ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                        continue
                    
                    summary = responses[0].strip()
                    
                    print(f"\nğŸ“ ç¬¬ {chapter_idx + 1} ç« çš„æ‘˜è¦:")
                    print("-" * 50)
                    print(summary)
                    print("-" * 50)
                    
                    # ä¿å­˜æ‘˜è¦åˆ°ç« èŠ‚
                    chapter.summary = summary
                    print(f"âœ… å·²ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„æ‘˜è¦")
                    success_count += 1

                return success_count > 0
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç« èŠ‚æ‘˜è¦æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return False
                
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        if self.use_unified_framework:
            # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“
            all_chapter_summaries = self.generate_chapter_summaries(node, llm_kwargs)
            
            if not all_chapter_summaries:
                print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç« èŠ‚çš„å€™é€‰æ€»ç»“ï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            
            # å¯¹å€™é€‰æ€»ç»“è¿›è¡Œèšç±»å¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“
            clusters = self.cluster_chapter_summaries(all_chapter_summaries, llm_kwargs)
            
            if not clusters:
                print("âŒ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„èšç±»ç»“æœï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            
            # ä¸ºæ¯ä¸ªèšç±»åˆ›å»ºä¸€ä¸ªå­èŠ‚ç‚¹
            children_nodes = []
            
            for cluster_idx, cluster in enumerate(clusters):
                cluster_id = cluster.get("cluster_id", f"cluster_{cluster_idx+1}")
                
                print(f"ğŸ”„ æ­£åœ¨ä¸ºèšç±» {cluster_id} åˆ›å»ºå­èŠ‚ç‚¹")
                
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                chapter_summaries = cluster.get("chapter_summaries", [])
                success_count = 0
                
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(child_node.report.chapters):
                        chapter = child_node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… ä¸ºèšç±» {cluster_id} åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                if success_count > 0:
                    # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                    child_node.node_type = ReportGenerationState.a6
                    child_node.summary_cluster_id = cluster_id
                    children_nodes.append(child_node)
                    print(f"âœ… æˆåŠŸåˆ›å»ºèšç±» {cluster_id} çš„å­èŠ‚ç‚¹")
            
            # å¦‚æœæ²¡æœ‰åˆ›å»ºä»»ä½•å­èŠ‚ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤èŠ‚ç‚¹
            if not children_nodes:
                print("âŒ æ²¡æœ‰åˆ›å»ºä»»ä½•æœ‰æ•ˆçš„å­èŠ‚ç‚¹ï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.a6
                return [child_node]
            
            return children_nodes
        else:
            # åŸæœ‰å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            
            # å¤„ç†æ‰€æœ‰ç« èŠ‚çš„æ€»ç»“
            self.process_all_chapters(child_node, llm_kwargs=llm_kwargs)
        
        # è®¾ç½®æœ€ç»ˆçŠ¶æ€
        child_node.node_type = ReportGenerationState.a6
        
        return [child_node]
    
class ReviseNarrativeStrategy(DataStorytellingAction):
    def __init__(self):
        super().__init__("NarrativeStrategy", "è°ƒæ•´æŠ¥å‘Šå™äº‹ç­–ç•¥ï¼Œé‡æ–°æ’åºç« èŠ‚")
        self.use_unified_framework = True  # ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_narrative_prompt(self, node, **kwargs):
        """ç”Ÿæˆå™äº‹ç­–ç•¥æç¤ºè¯"""
        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapters_info = []
        for i, chapter in enumerate(node.report.chapters):
            chapter_info = {
                "index": i,
                "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}"),
                "summary": getattr(chapter, 'summary', "") if hasattr(chapter, 'summary') else ""
            }
            chapters_info.append(chapter_info)
        
        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        prompt_args = {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "CHAPTERS": json.dumps(chapters_info, ensure_ascii=False, indent=2)
        }
        
        return get_prompt("revise_narrative", prompt_args)
    
    def apply_narrative_strategy(self, node, action, cluster, **kwargs):
        """å°†å™äº‹ç­–ç•¥åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–å™äº‹ç­–ç•¥å’Œç« èŠ‚é¡ºåº
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            strategy = cluster.get("strategy", "")
            strategy_reason = cluster.get("strategy_reason", "")
            chapter_order = cluster.get("chapter_order", [])
            
            if not chapter_order:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚é¡ºåºä¿¡æ¯ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“˜ åº”ç”¨èšç±» {cluster_id} çš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ")
            print(f"   ç­–ç•¥: {strategy}")
            print(f"   åŸå› : {strategy_reason}")
            
            # éªŒè¯ç« èŠ‚é¡ºåº
            if len(chapter_order) != len(node.report.chapters):
                print(f"âš ï¸ ç« èŠ‚æ•°é‡ä¸åŒ¹é…: æœŸæœ› {len(node.report.chapters)}, å®é™… {len(chapter_order)}")
                return None
                
            # æ ¹æ®æ–°é¡ºåºé‡æ’ç« èŠ‚
            new_chapters = []
            for chapter_info in chapter_order:
                original_index = chapter_info.get("original_index")
                if not isinstance(original_index, int) or original_index < 0 or original_index >= len(node.report.chapters):
                    print(f"âš ï¸ æ— æ•ˆçš„ç« èŠ‚ç´¢å¼•: {original_index}")
                    continue
                
                new_chapters.append(copy.deepcopy(node.report.chapters[original_index]))
                print(f"   - ç§»åŠ¨ç« èŠ‚ '{chapter_info.get('title', '')}' åˆ°æ–°ä½ç½®")
                print(f"     åŸå› : {chapter_info.get('reason', 'æœªæä¾›')}")
            
            # å¦‚æœæ²¡æœ‰æˆåŠŸé‡æ’æ‰€æœ‰ç« èŠ‚ï¼Œè·³è¿‡æ­¤èšç±»
            if len(new_chapters) != len(node.report.chapters):
                print(f"âš ï¸ ç« èŠ‚é‡æ’ä¸å®Œæ•´ï¼Œè·³è¿‡æ­¤èšç±»")
                return None
            
            # æ›´æ–°æŠ¥å‘Šçš„ç« èŠ‚é¡ºåºå’Œå™äº‹ç­–ç•¥
            child_node.report.chapters = new_chapters
            child_node.report.narrative_strategy = {
                "strategy": strategy,
                "strategy_reason": strategy_reason,
                "cluster_id": cluster_id
            }
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.REVISECHAPTERSORDERS
            
            print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨å™äº‹ç­–ç•¥æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ç”Ÿæˆå¤šä¸ªå™äº‹ç­–ç•¥æ–¹æ¡ˆå¹¶èšç±»é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"""
        return unified_generation_framework(
            node=node,
            action=self,
            llm_kwargs=llm_kwargs,
            action_type="narrative",
            prompt_generator=self.generate_narrative_prompt,
            node_applier=self.apply_narrative_strategy,
            n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ
        )



class TransitionAction(DataStorytellingAction):
    def __init__(self):
        super().__init__("Transition", "æ·»åŠ ç« èŠ‚é—´è¿‡æ¸¡æ–‡æœ¬ï¼Œæé«˜æŠ¥å‘Šè¿è´¯æ€§")
        self.use_unified_framework = True  # ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_transition_prompt(self, node, **kwargs):
        """ç”Ÿæˆè¿‡æ¸¡æ–‡æœ¬æç¤ºè¯"""
        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapters_info = []
        for i, chapter in enumerate(node.report.chapters):
            chapter_info = {
                "index": i,
                "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}"),
                "summary": getattr(chapter, 'summary', "") if hasattr(chapter, 'summary') else "",
                "charts_captions": [
                    getattr(chart, 'caption', "") for chart in getattr(chapter, 'charts', [])
                ]
            }
            chapters_info.append(chapter_info)
        
        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        prompt_args = {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "CHAPTERS": json.dumps(chapters_info, ensure_ascii=False, indent=2),
            "NARRATIVE_STRATEGY": json.dumps(getattr(node.report, 'narrative_strategy', {}), ensure_ascii=False, indent=2)
        }
        
        return get_prompt("add_transitions", prompt_args)
    
    def apply_transitions(self, node, action, cluster, **kwargs):
        """å°†è¿‡æ¸¡æ–‡æœ¬åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            transitions = cluster.get("transitions", [])
            
            if not transitions:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰è¿‡æ¸¡æ–‡æœ¬ä¿¡æ¯ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“ åº”ç”¨èšç±» {cluster_id} çš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ")
            
            # åº”ç”¨è¿‡æ¸¡æ–‡æœ¬
            success_count = 0
            for transition in transitions:
                chapter_idx = transition.get("chapter_idx")
                transition_text = transition.get("transition_text", "")
                
                if not isinstance(chapter_idx, int) or chapter_idx < 0 or chapter_idx >= len(child_node.report.chapters):
                    print(f"âš ï¸ æ— æ•ˆçš„ç« èŠ‚ç´¢å¼•: {chapter_idx}")
                    continue
                
                # æ·»åŠ è¿‡æ¸¡æ–‡æœ¬åˆ°ç« èŠ‚
                chapter = child_node.report.chapters[chapter_idx]
                if not hasattr(chapter, 'transition'):
                    chapter.transition = ""
                
                chapter.transition = transition_text
                success_count += 1
                print(f"   âœ… ä¸ºç¬¬ {chapter_idx + 1} ç« æ·»åŠ è¿‡æ¸¡æ–‡æœ¬")
            
            # å¦‚æœæ²¡æœ‰æˆåŠŸæ·»åŠ ä»»ä½•è¿‡æ¸¡æ–‡æœ¬ï¼Œè·³è¿‡æ­¤èšç±»
            if success_count == 0:
                print(f"âš ï¸ æ²¡æœ‰æˆåŠŸæ·»åŠ ä»»ä½•è¿‡æ¸¡æ–‡æœ¬ï¼Œè·³è¿‡æ­¤èšç±»")
                return None
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.FINALIZED
            
            print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆï¼Œå…± {success_count} ä¸ªè¿‡æ¸¡")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨è¿‡æ¸¡æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ç”Ÿæˆå¤šä¸ªè¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆå¹¶èšç±»é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"""
        return unified_generation_framework(
            node=node,
            action=self,
            llm_kwargs=llm_kwargs,
            action_type="transition",
            prompt_generator=self.generate_transition_prompt,
            node_applier=self.apply_transitions,
            n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ
        )

    

# ä¿®æ­£ save_chart æ–¹æ³•ï¼Œå°†å…¶ä½œä¸ºç±»æ–¹æ³•è€Œä¸æ˜¯ç‹¬ç«‹å‡½æ•°
class ChartUtils:
    @staticmethod
    def save_chart(node: MCTSNode, chart_data: dict) -> str:
        """ä¿å­˜å›¾è¡¨å¹¶è¿”å›URL"""
        # è·å–å½“å‰è¿­ä»£å·ï¼Œæ·»åŠ è°ƒè¯•ä¿¡æ¯
        current_iteration = node.report.current_iteration
        print(f"Debug: ä¿å­˜å›¾è¡¨æ—¶çš„è¿­ä»£å·: {current_iteration}")
        print(f"Debug: èŠ‚ç‚¹ç±»å‹: {node.node_type}")
        print(f"Debug: èŠ‚ç‚¹æ·±åº¦: {node.depth}")
        
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è¿­ä»£å·
        if current_iteration is None or current_iteration < 1:
            print("è­¦å‘Š: current_iteration æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ 1")
            current_iteration = 1
        
        # æ„å»ºä¿å­˜è·¯å¾„
        iteration_dir = os.path.join("storyteller", "output", "iterations", f"iteration_{current_iteration}")
        charts_dir = os.path.join(iteration_dir, "charts")
        os.makedirs(charts_dir, exist_ok=True)
        
        print(f"Debug: å›¾è¡¨å°†ä¿å­˜åˆ°: {charts_dir}")
        
        return charts_dir

    def get_current_iteration_dir(self):
        """è·å–å½“å‰è¿­ä»£çš„è¾“å‡ºç›®å½•"""
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å½“å‰è¿­ä»£ç›®å½•å±æ€§
            if hasattr(self, 'current_iteration_dir') and self.current_iteration_dir:
                return self.current_iteration_dir
            
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å‡ºæ ¹ç›®å½•å±æ€§
            if hasattr(self, 'output_dir') and self.output_dir:
                # æ‰¾åˆ°æœ€æ–°çš„è¿­ä»£ç›®å½•
                iteration_dirs = glob.glob(os.path.join(self.output_dir, "iteration_*"))
                if iteration_dirs:
                    # æŒ‰åˆ›å»ºæ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„
                    latest_dir = max(iteration_dirs, key=os.path.getctime)
                    return latest_dir
            
            # å¦‚æœæ²¡æœ‰è®¾ç½®è¾“å‡ºç›®å½•ï¼Œä½¿ç”¨é»˜è®¤çš„è¾“å‡ºç›®å½•
            default_output_dir = os.path.join("output", "mcts")
            os.makedirs(default_output_dir, exist_ok=True)
            
            # æŸ¥æ‰¾æœ€æ–°çš„è¿­ä»£ç›®å½•
            iteration_dirs = glob.glob(os.path.join(default_output_dir, "iteration_*"))
            if iteration_dirs:
                latest_dir = max(iteration_dirs, key=os.path.getctime)
                return latest_dir
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°è¿­ä»£ç›®å½•ï¼Œåˆ›å»ºä¸€ä¸ªæ–°çš„
            new_dir = os.path.join(default_output_dir, f"iteration_{int(time.time())}")
            os.makedirs(new_dir, exist_ok=True)
            return new_dir
            
        except Exception as e:
            print(f"âš ï¸ è·å–å½“å‰è¿­ä»£ç›®å½•æ—¶å‡ºé”™: {str(e)}")
            # è¿”å›ä¸´æ—¶ç›®å½•
            temp_dir = os.path.join("output", "temp_charts")
            os.makedirs(temp_dir, exist_ok=True)
            return temp_dir




# å°†å­—å…¸å®šä¹‰ä¿ç•™ä¸ºæ¨¡å—çº§å˜é‡
NODE_TYPE_TO_VALID_ACTIONS = {
    ReportGenerationState.EMPTY: [
        Query2Chapters
    ],
    ReportGenerationState.a1: [
        Chapters2Tasks,
    ],
    ReportGenerationState.a2: [
        Tasks2Charts
    ],
    ReportGenerationState.a3: [
        ReviseVis,
        Charts2Captions
    ],
    ReportGenerationState.a4: [
        Charts2Captions
    ],
    ReportGenerationState.a5: [
        Captions2Summaries,
    ],
    ReportGenerationState.a6: [
        ReviseNarrativeStrategy,
        TransitionAction
    ],
    ReportGenerationState.REVISECHAPTERSORDERS: [
        TransitionAction
    ], 
    ReportGenerationState.FINALIZED: []  # ç»ˆæ­¢çŠ¶æ€ï¼Œæ·»åŠ è¿‡æ¸¡åçš„æœ€ç»ˆçŠ¶æ€
}



