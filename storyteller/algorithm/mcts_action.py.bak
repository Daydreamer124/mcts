import copy
import json
import re,os,traceback
from typing import Dict, List, Any, Optional
from storyteller.algorithm.utils.DatasetContextGenerator import DatasetContextGenerator  # å¼•å…¥æ•°æ®é›†è§£æå™¨
from storyteller.algorithm.mcts_node import *
from storyteller.llm_call.openai_llm import call_openai
from storyteller.llm_call.prompt_factory import get_prompt
from typing import List, Dict, Any
import pandas as pd
from enum import Enum
import base64
from PIL import Image
import io,requests
from openai import OpenAI
from .utils.html2image import convert_html_file_to_image
from storyteller.algorithm.mcts_node import ReportGenerationState
from llmx import llm, TextGenerator
from lida.components.manager import Manager
from storyteller.algorithm.utils.universalsc import run_universal_self_consistency  # å¯¼å…¥universalscåŠŸèƒ½
from storyteller.algorithm.utils.unified_framework import unified_generation_framework  # å¯¼å…¥ç»Ÿä¸€æ¡†æ¶
import time
from tqdm import tqdm




class DataStorytellingAction:
    def __init__(self, action_id: str, description: str):
        self.action_id = action_id
        self.description = description# é»˜è®¤çš„ä¸‹ä¸€ä¸ªçŠ¶æ€
        
        # æ·»åŠ  MCTS ç»Ÿè®¡å±æ€§
        #self.Q = 0.0  # ç´¯ç§¯å¥–åŠ±
        #self.N = 0    # è®¿é—®æ¬¡æ•°
  

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
        
            raise NotImplementedError
        
    
class Query2Chapters(DataStorytellingAction):
    def __init__(self):
        super().__init__("A1", "å®šä¹‰ç« èŠ‚ç»“æ„") 
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶

    def generate_chapter_prompt(self, node, **kwargs):
        """ç”Ÿæˆç« èŠ‚æç¤ºè¯"""
        query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
        data_context = node.report.data_context
        
        # ä½¿ç”¨é¢„è®¾çš„æç¤ºæ¨¡æ¿
        prompt_args = {
            "QUERY": query,
            "DATA_CONTEXT": data_context
        }
        
        return get_prompt("Query2Chapters", prompt_args)
    
    def apply_chapters(self, node, action, cluster, **kwargs):
        """å°†ç« èŠ‚åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            chapters = cluster.get("chapters", [])
            
            if not chapters:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“˜ ä¸ºèšç±» {cluster_id} åº”ç”¨ç« èŠ‚æ–¹æ¡ˆ")
            print(f"   ç« èŠ‚ç»“æ„: {chapters}")
            
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # æ¸…ç©ºç°æœ‰ç« èŠ‚
            child_node.report.chapters = []
            
            # æ·»åŠ ç« èŠ‚
            for title in chapters:
                child_node.report.add_chapter(Chapter(title=title))
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.a1
            
            print(f"âœ… æˆåŠŸæ·»åŠ èšç±» {cluster_id} çš„ç« èŠ‚æ–¹æ¡ˆ")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨ç« èŠ‚æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """
        æ ¹æ®ç”¨æˆ·æŸ¥è¯¢å’Œæ•°æ®ä¸Šä¸‹æ–‡ï¼Œä½¿ç”¨ç»Ÿä¸€æ¡†æ¶ç”Ÿæˆå¤šæ ·åŒ–ç« èŠ‚ç»“æ„
        """
        if self.use_unified_framework:
            return unified_generation_framework(
                node=node,
                action=self,
                llm_kwargs=llm_kwargs,
                action_type="chapters",
                prompt_generator=self.generate_chapter_prompt,
                node_applier=self.apply_chapters,
                n=4
            )
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹æ³•çš„å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            # ä½¿ç”¨ clarified_queryï¼ˆå¦‚æœæœ‰ï¼‰æˆ–åŸå§‹æŸ¥è¯¢
            query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
            data_context = node.report.data_context
            print(data_context)
            # è¿è¡ŒUSCæµç¨‹è·å–èšç±»ç»“æœ
            clusters = run_universal_self_consistency(query, data_context, llm_kwargs, n=4)
            print(f"âœ… å®Œæˆç« èŠ‚èšç±»ï¼Œå¾—åˆ° {len(clusters)} ä¸ªèšç±»")
            
            # ä»æ¯ä¸ªèšç±»ä¸­åˆ›å»ºå­èŠ‚ç‚¹
            nodes = []
            for cluster in clusters:
                cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
                chapters = cluster.get("chapters", [])
                
                # è·³è¿‡æ²¡æœ‰ç« èŠ‚çš„èšç±»
                if not chapters:
                    print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡")
                    continue
        
                print(f"ğŸ“˜ ä¸ºèšç±» {cluster_id} åˆ›å»ºå­èŠ‚ç‚¹")
                print(f"   ç« èŠ‚ç»“æ„: {chapters}")
                
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # æ¸…ç©ºç°æœ‰ç« èŠ‚
                child_node.report.chapters = []
                
                # æ·»åŠ ç« èŠ‚
                for title in chapters:
                        child_node.report.add_chapter(Chapter(title=title))
                
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.a1
                
                # æ·»åŠ åˆ°èŠ‚ç‚¹åˆ—è¡¨
                nodes.append(child_node)
                print(f"âœ… æˆåŠŸæ·»åŠ èšç±» {cluster_id} çš„ç« èŠ‚æ–¹æ¡ˆ")
        
        return nodes



class Chapters2Tasks(DataStorytellingAction):
    def __init__(self):
        super().__init__("A2", "æ ¹æ®ç« èŠ‚æ–¹æ¡ˆåˆ’åˆ†ç« èŠ‚ä»»åŠ¡æ–¹æ¡ˆ")
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶

    def generate_tasks_prompt(self, node, **kwargs):
        """ç”Ÿæˆä»»åŠ¡æç¤ºè¯"""
        # è·å–æ•°æ®é›†ä¿¡æ¯
        data_context = node.report.data_context
        query = node.report.clarified_query if node.report.clarified_query else node.report.original_query
        
        # æ„å»ºç« èŠ‚åˆ—è¡¨
        chapters_list = []
        for i, chapter in enumerate(node.report.chapters):
            # å®‰å…¨è·å–æ ‡é¢˜
            if isinstance(chapter, dict):
                # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                if 'title' in chapter:
                    # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                    if isinstance(chapter['title'], dict):
                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                        title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                    else:
                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                        title_text = chapter['title']
                else:
                    # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                    title_text = f"ç« èŠ‚{i+1}"
            else:
                # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                title_attr = getattr(chapter, 'title', None)
                if isinstance(title_attr, dict):
                    # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                    title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                else:
                    # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                    title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
            
            chapters_list.append({"title": title_text})
        
        # ç”Ÿæˆ LLM æç¤ºè¯
        prompt_args = {
            "QUERY": query,
            "DATA_CONTEXT": data_context,
            "CHAPTERS": json.dumps(chapters_list, ensure_ascii=False)
        }
        
        return get_prompt("Chapters2Tasks", prompt_args)
    
    def apply_tasks(self, node, action, cluster, **kwargs):
        """å°†ä»»åŠ¡åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–èšç±»ä¸­çš„ç« èŠ‚ä»»åŠ¡
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            chapters_info = cluster.get("chapters", [])
            
            if not chapters_info:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ä»»åŠ¡å†…å®¹ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“‹ ä¸ºèšç±» {cluster_id} åº”ç”¨ä»»åŠ¡æ–¹æ¡ˆ")
            
            # åˆ›å»ºç« èŠ‚æ ‡é¢˜åˆ°ç´¢å¼•çš„æ˜ å°„
            chapter_title_to_index = {}
            for i, chapter in enumerate(child_node.report.chapters):
                # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                if isinstance(chapter, dict):
                    # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                    if 'title' in chapter:
                        # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                        if isinstance(chapter['title'], dict):
                            # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                            title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                        else:
                            # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                            title_text = chapter['title']
                    else:
                        # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        title_text = f"ç« èŠ‚{i+1}"
                else:
                    # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                    title_attr = getattr(chapter, 'title', None)
                    if isinstance(title_attr, dict):
                        # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                        title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                    else:
                        # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                        title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                
                # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                if not isinstance(title_text, str):
                    title_text = str(title_text)
                    
                # å­˜å‚¨å°å†™æ ‡é¢˜æ–‡æœ¬åˆ°ç´¢å¼•çš„æ˜ å°„
                chapter_title_to_index[title_text.lower()] = i
            
            # è·Ÿè¸ªå“ªäº›ç« èŠ‚å·²ç»åˆ†é…äº†ä»»åŠ¡
            chapters_with_tasks = set()
            
            # å¤„ç†æ¯ä¸ªç« èŠ‚
            for chapter_info in chapters_info:
                raw_title = chapter_info.get("title", "")
                
                # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                if isinstance(raw_title, dict):
                    # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬
                    title_text = raw_title.get('title', '') or raw_title.get('text', '')
                else:
                    # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                    title_text = raw_title
                
                # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                if not isinstance(title_text, str):
                    title_text = str(title_text) if title_text is not None else ""
                    
                tasks = chapter_info.get("tasks", [])
                
                # æŸ¥æ‰¾åŒ¹é…çš„ç« èŠ‚
                chapter_idx = -1
                title_lower = title_text.lower()  # ç°åœ¨å¯ä»¥å®‰å…¨è°ƒç”¨lower()
                
                # ç²¾ç¡®åŒ¹é…
                if title_lower in chapter_title_to_index:
                    chapter_idx = chapter_title_to_index[title_lower]
                else:
                    # æ¨¡ç³ŠåŒ¹é…
                    for i, chapter in enumerate(child_node.report.chapters):
                        # å®‰å…¨è·å–ç« èŠ‚æ ‡é¢˜
                        if isinstance(chapter, dict):
                            if 'title' in chapter:
                                if isinstance(chapter['title'], dict):
                                    search_title = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                else:
                                    search_title = chapter['title']
                            else:
                                search_title = f"ç« èŠ‚{i+1}"
                        else:
                            title_attr = getattr(chapter, 'title', None)
                            if isinstance(title_attr, dict):
                                search_title = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                            else:
                                search_title = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                        
                        # ç¡®ä¿search_titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                        if not isinstance(search_title, str):
                            search_title = str(search_title)
                            
                        search_title_lower = search_title.lower()
                        if title_lower in search_title_lower or search_title_lower in title_lower:
                            chapter_idx = i
                            break
                
                if chapter_idx >= 0 and chapter_idx < len(child_node.report.chapters):
                    chapter = child_node.report.chapters[chapter_idx]
                    
                    # æ¸…ç©ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
                    chapter.visualization_tasks = []
                    
                    # æ·»åŠ ä»»åŠ¡
                    for task in tasks:
                        task_id = task.get("task_id", "")
                        description = task.get("task_description", "")
                        chart_type = task.get("chart_type", ["Bar Chart"])
                        
                        # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                        task_obj = {
                            "task_id": task_id,
                            "task_description": description,
                            "chart_type": chart_type,
                            "status": "pending",  # æ·»åŠ çŠ¶æ€å­—æ®µ
                            "visualization_success": False  # æ·»åŠ å¯è§†åŒ–æˆåŠŸæ ‡å¿—
                        }
                        
                        # æ·»åŠ åˆ°ç« èŠ‚çš„ä»»åŠ¡åˆ—è¡¨
                        if not hasattr(chapter, 'visualization_tasks'):
                            chapter.visualization_tasks = []
                        chapter.visualization_tasks.append(task_obj)
                        
                        # æ‰“å°ä»»åŠ¡çŠ¶æ€
                        print(f"   - ä»»åŠ¡ID: '{task_id}'")
                        print(f"   - ä»»åŠ¡æè¿°: '{description}'")
                        print(f"   - å›¾è¡¨ç±»å‹: {chart_type}")
                        print(f"   - çŠ¶æ€: {task_obj.get('status')}")
                    
                    # è®°å½•å·²åˆ†é…ä»»åŠ¡çš„ç« èŠ‚
                    chapters_with_tasks.add(chapter_idx)
                    
                    # æ‰“å°è°ƒè¯•ä¿¡æ¯
                    print(f"âœ… ä¸ºç« èŠ‚ {chapter_idx+1} ({chapter.title}) ç”Ÿæˆäº† {len(tasks)} ä¸ªå¯è§†åŒ–ä»»åŠ¡")
                else:
                    print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é…çš„ç« èŠ‚: {title_text}")
            
            # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚æ˜¯å¦éƒ½æœ‰ä»»åŠ¡
            all_chapters_have_tasks = True
            for i, chapter in enumerate(child_node.report.chapters):
                if i not in chapters_with_tasks:
                    print(f"âš ï¸ ç« èŠ‚ {i+1} ({chapter.title}) æ²¡æœ‰ä»»åŠ¡")
                    all_chapters_have_tasks = False
            
            # åªæœ‰å½“æ‰€æœ‰ç« èŠ‚éƒ½æœ‰ä»»åŠ¡æ—¶ï¼Œæ‰è¿”å›è¿™ä¸ªèŠ‚ç‚¹
            if all_chapters_have_tasks:
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.a2
                print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„ä»»åŠ¡æ–¹æ¡ˆ")
                return [child_node]
            else:
                print(f"âš ï¸ èšç±» {cluster_id} çš„ä»»åŠ¡æ–¹æ¡ˆä¸å®Œæ•´ï¼Œè·³è¿‡")
                return None
                
        except Exception as e:
            print(f"âŒ åº”ç”¨ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šç§ä»»åŠ¡æ–¹æ¡ˆ"""
        if self.use_unified_framework:
            return unified_generation_framework(
                node=node,
                action=self,
                llm_kwargs=llm_kwargs,
                action_type="tasks",
                prompt_generator=self.generate_tasks_prompt,
                node_applier=self.apply_tasks,
                n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“
            )
        else:
            # ä½¿ç”¨åŸæœ‰æ–¹æ³•çš„å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            children_nodes = []
        
        try:
            # è·å–æ•°æ®é›†ä¿¡æ¯
            data_context = node.report.data_context
            
            # ä¸ºæ¯ä¸ªç« èŠ‚æ–¹æ¡ˆåˆ›å»º2-3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå­èŠ‚ç‚¹
            # åˆ›å»ºåŸºç¡€èŠ‚ç‚¹çš„å¤šä¸ªå‰¯æœ¬
            for variant_idx in range(3):  # ç”Ÿæˆ3ä¸ªä¸åŒçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # ç”Ÿæˆ LLM æç¤ºè¯
                prompt_text = get_prompt("Chapters2Tasks", {
                    "QUERY": node.original_query,
                    "DATA_CONTEXT": data_context,
                    "CHAPTERS": json.dumps([{
                        "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{i+1}")
                    } for i, chapter in enumerate(child_node.report.chapters)], ensure_ascii=False)
                })
                
                # ä½¿ç”¨ä¸åŒçš„æ¸©åº¦ï¼Œä»¥è·å¾—æ›´å¤šæ ·åŒ–çš„ä»»åŠ¡æ–¹æ¡ˆ
                llm_kwargs_temp = llm_kwargs.copy()
                llm_kwargs_temp['temperature'] = 0.3 + variant_idx * 0.25  # 0.3, 0.55, 0.8
                
                print(f"\nğŸ”„ ç”Ÿæˆä»»åŠ¡æ–¹æ¡ˆå˜ä½“ {variant_idx+1}/3 (æ¸©åº¦: {llm_kwargs_temp['temperature']})")
                
                responses = call_openai(prompt_text, **llm_kwargs_temp)
                if not responses:
                    print(f"âŒ å˜ä½“ {variant_idx+1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                    continue
                
                response_text = responses[0]
                
                try:
                    # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œæå– JSON éƒ¨åˆ†
                    json_text = self.extract_json_from_text(response_text)
                    print(f"åŸå§‹å“åº”: {json_text}")
                    
                    # è§£æ JSON
                    response_json = json.loads(json_text)
                    
                    # å¤„ç†æ¯ä¸ªç« èŠ‚çš„å¯è§†åŒ–ä»»åŠ¡
                    if "chapters" in response_json:
                        # åˆ›å»ºç« èŠ‚æ ‡é¢˜åˆ°ç´¢å¼•çš„æ˜ å°„
                        chapter_title_to_index = {}
                        for i, chapter in enumerate(child_node.report.chapters):
                            # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                            if isinstance(chapter, dict):
                                # å¦‚æœç« èŠ‚æ˜¯å­—å…¸ç±»å‹
                                if 'title' in chapter:
                                    # å¦‚æœç« èŠ‚å­—å…¸æœ‰'title'é”®
                                    if isinstance(chapter['title'], dict):
                                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼ä¹Ÿæ˜¯å­—å…¸
                                        title_text = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                    else:
                                        # å¦‚æœ'title'é”®å¯¹åº”çš„å€¼æ˜¯å­—ç¬¦ä¸²
                                        title_text = chapter['title']
                                else:
                                    # å¦‚æœç« èŠ‚å­—å…¸æ²¡æœ‰'title'é”®ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                    title_text = f"ç« èŠ‚{i+1}"
                            else:
                                # å¦‚æœç« èŠ‚æ˜¯å¯¹è±¡ç±»å‹
                                title_attr = getattr(chapter, 'title', None)
                                if isinstance(title_attr, dict):
                                    # å¦‚æœtitleå±æ€§æ˜¯å­—å…¸
                                    title_text = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                                else:
                                    # å¦‚æœtitleå±æ€§æ˜¯å­—ç¬¦ä¸²æˆ–å…¶ä»–ç±»å‹
                                    title_text = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                            
                            # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if not isinstance(title_text, str):
                                title_text = str(title_text)
                                
                            # å­˜å‚¨å°å†™æ ‡é¢˜æ–‡æœ¬åˆ°ç´¢å¼•çš„æ˜ å°„
                            chapter_title_to_index[title_text.lower()] = i
                        
                        # å¤„ç†æ¯ä¸ªç« èŠ‚
                        for chapter_info in response_json["chapters"]:
                            raw_title = chapter_info.get("title", "")
                            # è°ƒè¯•æ‰“å°
                            #print(f"DEBUG - è·å–åˆ°çš„ title ç±»å‹: {type(raw_title)}")
                            #print(f"DEBUG - title å†…å®¹: {raw_title}")
                            
                            # å®‰å…¨è·å–æ ‡é¢˜æ–‡æœ¬
                            if isinstance(raw_title, dict):
                                # å¦‚æœæ˜¯å­—å…¸ï¼Œå°è¯•æå–æ–‡æœ¬
                                title_text = raw_title.get('title', '') or raw_title.get('text', '')
                            else:
                                # å¦‚æœä¸æ˜¯å­—å…¸ï¼Œç›´æ¥ä½¿ç”¨
                                title_text = raw_title
                            
                            # ç¡®ä¿title_textæ˜¯å­—ç¬¦ä¸²ç±»å‹
                            if not isinstance(title_text, str):
                                title_text = str(title_text) if title_text is not None else ""
                                
                            tasks = chapter_info.get("tasks", [])
                            
                            # æŸ¥æ‰¾åŒ¹é…çš„ç« èŠ‚
                            chapter_idx = -1
                            title_lower = title_text.lower()  # ç°åœ¨å¯ä»¥å®‰å…¨è°ƒç”¨lower()
                            
                            # ç²¾ç¡®åŒ¹é…
                            if title_lower in chapter_title_to_index:
                                chapter_idx = chapter_title_to_index[title_lower]
                            else:
                                # æ¨¡ç³ŠåŒ¹é…
                                for i, chapter in enumerate(child_node.report.chapters):
                                    # å®‰å…¨è·å–ç« èŠ‚æ ‡é¢˜
                                    if isinstance(chapter, dict):
                                        if 'title' in chapter:
                                            if isinstance(chapter['title'], dict):
                                                search_title = chapter['title'].get('title', '') or chapter['title'].get('text', f"ç« èŠ‚{i+1}")
                                            else:
                                                search_title = chapter['title']
                                        else:
                                            search_title = f"ç« èŠ‚{i+1}"
                                    else:
                                        title_attr = getattr(chapter, 'title', None)
                                        if isinstance(title_attr, dict):
                                            search_title = title_attr.get('title', '') or title_attr.get('text', f"ç« èŠ‚{i+1}")
                                        else:
                                            search_title = title_attr if title_attr else f"ç« èŠ‚{i+1}"
                                    
                                    # ç¡®ä¿search_titleæ˜¯å­—ç¬¦ä¸²ç±»å‹
                                    if not isinstance(search_title, str):
                                        search_title = str(search_title)
                                        
                                    search_title_lower = search_title.lower()
                                    if title_lower in search_title_lower or search_title_lower in title_lower:
                                        chapter_idx = i
                                        break
                            
                            if chapter_idx >= 0 and chapter_idx < len(child_node.report.chapters):
                                chapter = child_node.report.chapters[chapter_idx]
                                
                                # æ¸…ç©ºç°æœ‰ä»»åŠ¡åˆ—è¡¨
                                chapter.visualization_tasks = []
                                
                                # æ·»åŠ ä»»åŠ¡
                                for task in tasks:
                                    task_id = task.get("task_id", "")
                                    description = task.get("task_description", "")
                                    chart_type = task.get("chart_type", ["Bar Chart"])
                                    
                                    # åˆ›å»ºä»»åŠ¡å¯¹è±¡
                                    task_obj = {
                                        "task_id": task_id,
                                        "task_description": description,
                                        "chart_type": chart_type,
                                        "status": "pending",  # æ·»åŠ çŠ¶æ€å­—æ®µ
                                        "visualization_success": False  # æ·»åŠ å¯è§†åŒ–æˆåŠŸæ ‡å¿—
                                    }
                                    
                                    # æ·»åŠ åˆ°ç« èŠ‚çš„ä»»åŠ¡åˆ—è¡¨
                                    if not hasattr(chapter, 'visualization_tasks'):
                                        chapter.visualization_tasks = []
                                    chapter.visualization_tasks.append(task_obj)
                                    
                                    # æ‰“å°ä»»åŠ¡çŠ¶æ€
                                    print(f"   - ä»»åŠ¡ID: '{task_id}'")
                                    print(f"   - ä»»åŠ¡æè¿°: '{description}'")
                                    print(f"   - å›¾è¡¨ç±»å‹: {chart_type}")
                                    print(f"   - çŠ¶æ€: {task_obj.get('status')}")
                                
                                # æ‰“å°è°ƒè¯•ä¿¡æ¯
                                print(f"âœ… å˜ä½“ {variant_idx+1} - ç« èŠ‚ {chapter_idx+1} ({chapter.title}) ç”Ÿæˆäº† {len(tasks)} ä¸ªå¯è§†åŒ–ä»»åŠ¡")
                                print(f"å½“å‰ç« èŠ‚ä»»åŠ¡åˆ—è¡¨: {[t.get('task_id') for t in chapter.visualization_tasks]}")
                            else:
                                print(f"âŒ æ‰¾ä¸åˆ°åŒ¹é…çš„ç« èŠ‚: {title_text}")
                        
                        # æ£€æŸ¥æ‰€æœ‰ç« èŠ‚æ˜¯å¦éƒ½æœ‰ä»»åŠ¡
                        all_chapters_have_tasks = True
                        for i, chapter in enumerate(child_node.report.chapters):
                            if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                                print(f"âš ï¸ å˜ä½“ {variant_idx+1} - ç« èŠ‚ {i+1} ({chapter.title}) æ²¡æœ‰ä»»åŠ¡")
                                all_chapters_have_tasks = False
                            else:
                                print(f"âœ“ å˜ä½“ {variant_idx+1} - ç« èŠ‚ {i+1} ({chapter.title}) æœ‰ {len(chapter.visualization_tasks)} ä¸ªä»»åŠ¡")
                        
                        # åªæœ‰å½“æ‰€æœ‰ç« èŠ‚éƒ½æœ‰ä»»åŠ¡æ—¶ï¼Œæ‰æ·»åŠ è¿™ä¸ªå˜ä½“
                        if all_chapters_have_tasks:
                            children_nodes.append(child_node)
                            print(f"âœ… ä»»åŠ¡æ–¹æ¡ˆå˜ä½“ {variant_idx+1} å·²æ·»åŠ åˆ°å€™é€‰åˆ—è¡¨")
                    
                except json.JSONDecodeError as e:
                    print(f"âŒ JSON è§£æé”™è¯¯: {str(e)}")
                    print(f"âš ï¸ å˜ä½“ {variant_idx+1} æ— æ³•è§£æ JSONï¼Œè·³è¿‡")
            
            # å¦‚æœæ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„æ–¹æ¡ˆï¼Œè¿”å›åŸå§‹èŠ‚ç‚¹çš„å‰¯æœ¬
            if not children_nodes:
                print("âš ï¸ æ²¡æœ‰ç”Ÿæˆä»»ä½•æœ‰æ•ˆçš„ä»»åŠ¡æ–¹æ¡ˆï¼Œè¿”å›åŸå§‹èŠ‚ç‚¹")
                fallback_node = copy.deepcopy(node)
                fallback_node.parent_node = node
                fallback_node.parent_action = self
                fallback_node.depth = node.depth + 1
                children_nodes.append(fallback_node)
            
            print(f"ğŸ”¢ æ€»å…±ç”Ÿæˆäº† {len(children_nodes)} ä¸ªæœ‰æ•ˆçš„ä»»åŠ¡æ–¹æ¡ˆå˜ä½“")
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆå¯è§†åŒ–ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            # ç¡®ä¿å³ä½¿å‡ºé”™ä¹Ÿè¿”å›è‡³å°‘ä¸€ä¸ªå­èŠ‚ç‚¹
            if not children_nodes:
                fallback_node = copy.deepcopy(node)
                fallback_node.parent_node = node
                fallback_node.parent_action = self
                fallback_node.depth = node.depth + 1
                children_nodes.append(fallback_node)
        
        # ä¸ºæ‰€æœ‰ç”Ÿæˆçš„èŠ‚ç‚¹è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
        for child_node in children_nodes:
            child_node.node_type = ReportGenerationState.a2
        
        return children_nodes

    def extract_json_from_text(self, response_text):
        """ä»æ–‡æœ¬ä¸­æå– JSON éƒ¨åˆ†"""
        try:
            # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå“åº”
            json.loads(response_text)
            return response_text
        except:
            # å¦‚æœç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå– JSON éƒ¨åˆ†
            import re
            
            # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
            response_text = re.sub(r'^```(?:json)?\s*', '', response_text)
            response_text = re.sub(r'\s*```$', '', response_text)
            
            # æŸ¥æ‰¾ JSON å¯¹è±¡
            json_pattern = r'\{.*\}'
            json_match = re.search(json_pattern, response_text, re.DOTALL)
            
            if json_match:
                return json_match.group(0)
            
            return response_text



class Tasks2Charts(DataStorytellingAction):
    def __init__(self):
        super().__init__("A3", "ç”Ÿæˆå¯è§†åŒ–")
        # åˆå§‹åŒ–å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·
        try:
            from storyteller.algorithm.utils.ChartSimilarity import ChartSimilarity
            self.similarity_tool = ChartSimilarity()
            self.similarity_threshold = 0.90  # ç›¸ä¼¼åº¦é˜ˆå€¼
            self.use_similarity_check = self.similarity_tool.initialized
            print("âœ… å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"âš ï¸ å›¾è¡¨ç›¸ä¼¼åº¦æ£€æµ‹å·¥å…·åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            self.use_similarity_check = False
            
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = self
        child_node.depth = node.depth + 1

        try:
            # é€’å¢è¿­ä»£å· - ç¡®ä¿æ¯æ¬¡åˆ›å»ºæ–°èŠ‚ç‚¹æ—¶è¿­ä»£å·åŠ 1
            #child_node.report.current_iteration += 1
            current_iteration = child_node.report.current_iteration
            print(f"âœ… å½“å‰è¿­ä»£å·: {current_iteration}")
            
            # ç¡®å®šå½“å‰è¿­ä»£å·å’Œä¿å­˜è·¯å¾„
            iteration_dir = os.path.join("storyteller", "output", "iterations", f"iteration_{current_iteration}")
            os.makedirs(iteration_dir, exist_ok=True)
            charts_dir = os.path.join(iteration_dir, "charts")
            os.makedirs(charts_dir, exist_ok=True)
          
            # åˆ›å»ºä¸€ä¸ªé¢å¤–çš„ JSON é…ç½®ç›®å½•
            json_dir = os.path.join(iteration_dir, "chart_configs")
            os.makedirs(json_dir, exist_ok=True)
             
            # è·å–æ•°æ®é›†
            dataset_path = node.report.dataset_path
            df = pd.read_csv(dataset_path)

            # éå†æ‰€æœ‰ç« èŠ‚
            for chapter_idx, chapter in enumerate(child_node.report.chapters):
                print(f"\nğŸ“Š æ­£åœ¨å¤„ç†ç¬¬ {chapter_idx + 1} ç« ...")
                print(f"ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
                print(f"ç« èŠ‚çš„å¯è§†åŒ–ä»»åŠ¡æ•°é‡: {len(getattr(chapter, 'visualization_tasks', []))}")
                
                # åˆå§‹åŒ–ç« èŠ‚å›¾è¡¨åˆ—è¡¨ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                if not hasattr(chapter, 'charts'):
                    chapter.charts = []
                
                # æ”¶é›†æ‰€æœ‰ç« èŠ‚çš„å›¾è¡¨ç”¨äºç›¸ä¼¼åº¦æ£€æŸ¥
                all_charts = []
                for ch in child_node.report.chapters:
                    if hasattr(ch, 'charts'):
                        all_charts.extend(ch.charts)
                
                # éå†ç« èŠ‚ä¸­çš„æ‰€æœ‰å¯è§†åŒ–ä»»åŠ¡
                for task in chapter.visualization_tasks:
                    print(f"\nğŸ” å¤„ç†ä»»åŠ¡:")
                    print(f"- ä»»åŠ¡ID: {task.get('task_id', '')}")
                    print(f"- ä»»åŠ¡æè¿°: {task.get('task_description', '')}")
                    print(f"- å›¾è¡¨ç±»å‹: {task.get('chart_type', ['Bar Chart'])[0]}")
                    
                    task_id = task.get('task_id', "")
                    description = task.get('task_description')
                    chart_type = task.get('chart_type', ["Bar Chart"])[0]

                    # ä½¿ç”¨ä»»åŠ¡IDä½œä¸ºæ–‡ä»¶åï¼Œå¦‚æœä¸ºç©ºåˆ™ä½¿ç”¨ä»»åŠ¡æè¿°
                    file_name = task_id if task_id else description
                    if not file_name:
                        file_name = f"chart_{chapter_idx}_{len(chapter.charts)}"
                    # æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦
                    file_name = re.sub(r'[<>:"/\\|?*]', '_', file_name)
                    chart_path = os.path.join(charts_dir, f"{file_name}.png")

                    
                    from lida.datamodel import Goal, Summary
                    from lida.components.manager import Manager
                    # åˆ›å»º Goal å¯¹è±¡ - ä½¿ç”¨ description æ›¿ä»£ task_name
                    #goal = Goal(question=task_id, visualization=chart_type, rationale=description) !!åŸå…ˆæ˜¯è¿™ä¸ª
                    goal = Goal(question=task_id, visualization=description, rationale=description)
                    # åˆ›å»º Summary å¯¹è±¡
                    # è¯»å–æ•°æ®æ‘˜è¦ JSON æ–‡ä»¶
                    data_summary = {}
                    json_path = os.path.join("storyteller", "dataset", "data_context.json")
                    print(f"å°è¯•è¯»å–æ•°æ®æ‘˜è¦ JSON: {json_path}")
                    
                    try:
                        with open(json_path, 'r', encoding='utf-8') as f:
                            data_summary = json.load(f)
                        print("âœ“ æˆåŠŸè¯»å–æ•°æ®æ‘˜è¦ JSON")
                    except Exception as e:
                        print(f"âœ— è¯»å–æ•°æ®æ‘˜è¦ JSON å¤±è´¥: {str(e)}")
                        # å¦‚æœæ— æ³•è¯»å– JSON æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                        data_summary = {
                            "name": node.report.original_query,
                            "dataset_description": node.report.data_context,
                            "fields_info": {col: {"dtype": str(dtype)} for col, dtype in zip(df.columns, df.dtypes)}
                        }

                    # åˆ›å»º Summary å¯¹è±¡ï¼Œä½¿ç”¨ä» JSON æ–‡ä»¶ä¸­æå–çš„ä¿¡æ¯
                    summary = Summary(
                        name=data_summary.get("name", "è´­ç‰©æ•°æ®åˆ†æ"),
                        file_name=dataset_path,
                        dataset_description=str(data_summary.get("dataset_description", "è´­ç‰©æ•°æ®é›†")),
                        field_names=list(data_summary.get("fields_info", {}).keys()) if "fields_info" in data_summary else df.columns.tolist(),
                        fields=[info.get("dtype", "unknown") for info in data_summary.get("fields_info", {}).values()] if "fields_info" in data_summary else [str(dtype) for dtype in df.dtypes.tolist()]
                    )
                    
                    # åˆ›å»ºè‡ªå®šä¹‰çš„æ–‡æœ¬ç”Ÿæˆå™¨
                    #text_gen = llm(provider="openai", model="gpt-4-32k")
                    text_gen = llm(
                        provider="openai", 
                        model="gpt-4-32k"
                    )

                    # åˆ›å»º LIDA ç®¡ç†å™¨
                    manager = Manager(text_gen=text_gen)

                    # ç”Ÿæˆå¯è§†åŒ–
                    print(f"æ­£åœ¨ä¸ºä»»åŠ¡ '{description}' ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
                    visualization = manager.visualize(summary, goal, library="matplotlib")

                    # å¤„ç†å¯è§†åŒ–ç»“æœ
                    if isinstance(visualization, list) and len(visualization) > 0:
                        visualization = visualization[0]

                    if hasattr(visualization, 'status') and visualization.status:
                        print("âœ“ æˆåŠŸç”Ÿæˆå¯è§†åŒ–ç»“æœ")

                        # ä¿å­˜å›¾è¡¨
                        if hasattr(visualization, 'savefig'):
                            visualization.savefig(chart_path)
                            print(f"âœ“ å›¾è¡¨å·²ä¿å­˜åˆ°: {chart_path}")
                                                   
                            # é¢å¤–ç”Ÿæˆ Chart.js é…ç½® JSON æ–‡ä»¶
                            try:
                                # æå–å›¾è¡¨ä½¿ç”¨çš„å®é™…æ•°æ®
                                # chart_data = self._extract_actual_data(visualization)
                                chart_config = self._extract_chart_config(visualization, task_id, description, df, use_antv=True)
                                
                                # å°†æå–çš„å®é™…æ•°æ®æ·»åŠ åˆ°é…ç½®ä¸­
                                #if chart_data:
                                #    chart_config['data'] = chart_data
                                #    print(f"âœ“ æˆåŠŸæå–å›¾è¡¨å®é™…æ•°æ®")
                                
                                # è·å– JSON é…ç½®ç›®å½•
                                json_dir = os.path.join(os.path.dirname(charts_dir), "chart_configs")
                                os.makedirs(json_dir, exist_ok=True)
                                
                                # ä¿å­˜ JSON é…ç½®
                                json_file_name = f"{file_name}.json"
                                json_path = os.path.join(json_dir, json_file_name)
                                with open(json_path, "w", encoding="utf-8") as f:
                                    json.dump(chart_config, f, ensure_ascii=False, indent=2)
                                print(f"âœ“ å›¾è¡¨é…ç½® JSON å·²ä¿å­˜åˆ°: {json_path}")
                            except Exception as e:
                                print(f"âš ï¸ ä¿å­˜å›¾è¡¨é…ç½® JSON æ—¶å‡ºé”™: {str(e)}")
                                traceback.print_exc()
                                json_path = None
                                
                            # é¢å¤–ä¿å­˜å›¾è¡¨æ•°æ®ä¸ºCSVï¼Œä»¥ä¾¿åç»­åˆ†æ
                            try:
                                csv_dir = os.path.join(os.path.dirname(charts_dir), "chart_data")
                                os.makedirs(csv_dir, exist_ok=True)
                                csv_file_name = f"{file_name}.csv"
                                csv_path = os.path.join(csv_dir, csv_file_name)
                                
                                # å°è¯•ä»å¯è§†åŒ–å¯¹è±¡ä¸­æå–å®é™…ä½¿ç”¨çš„æ•°æ®
                                if hasattr(visualization, '_data') and isinstance(visualization._data, pd.DataFrame):
                                    visualization._data.to_csv(csv_path, index=False)
                                    print(f"âœ“ å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                elif hasattr(visualization, 'data') and isinstance(visualization.data, pd.DataFrame):
                                    visualization.data.to_csv(csv_path, index=False)
                                    print(f"âœ“ å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                else:
                                    # å°è¯•ä»ä»£ç ä¸­æå–å’Œåˆ†ææ•°æ®
                                    last_df_var = self._find_last_dataframe_variable(visualization.code)
                                    if last_df_var:
                                        # è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®ä»£ç ä¸­çš„å˜é‡
                                        # æ‰€ä»¥åªèƒ½ä¿å­˜ä¸€ä¸ªæŒ‡ç¤ºæ–‡ä»¶ï¼Œæç¤ºchart_configä½¿ç”¨ä»€ä¹ˆå˜é‡
                                        with open(csv_path + ".info", "w") as f:
                                            f.write(f"Last DataFrame variable: {last_df_var}")
                                        print(f"âœ“ å›¾è¡¨æ•°æ®å˜é‡ä¿¡æ¯å·²ä¿å­˜: {last_df_var}")
                            except Exception as e:
                                print(f"âš ï¸ ä¿å­˜å›¾è¡¨æ•°æ® CSV æ—¶å‡ºé”™: {str(e)}")
                                traceback.print_exc()
        
                            # æ£€æŸ¥å›¾è¡¨ç›¸ä¼¼åº¦
                            if self.use_similarity_check and all_charts:
                                # æ”¶é›†å·²æœ‰å›¾è¡¨çš„è·¯å¾„åˆ—è¡¨
                                existing_chart_paths = []
                                for chart in all_charts:
                                    if hasattr(chart, 'url') and chart.url:
                                        existing_chart_paths.append(chart.url)
                                
                                if existing_chart_paths:
                                    # ä½¿ç”¨batch_compareè®¡ç®—ç›¸ä¼¼åº¦
                                    is_too_similar, max_similarity, similar_chart_path, all_similarities = self.similarity_tool.batch_compare(
                                        chart_path, existing_chart_paths, self.similarity_threshold
                                    )
                                    
                                    if is_too_similar:
                                        # æ‰¾åˆ°æœ€ç›¸ä¼¼çš„å›¾è¡¨å¯¹è±¡
                                        similar_chart = None
                                        for chart in all_charts:
                                            if hasattr(chart, 'url') and chart.url == similar_chart_path:
                                                similar_chart = chart
                                                break
                                        
                                        similar_task_id = getattr(similar_chart, 'task_id', 'æœªçŸ¥ä»»åŠ¡') if similar_chart else 'æœªçŸ¥ä»»åŠ¡'
                                        
                                        print(f"âš ï¸ è­¦å‘Š: ç”Ÿæˆçš„å›¾è¡¨ä¸ç°æœ‰å›¾è¡¨ç›¸ä¼¼åº¦è¿‡é«˜ ({max_similarity:.4f})")
                                        print(f"   - ç›¸ä¼¼å›¾è¡¨: {similar_task_id}")
                                        
                                        # åˆ›å»ºsamechartæ–‡ä»¶å¤¹
                                        samechart_dir = os.path.join(charts_dir, "samechart")
                                        os.makedirs(samechart_dir, exist_ok=True)
                                        
                                        # ç§»åŠ¨ç›¸ä¼¼çš„å›¾è¡¨åˆ°samechartæ–‡ä»¶å¤¹
                                        samechart_path = os.path.join(samechart_dir, f"{file_name}.png")
                                        
                                        try:
                                            import shutil
                                            # ç§»åŠ¨å›¾è¡¨åˆ°samechartç›®å½•(è€Œéå¤åˆ¶)
                                            shutil.move(chart_path, samechart_path)
                                            print(f"âœ“ ç›¸ä¼¼å›¾è¡¨å·²ç§»åŠ¨åˆ°: {samechart_path}")
                                            
                                            # åœ¨æ§åˆ¶å°è¾“å‡ºç›¸ä¼¼åº¦ä¿¡æ¯
                                            print(f"ğŸ“Š å›¾è¡¨ç›¸ä¼¼åº¦ä¿¡æ¯:")
                                            print(f"   - ç›¸ä¼¼åº¦å€¼: {max_similarity:.4f}")
                                            print(f"   - ç›¸ä¼¼å›¾è¡¨ä»»åŠ¡: {similar_task_id}")
                                            print(f"   - å½“å‰ä»»åŠ¡: {task_id}")
                                            
                                            # æ ‡è®°ä»»åŠ¡ä¸ºå·²å®Œæˆä½†å›¾è¡¨è¢«è·³è¿‡
                                            for vis_task in chapter.visualization_tasks:
                                                if vis_task.get('task_id') == task_id:
                                                    vis_task['visualization_success'] = False
                                                    vis_task['skipped_due_to_similarity'] = True
                                                    print(f"âš ï¸ ä»»åŠ¡ '{task_id}' å› å›¾è¡¨ç›¸ä¼¼åº¦è¿‡é«˜è€Œè¢«è·³è¿‡")
                                                    break
                                                    
                                            # è·³è¿‡å½“å‰ä»»åŠ¡çš„åç»­å¤„ç†
                                            continue
                                            
                                        except Exception as e:
                                            print(f"âš ï¸ ç§»åŠ¨ç›¸ä¼¼å›¾è¡¨æ—¶å‡ºé”™: {str(e)}")
                                            # å¦‚æœç§»åŠ¨å¤±è´¥ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹è·¯å¾„

                        # åˆ›å»ºå›¾è¡¨å¯¹è±¡
                        print(f"\nğŸ“Š åˆ›å»ºå›¾è¡¨å¯¹è±¡:")
                        print(f"- å›¾è¡¨è·¯å¾„: {chart_path}")
                        print(f"- å›¾è¡¨ç±»å‹: {chart_type}")
                        print(f"- ä»»åŠ¡ID: {task_id}")
                        
                        chart = Chart(
                            url=chart_path,
                            caption="",  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºåˆå§‹è¯´æ˜
                            chart_type=chart_type,
                            task_id=task_id  # task_id å®é™…ä¸Šå°±æ˜¯ä»»åŠ¡æè¿°
                        )
                        
                        # å­˜å‚¨å¯è§†åŒ–ä»£ç ï¼Œä»¥ä¾¿åç»­ä¿®æ”¹
                        if hasattr(visualization, 'code'):
                            chart.code = visualization.code
                        
                        # æ·»åŠ å›¾è¡¨åˆ°ç« èŠ‚
                        if not hasattr(chapter, 'charts'):
                            chapter.charts = []
                            print("åˆå§‹åŒ–ç« èŠ‚çš„å›¾è¡¨åˆ—è¡¨")
                        
                        chapter.charts.append(chart)
                        # æ›´æ–°æ‰€æœ‰å›¾è¡¨åˆ—è¡¨
                        all_charts.append(chart)
                        print(f"âœ“ å›¾è¡¨å·²æ·»åŠ åˆ°ç« èŠ‚ï¼Œå½“å‰ç« èŠ‚å›¾è¡¨æ•°é‡: {len(chapter.charts)}")
                        
                        # å¦‚æœå¤„ç†æˆåŠŸï¼Œä¹Ÿæ ‡è®°ä¸ºå·²å®Œæˆ
                        for vis_task in chapter.visualization_tasks:
                            if vis_task.get('task_id') == task_id:
                                vis_task['visualization_success'] = True
                                print(f"âœ… ä»»åŠ¡ '{task_id}' å·²æˆåŠŸå®Œæˆ")
                                break
                    else:
                        print("âœ— ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨å¤±è´¥")
                        # å³ä½¿å¤±è´¥ä¹Ÿæ ‡è®°ä¸ºå®Œæˆï¼Œé¿å…æ— é™å¾ªç¯
                        for vis_task in chapter.visualization_tasks:
                            if vis_task.get('task_id') == task_id:
                                # ç¡®ä¿åˆå§‹åŒ– visualization_success å­—æ®µ
                                vis_task['visualization_success'] = False
                                
                                # æ–°å¢ï¼šä¿å­˜å¤±è´¥å›¾è¡¨çš„ä»£ç ï¼ˆå¦‚æœæœ‰ï¼‰
                                if hasattr(visualization, 'code'):
                                    # åˆ›å»ºå¤±è´¥å›¾è¡¨ç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
                                    failed_code_dir = os.path.join(charts_dir, "failed_code")
                                    os.makedirs(failed_code_dir, exist_ok=True)
                                    
                                    # ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç åˆ°æ–‡ä»¶
                                    code_file_path = os.path.join(failed_code_dir, f"{file_name}_failed.py")
                                    try:
                                        with open(code_file_path, 'w', encoding='utf-8') as f:
                                            f.write(visualization.code)
                                        print(f"âœ… å·²ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç åˆ°: {code_file_path}")
                                        
                                        # åœ¨ä»»åŠ¡ä¸­è®°å½•ä»£ç è·¯å¾„
                                        vis_task['failed_code_path'] = code_file_path
                                    except Exception as e:
                                        print(f"âŒ ä¿å­˜å¤±è´¥å›¾è¡¨ä»£ç æ—¶å‡ºé”™: {str(e)}")
                                
                                print(f"âš ï¸ ä»»åŠ¡ '{description}' è™½ç„¶å¤±è´¥ä½†å·²æ ‡è®°ä¸ºå·²å®Œæˆï¼Œé¿å…æ— é™å¾ªç¯")
                                break
            # è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a3
            return [child_node]

        except Exception as e:
            print(f"âŒ å¤„ç†èŠ‚ç‚¹æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            # ç¡®ä¿å³ä½¿å¼‚å¸¸ä¹Ÿè®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a3
            return [child_node]


    def _extract_chart_config(self, visualization, task_id, description, df, use_antv=False):
        """ä»å¯è§†åŒ–ä»£ç ä¸­æå–å›¾è¡¨é…ç½®
        
        å‚æ•°:
            visualization: åŒ…å«å¯è§†åŒ–ä»£ç çš„å­—å…¸
            task_id: ä»»åŠ¡ID
            description: ä»»åŠ¡æè¿°
            df: æ•°æ®DataFrame
            use_antv: æ˜¯å¦ä½¿ç”¨AntV G2é…ç½®ï¼ˆé»˜è®¤ä¸ºFalseï¼Œä½¿ç”¨Chart.jsï¼‰
            
        è¿”å›:
            å›¾è¡¨é…ç½®å­—å…¸
        """
        chart_config = {}
        
        try:
            # ç¡®ä¿æœ‰å¯è§†åŒ–ä»£ç 
            if not hasattr(visualization, 'code'):
                raise ValueError("å¯è§†åŒ–å¯¹è±¡æ²¡æœ‰ä»£ç å±æ€§")
            
            code = visualization.code
            print("\nğŸ“‹ åˆ†æå¯è§†åŒ–ä»£ç :")
            print("-" * 50)
            print(code)
            print("-" * 50)
            
            # æ‰“å°DataFrameä¿¡æ¯ï¼Œå¸®åŠ©ç†è§£æ•°æ®ç»“æ„
            print("\nğŸ“Š DataFrameä¿¡æ¯:")
            print(f"å½¢çŠ¶: {df.shape}")
            print(f"åˆ—å: {df.columns.tolist()}")
            print(f"æ•°æ®ç±»å‹:\n{df.dtypes}")
            print("\nå‰5è¡Œæ•°æ®:")
            print(df.head(5).to_string())
            print("-" * 50)
            
            # å¯¼å…¥ASTè§£æå™¨å’Œé…ç½®è½¬æ¢å‡½æ•°
            if use_antv:
                from storyteller.algorithm.utils.chart_config_extractor import ChartConfigExtractor, convert_to_antv_config as convert_config
                config_type = "AntV G2"
            else:
                from storyteller.algorithm.utils.chart_config_extractor import ChartConfigExtractor, convert_to_chartjs_config as convert_config
                config_type = "Chart.js"
            
            # åˆ›å»ºæå–å™¨å¹¶è§£æä»£ç 
            extractor = ChartConfigExtractor()
            ast_config = extractor.extract_from_code(code)
            
            print(f"\nğŸ” ASTè§£æç»“æœ (ç”¨äº{config_type}):")
            for key, value in ast_config.items():
                print(f"- {key}: {value}")
            
            # å¦‚æœè§£æå¤±è´¥ï¼Œå›é€€åˆ°åŸæœ‰çš„é™æ€åˆ†æ
            if "error" in ast_config:
                print(f"âš ï¸ ASTè§£æå¤±è´¥ï¼Œå›é€€åˆ°é™æ€åˆ†æ: {ast_config['error']}")
                return self._extract_chart_config_fallback(visualization, task_id, description, df, use_antv)
            
            # æå–ASTé…ç½®å¹¶ä¿®æ­£å­—æ®µä¿¡æ¯
            if "error" not in ast_config:
                # ä½¿ç”¨extractorå®ä¾‹ç›´æ¥è°ƒç”¨resolve_chart_data
                try:
                    chart_data = extractor.resolve_chart_data(df)
                    print(f"âœ“ ä½¿ç”¨ASTè§£æå™¨çš„resolve_chart_dataæ–¹æ³•ç”Ÿæˆå›¾è¡¨æ•°æ®")
                    # ä¿å­˜åŸå§‹ä»£ç ä»¥ä¾¿åç»­å¤„ç†
                    ast_config["code"] = code
                except Exception as e:
                    print(f"âš ï¸ ä½¿ç”¨resolve_chart_dataæ–¹æ³•æ—¶å‡ºé”™: {e}")
                    chart_data = None
            
            # è½¬æ¢ä¸ºç›®æ ‡é…ç½®ï¼ˆChart.jsæˆ–AntV G2ï¼‰
            chart_config = convert_config(ast_config, df)
            
            # è®¾ç½®æ ‡é¢˜
            if not chart_config.get("title") or chart_config["title"] == "Chart":
                chart_config["title"] = description
            
            # æ ¹æ®å›¾è¡¨åº“ç±»å‹è¾“å‡ºä¸åŒçš„æ—¥å¿—ä¿¡æ¯
            if use_antv:
                print(f"\nâœ“ æˆåŠŸç”ŸæˆAntV G2é…ç½®:")
                print(f"- å›¾è¡¨ç±»å‹: {chart_config['type']}")
                print(f"- å›¾è¡¨æ ‡é¢˜: {chart_config['title']}")
                print(f"- Xè½´å­—æ®µ: {chart_config['xField']}")
                print(f"- Yè½´å­—æ®µ: {chart_config['yField']}")
                print(f"- æ•°æ®ç‚¹æ•°é‡: {len(chart_config['data'])}")
                series_field = chart_config.get('seriesField', None)
                if series_field:
                    print(f"- åˆ†ç»„å­—æ®µ: {series_field}")
                print(f"- æ˜¯å¦å †å : {'æ˜¯' if chart_config.get('isStack', False) else 'å¦'}")
            else:
                print(f"\nâœ“ æˆåŠŸç”ŸæˆChart.jsé…ç½®:")
                print(f"- å›¾è¡¨ç±»å‹: {chart_config['chart_type']}")
                print(f"- å›¾è¡¨æ ‡é¢˜: {chart_config['title']}")
                print(f"- Xè½´å­—æ®µ: {chart_config.get('x_field', '')}")
                print(f"- Yè½´å­—æ®µ: {chart_config.get('y_field', '')}")
                print(f"- æ•°æ®ç‚¹æ•°é‡: {len(chart_config['data']['labels'])}")
                print(f"- æ•°æ®é›†æ•°é‡: {len(chart_config['data']['datasets'])}")
                print(f"- æ˜¯å¦å †å æŸ±çŠ¶å›¾: {'æ˜¯' if chart_config.get('options', {}).get('scales', {}).get('y', {}).get('stacked', False) else 'å¦'}")
            
        except Exception as e:
            print(f"âš ï¸ æå–å›¾è¡¨é…ç½®æ—¶å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            
            # å›é€€åˆ°åŸæœ‰æ–¹æ³•
            chart_config = self._extract_chart_config_fallback(visualization, task_id, description, df, use_antv)
        
        return chart_config
    
    def _extract_chart_config_fallback(self, visualization, task_id, description, df, use_antv=False):
        """åŸå§‹çš„å›¾è¡¨é…ç½®æå–æ–¹æ³•ï¼Œä½œä¸ºå›é€€æœºåˆ¶
        
        å‚æ•°:
            visualization: åŒ…å«å¯è§†åŒ–ä»£ç çš„å­—å…¸
            task_id: ä»»åŠ¡ID
            description: ä»»åŠ¡æè¿°
            df: æ•°æ®DataFrame
            use_antv: æ˜¯å¦ä½¿ç”¨AntV G2é…ç½®ï¼ˆé»˜è®¤ä¸ºFalseï¼Œä½¿ç”¨Chart.jsï¼‰
        """
        chart_config = {}
        
        try:
            code = visualization.code
            
            # åˆå§‹åŒ–åŸºæœ¬å˜é‡
            x_field = None
            y_field = None
            has_hue = False
            hue_field = None
            is_histogram_chart = False
            is_multi_series = False  # æ ‡è®°æ˜¯å¦ä¸ºå¤šç³»åˆ—æ•°æ®
            is_stacked_bar = False   # æ ‡è®°æ˜¯å¦ä¸ºå †å æŸ±çŠ¶å›¾
            
            # è§£æå¯è§†åŒ–ä»£ç ä»¥æå–å…³é”®ä¿¡æ¯
            # é»˜è®¤å›¾è¡¨ç±»å‹
            chart_type = "bar"
            
            # å°è¯•ç¡®å®šå›¾è¡¨ç±»å‹
            if 'plt.bar(' in code or '.plot.bar(' in code or 'kind="bar"' in code or "kind='bar'" in code:
                chart_type = "bar"
                # æ£€æŸ¥æ˜¯å¦æ˜¯å †å æŸ±çŠ¶å›¾
                if 'stacked=True' in code or 'stacked=True,' in code or "stacked=True)" in code:
                    is_stacked_bar = True
                    print("ğŸ“Š æ£€æµ‹åˆ°å †å æŸ±çŠ¶å›¾")
            elif 'plt.line(' in code or '.plot(' in code and not '.plot.bar(' in code or 'kind="line"' in code or "kind='line'" in code:
                chart_type = "line"
            elif 'plt.scatter(' in code or '.plot.scatter(' in code or 'kind="scatter"' in code or "kind='scatter'" in code:
                chart_type = "scatter"
            elif 'plt.pie(' in code or 'kind="pie"' in code or "kind='pie'" in code:
                chart_type = "pie"
            elif 'plt.hist(' in code or 'kind="hist"' in code or "kind='hist'" in code:
                chart_type = "bar"  # ç›´æ–¹å›¾åœ¨ Chart.js ä¸­ä½¿ç”¨ bar
            
            # ç›´æ¥ä»plt.xlabelå’Œplt.ylabelæå–è½´æ ‡ç­¾
            xlabel_match = re.search(r'plt\.xlabel\([\'"]([^\'"]+)[\'"]\)', code)
            if xlabel_match:
                x_field = xlabel_match.group(1)
                print(f"ğŸ“Š ä»plt.xlabelç›´æ¥æå–xè½´æ ‡é¢˜: {x_field}")
            
                ylabel_match = re.search(r'plt\.ylabel\([\'"]([^\'"]+)[\'"]\)', code)
                if ylabel_match:
                    y_field = ylabel_match.group(1)
                print(f"ğŸ“Š ä»plt.ylabelç›´æ¥æå–yè½´æ ‡é¢˜: {y_field}")
            
            # ä»snsç»˜å›¾ä¸­æå–è½´æ ‡ç­¾
            if not x_field:
                sns_xlabel = re.search(r'ax\.set_xlabel\([\'"]([^\'"]+)[\'"]\)', code)
                if sns_xlabel:
                    x_field = sns_xlabel.group(1)
                    print(f"ğŸ“Š ä»snsç»˜å›¾ä¸­æå–xè½´æ ‡é¢˜: {x_field}")
            
            if not y_field:
                sns_ylabel = re.search(r'ax\.set_ylabel\([\'"]([^\'"]+)[\'"]\)', code)
                if sns_ylabel:
                    y_field = sns_ylabel.group(1)
                    print(f"ğŸ“Š ä»snsç»˜å›¾ä¸­æå–yè½´æ ‡é¢˜: {y_field}")
            
            # ä»å›¾è¡¨æ ‡é¢˜æå–ä¿¡æ¯
            title = ""
            title_match = re.search(r'plt\.title\([\'"]([^\'"]+)[\'"]\)', code)
            if title_match:
                title = title_match.group(1)
                print(f"ğŸ“Š ä»plt.titleæå–å›¾è¡¨æ ‡é¢˜: {title}")
            else:
                # å°è¯•ä»ax.set_titleæå–
                ax_title_match = re.search(r'ax\.set_title\([\'"]([^\'"]+)[\'"]\)', code)
                if ax_title_match:
                    title = ax_title_match.group(1)
                    print(f"ğŸ“Š ä»ax.set_titleæå–å›¾è¡¨æ ‡é¢˜: {title}")
                else:
                    # ä½¿ç”¨ä»»åŠ¡æè¿°ä½œä¸ºå›¾è¡¨æ ‡é¢˜
                    title = description
                    print(f"âš ï¸ æœªæ‰¾åˆ°å›¾è¡¨æ ‡é¢˜ï¼Œä½¿ç”¨ä»»åŠ¡æè¿°: {title}")
            
            # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨äº†hueå‚æ•° (åˆ†ç»„)
            hue_match = re.search(r'hue=[\'"]([^\'"]+)[\'"]', code)
            if hue_match:
                has_hue = True
                hue_field = hue_match.group(1)
                is_multi_series = True
                print(f"ğŸ“Š æ£€æµ‹åˆ°hueå‚æ•°: {hue_field}")
            
            # æ£€æŸ¥.groupby()è°ƒç”¨ï¼Œå¯èƒ½è¡¨ç¤ºåˆ†ç»„
            groupby_match = re.search(r'\.groupby\(\[[\'"]([^\'"]+)[\'"](?:,\s*[\'"]([^\'"]+)[\'"])?\]', code)
            if groupby_match:
                group_fields = [groupby_match.group(1)]
                if groupby_match.group(2):
                    group_fields.append(groupby_match.group(2))
                
                print(f"ğŸ“Š æ£€æµ‹åˆ°groupbyåˆ†ç»„å­—æ®µ: {', '.join(group_fields)}")
                if not x_field and len(group_fields) > 0:
                    x_field = group_fields[0]
                    print(f"ğŸ“Š ä½¿ç”¨ç¬¬ä¸€ä¸ªgroupbyå­—æ®µä½œä¸ºxè½´: {x_field}")
                
                # å¦‚æœæœ‰å¤šä¸ªåˆ†ç»„å­—æ®µï¼Œç¬¬äºŒä¸ªå¯èƒ½æ˜¯hue
                if len(group_fields) > 1 and not has_hue:
                    has_hue = True
                    hue_field = group_fields[1]
                    is_multi_series = True
                    print(f"ğŸ“Š ä½¿ç”¨ç¬¬äºŒä¸ªgroupbyå­—æ®µä½œä¸ºhue: {hue_field}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰pd.crosstabè°ƒç”¨ï¼Œè¿™é€šå¸¸ç”¨äºå¤šç³»åˆ—æ•°æ®
            crosstab_match = re.search(r'pd\.crosstab\(([^,]+),\s*([^,\)]+)', code)
            if crosstab_match:
                is_multi_series = True
                if not x_field:
                    x_field_expr = crosstab_match.group(1).strip()
                    if "df[" in x_field_expr:
                        col_match = re.search(r'df\[[\'"]([^\'"]+)[\'"]\]', x_field_expr)
                        if col_match:
                            x_field = col_match.group(1)
                            print(f"ğŸ“Š ä»crosstabæå–xè½´å­—æ®µ: {x_field}")
                
                if not has_hue:
                    hue_field_expr = crosstab_match.group(2).strip()
                    if "df[" in hue_field_expr:
                        col_match = re.search(r'df\[[\'"]([^\'"]+)[\'"]\]', hue_field_expr)
                        if col_match:
                            has_hue = True
                            hue_field = col_match.group(1)
                            print(f"ğŸ“Š ä»crosstabæå–hueå­—æ®µ: {hue_field}")
            
            # æå–ä»£ç ä¸­ä½¿ç”¨çš„æ•°æ®å˜é‡
            data_var_match = re.search(r'([a-zA-Z_][a-zA-Z0-9_]*)\s*=\s*df\[', code)
            data_var_name = None
            if data_var_match:
                data_var_name = data_var_match.group(1)
                print(f"ğŸ“Š æ‰¾åˆ°æ•°æ®å˜é‡å: {data_var_name}")
            
            # å°è¯•ä»plt.baræˆ–å…¶ä»–ç»˜å›¾å‡½æ•°æå–åæ ‡å’Œæ•°æ®
            column_name = None
            
            # æå–xè½´ä½¿ç”¨çš„åˆ—å
            x_col_match = re.search(r'df\[[\'"]([^\'"]+)[\'"]\]', code)
            if x_col_match:
                column_name = x_col_match.group(1)
                if not x_field:
                    x_field = column_name
                print(f"ğŸ“Š ä»ä»£ç æå–å¯èƒ½çš„xè½´åˆ—å: {column_name}")
            
            # æ£€æŸ¥forå¾ªç¯ä¸­çš„ç»˜å›¾ï¼Œå¯èƒ½è¡¨ç¤ºå¤šç³»åˆ—æ•°æ®
            for_loop_match = re.search(r'for\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+in\s+([a-zA-Z_][a-zA-Z0-9_]*)', code)
            if for_loop_match:
                loop_var = for_loop_match.group(1)
                loop_iterable = for_loop_match.group(2)
                print(f"ğŸ“Š æ£€æµ‹åˆ°forå¾ªç¯: {loop_var} in {loop_iterable}")
                is_multi_series = True
            
            # æ£€æŸ¥å †å æ¡å½¢å›¾ç‰¹å®šçš„ä»£ç æ¨¡å¼
            if 'bottom=' in code or '.stack()' in code:
                is_stacked_bar = True
                print("ğŸ“Š æ£€æµ‹åˆ°å †å æŸ±çŠ¶å›¾ç‰¹å¾(bottomå‚æ•°æˆ–stackæ–¹æ³•)")
            
            # æ•°æ®é¢„å¤„ç†é€»è¾‘
            # 1. æå–å®é™…æ•°æ®æ ‡ç­¾å’Œå€¼
            labels = []
            data_values = []
            datasets = []
            
            # åˆ†æå®é™…ä½¿ç”¨çš„åˆ—å
            if x_field and x_field in df.columns:
                # ä»DataFrameä¸­æå–å®é™…çš„xè½´æ ‡ç­¾
                unique_values = df[x_field].dropna().unique()
                if len(unique_values) > 0 and len(unique_values) <= 30:  # é™åˆ¶æ ‡ç­¾æ•°é‡
                    labels = [str(val) for val in unique_values]
                    print(f"ğŸ“Š ä»DataFrameæå–xè½´å®é™…å€¼: {labels}")
            
            # å¦‚æœæœ‰hueå­—æ®µï¼Œåˆ™å°è¯•æå–å¤šç³»åˆ—æ•°æ®
            if has_hue and hue_field and hue_field in df.columns and x_field and x_field in df.columns:
                is_multi_series = True
                
                # è·å–hueå­—æ®µçš„å”¯ä¸€å€¼
                hue_values = df[hue_field].dropna().unique()
                x_values = df[x_field].dropna().unique()
                
                print(f"ğŸ“Š hueå­—æ®µ'{hue_field}'çš„å”¯ä¸€å€¼: {hue_values}")
                print(f"ğŸ“Š xå­—æ®µ'{x_field}'çš„å”¯ä¸€å€¼: {x_values}")
                
                # å‡†å¤‡æ ‡ç­¾
                labels = [str(val) for val in x_values]
                
                # å¦‚æœæ˜¯å †å æŸ±çŠ¶å›¾ï¼Œå°è¯•ä»DataFrameé‡å»ºæ•°æ®
                if is_stacked_bar and y_field:
                    try:
                        # åˆ›å»ºäº¤å‰è¡¨
                        if y_field in df.columns:
                            # å°è¯•åˆ›å»ºäº¤å‰è¡¨ï¼ŒæŒ‰x_fieldå’Œhue_fieldåˆ†ç»„ï¼Œèšåˆy_field
                            cross_tab = df.pivot_table(
                                index=x_field, 
                                columns=hue_field, 
                                values=y_field, 
                                aggfunc='sum'
                            ).fillna(0)
                            
                            # å‡†å¤‡æ¯ä¸ªç³»åˆ—çš„æ•°æ®é›†
                            colors = self._get_colors(len(hue_values), 0.7)
                            border_colors = self._get_colors(len(hue_values), 1.0)
                            
                            for i, hue_val in enumerate(cross_tab.columns):
                                datasets.append({
                                    "label": str(hue_val),
                                    "data": cross_tab[hue_val].tolist(),
                                    "backgroundColor": colors[i],
                                    "borderColor": border_colors[i],
                                    "borderWidth": 1
                                })
                            
                            print(f"âœ“ æˆåŠŸä»DataFrameåˆ›å»ºå †å æŸ±çŠ¶å›¾æ•°æ®ï¼ŒåŒ…å«{len(datasets)}ä¸ªç³»åˆ—")
                        else:
                            print(f"âš ï¸ y_field '{y_field}' ä¸åœ¨DataFrameåˆ—ä¸­")   
                    except Exception as e:
                        print(f"âš ï¸ åˆ›å»ºå †å æŸ±çŠ¶å›¾æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                elif is_multi_series:
                    # éå †å å›¾çš„å¤šç³»åˆ—æ•°æ®å¤„ç†
                    try:
                        # ä¸ºæ¯ä¸ªhueå€¼åˆ›å»ºä¸€ä¸ªæ•°æ®é›†
                        colors = self._get_colors(len(hue_values), 0.7)
                        border_colors = self._get_colors(len(hue_values), 1.0)
                        
                        for i, hue_val in enumerate(hue_values):
                            # è¿‡æ»¤æ•°æ®
                            filtered_df = df[df[hue_field] == hue_val]
                            
                            # å¦‚æœæœ‰y_fieldï¼Œä½¿ç”¨å®ƒæ¥èšåˆæ•°æ®
                            if y_field and y_field in df.columns:
                                agg_data = filtered_df.groupby(x_field)[y_field].sum().reindex(x_values).fillna(0).tolist()
                            else:
                                # å¦åˆ™åªè®¡ç®—æ¯ä¸ªxå€¼çš„è®¡æ•°
                                agg_data = filtered_df.groupby(x_field).size().reindex(x_values).fillna(0).tolist()
                            
                                datasets.append({
                                    "label": str(hue_val),
                                    "data": agg_data,
                                    "backgroundColor": colors[i],
                                    "borderColor": border_colors[i],
                                    "borderWidth": 1
                                })
                        
                        print(f"âœ“ æˆåŠŸä»DataFrameåˆ›å»ºå¤šç³»åˆ—æ•°æ®ï¼ŒåŒ…å«{len(datasets)}ä¸ªç³»åˆ—")
                    except Exception as e:
                        print(f"âš ï¸ åˆ›å»ºå¤šç³»åˆ—æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            
            # æ ‡è®°è¿™æ˜¯ä¸€ä¸ªç›´æ–¹å›¾/é¢‘æ•°ç»Ÿè®¡å›¾è¡¨
            is_histogram_chart = 'plt.hist(' in code or 'sns.histplot' in code or 'kind="hist"' in code
            
            # å‡†å¤‡é¢‘æ•°åˆ†å¸ƒå›¾è¡¨æ•°æ®
            if is_histogram_chart and column_name and column_name in df.columns:
                print(f"ğŸ“Š æ•°æ®ä¸­å­˜åœ¨åˆ— '{column_name}'ï¼Œç”Ÿæˆé¢‘æ•°åˆ†å¸ƒ")
                            
                # å¤„ç†å¸¦hueå‚æ•°çš„countplotï¼ˆå¤šç³»åˆ—æ•°æ®ï¼‰
                if has_hue and hue_field and hue_field in df.columns:
                    print(f"ğŸ“Š ä½¿ç”¨hueå‚æ•° '{hue_field}' ç”Ÿæˆåˆ†ç»„é¢‘æ•°ç»Ÿè®¡")
                    is_multi_series = True
                                
                    # ä½¿ç”¨crosstabç”Ÿæˆäº¤å‰è¡¨
                    cross_tab = pd.crosstab(df[column_name], df[hue_field])
                                
                    # å‡†å¤‡å¤šç³»åˆ—æ•°æ®
                    labels = cross_tab.index.astype(str).tolist()
                                
                    # ä¸ºæ¯ä¸ªhueç±»åˆ«åˆ›å»ºä¸€ä¸ªæ•°æ®é›†
                    datasets = []
                    hue_categories = cross_tab.columns.tolist()
                    colors = self._get_colors(len(hue_categories), 0.7)
                                
                    for i, hue_cat in enumerate(hue_categories):
                            datasets.append({
                            "label": str(hue_cat),
                            "data": cross_tab[hue_cat].tolist(),
                            "backgroundColor": colors[i],
                            "borderColor": colors[i].replace("0.7", "1.0"),
                            "borderWidth": 1
                            })
                else:
                    # å•ç³»åˆ—ç›´æ–¹å›¾å¤„ç†
                    if not labels and len(df[column_name].dropna().unique()) <= 30:
                        # ä½¿ç”¨å”¯ä¸€å€¼ä½œä¸ºæ ‡ç­¾
                        labels = [str(val) for val in sorted(df[column_name].dropna().unique())]
                        # è®¡ç®—æ¯ä¸ªå€¼çš„é¢‘ç‡
                        value_counts = df[column_name].value_counts().reindex(sorted(df[column_name].dropna().unique()))
                        data_values = value_counts.tolist()
            
            # å¦‚æœx_fieldæˆ–y_fieldä»æœªæ‰¾åˆ°ï¼Œå°è¯•ä»å…¶ä»–ä»£ç ä¸­æå–
            if not x_field or not y_field:
                # è¿™é‡Œä¿ç•™åŸæœ‰çš„æå–é€»è¾‘
                pass
            
            # å¦‚æœlabelsä¸ºç©ºï¼Œå°è¯•è®¾ç½®é»˜è®¤å€¼æˆ–ä»DataFrameæå–å€¼
            if not labels:
                if x_field and x_field in df.columns:
                    # å°è¯•ä»DataFrameåˆ—ä¸­æå–å”¯ä¸€å€¼
                    unique_values = df[x_field].dropna().unique()
                    if len(unique_values) <= 30:  # é™åˆ¶æ ‡ç­¾æ•°é‡
                        labels = [str(val) for val in unique_values]
                    else:
                        # å¦‚æœå”¯ä¸€å€¼å¤ªå¤šï¼Œåªä½¿ç”¨å‰15ä¸ª
                        labels = [str(val) for val in unique_values[:15]]
                else:
                    # é»˜è®¤æ ‡ç­¾
                    labels = ["ç±»åˆ«1", "ç±»åˆ«2", "ç±»åˆ«3", "ç±»åˆ«4", "ç±»åˆ«5"]
            
            # æœ€ç»ˆæ„å»ºChart.jsé…ç½®
            chart_config = {
                "chart_type": chart_type,
                "title": title,
                "x_field": x_field,
                "y_field": y_field,
                "is_stacked": is_stacked_bar,
                "data": {
                    "labels": labels,
                    "datasets": datasets
                },
                "options": {
                    "responsive": True,
                    "maintainAspectRatio": False,
                    "plugins": {
                        "title": {
                            "display": True,
                            "text": title
                        },
                        "legend": {
                            "position": "top",
                            "display": len(datasets) > 1 or chart_type == 'pie'
                        },
                        "tooltip": {
                            "enabled": True
                        }
                    }
                }
            }
            
            # æ·»åŠ scalesé…ç½®ï¼ˆå¦‚æœä¸æ˜¯é¥¼å›¾ï¼‰
            if chart_type != "pie":
                chart_config["options"]["scales"] = {
                    "y": {
                        "beginAtZero": True,
                        "title": {
                            "display": True,
                            "text": y_field or "å€¼"
                        }
                    },
                    "x": {
                        "title": {
                            "display": True,
                            "text": x_field or "ç±»åˆ«"
                        }
                    }
                }
                
            # å¦‚æœæ˜¯å †å æŸ±çŠ¶å›¾ï¼Œè®¾ç½®å †å é€‰é¡¹
            if is_stacked_bar and chart_type == "bar":
                chart_config["options"]["scales"]["x"]["stacked"] = True
                chart_config["options"]["scales"]["y"]["stacked"] = True
            
            return chart_config

        except Exception as e:
            print(f"âš ï¸ æå–å›¾è¡¨é…ç½®æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            
            # åˆ›å»ºä¸€ä¸ªé»˜è®¤é…ç½®
            chart_config = {
                "chart_type": "bar",
                "x_field": "undefined",
                "y_field": "undefined",
                "title": description,
                "data": {
                    "labels": ["ç±»åˆ«1", "ç±»åˆ«2", "ç±»åˆ«3", "ç±»åˆ«4", "ç±»åˆ«5"],
                    "datasets": [
                        {
                            "label": description,
                            "data": [5, 10, 15, 7, 12],
                            "backgroundColor": "rgba(75, 192, 192, 0.2)",
                            "borderColor": "rgba(75, 192, 192, 1)",
                            "borderWidth": 1
                        }
                    ]
                },
                "options": {
                    "responsive": True,
                    "maintainAspectRatio": False,
                    "plugins": {
                        "title": {
                            "display": True,
                            "text": description
                        }
                    }
                }
            }
        
        return chart_config

    def _get_colors(self, length, opacity=0.7):
        """è·å–æŒ‡å®šæ•°é‡çš„é¢œè‰²ï¼Œç”¨äºå›¾è¡¨

        å‚æ•°:
            length: éœ€è¦çš„é¢œè‰²æ•°é‡
            opacity: é€æ˜åº¦ï¼Œ0åˆ°1ä¹‹é—´
            
        è¿”å›:
            é¢œè‰²åˆ—è¡¨ï¼Œæ ¼å¼ä¸ºrgba(r,g,b,a)
        """
        # é¢„å®šä¹‰çš„ç¾è§‚è°ƒè‰²æ¿
        base_colors = [
            (54, 162, 235),    # è“è‰²
            (255, 99, 132),    # çº¢è‰²
            (75, 192, 192),    # é’è‰²
            (255, 159, 64),    # æ©™è‰²
            (153, 102, 255),   # ç´«è‰²
            (255, 205, 86),    # é»„è‰²
            (201, 203, 207),   # ç°è‰²
            (22, 160, 133),    # ç»¿æ¾çŸ³
            (142, 68, 173),    # ç´«ç½—å…°
            (241, 196, 15),    # é‡‘è‰²
            (231, 76, 60),     # çŸ³æ¦´çº¢
            (52, 152, 219),    # å¤©è“
            (46, 204, 113),    # ç¥–æ¯ç»¿
            (155, 89, 182),    # æ·¡ç´«è‰²
            (26, 188, 156),    # é’ç¢§è‰²
            (192, 57, 43),     # æ·±çº¢è‰²
            (41, 128, 185),    # é›è“è‰²
            (39, 174, 96),     # æ·±ç»¿è‰²
        ]
        
        # å¦‚æœéœ€è¦çš„é¢œè‰²æ•°é‡å°äºé¢„å®šä¹‰çš„é¢œè‰²æ•°é‡ï¼Œç›´æ¥è¿”å›å‰nä¸ª
        if length <= len(base_colors):
            return [f"rgba({r}, {g}, {b}, {opacity})" for r, g, b in base_colors[:length]]
        
        # å¦‚æœéœ€è¦æ›´å¤šé¢œè‰²ï¼Œå¯¹å·²æœ‰çš„é¢œè‰²è¿›è¡Œæ’å€¼
        # ä¸ºç®€åŒ–ï¼Œæˆ‘ä»¬å¾ªç¯ä½¿ç”¨å·²æœ‰çš„é¢œè‰²
        result = []
        for i in range(length):
            idx = i % len(base_colors)
            r, g, b = base_colors[idx]
            # æ¯æ¬¡å¾ªç¯éƒ½ç¨å¾®è°ƒæ•´ä¸€ä¸‹é€æ˜åº¦ï¼Œå¢åŠ å˜åŒ–
            adjusted_opacity = max(0.3, min(0.9, opacity - 0.05 * (i // len(base_colors))))
            result.append(f"rgba({r}, {g}, {b}, {adjusted_opacity})")
        
        return result
    
    # def _find_best_matching_column(self, label, df):
    #     """æŸ¥æ‰¾ä¸ç»™å®šæ ‡ç­¾æœ€åŒ¹é…çš„DataFrameåˆ—å
        
    #     å‚æ•°:
    #         label: ä»å¯è§†åŒ–ä»£ç ä¸­æå–çš„æ ‡ç­¾å
    #         df: æ•°æ®DataFrame
            
    #     è¿”å›:
    #         æœ€åŒ¹é…çš„åˆ—åï¼Œå¦‚æœæ²¡æœ‰æ‰¾åˆ°åˆ™è¿”å›None
    #     """
    #     if label in df.columns:
    #         return label
            
    #     # 1. å°è¯•ç®€åŒ–æ ‡ç­¾ï¼ˆå°å†™ã€ç§»é™¤ç©ºæ ¼ç­‰ï¼‰
    #     simplified_label = label.lower().replace(' ', '_')
    #     for col in df.columns:
    #         if simplified_label == col.lower().replace(' ', '_'):
    #             return col
                
    #     # 2. æ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†åŒ¹é…
    #     label_words = set(label.lower().split())
    #     best_match = None
    #     best_score = 0
        
    #     for col in df.columns:
    #         col_words = set(col.lower().split('_'))
    #         # è®¡ç®—åŒ¹é…å•è¯çš„æ•°é‡
    #         match_score = len(label_words.intersection(col_words))
    #         if match_score > best_score:
    #             best_score = match_score
    #             best_match = col
                
    #     # å¦‚æœè‡³å°‘æœ‰ä¸€ä¸ªå•è¯åŒ¹é…ï¼Œè¿”å›æœ€ä½³åŒ¹é…
    #     if best_score > 0:
    #         print(f"ğŸ“Š æ‰¾åˆ°ä¸'{label}'æœ€åŒ¹é…çš„åˆ—: '{best_match}'")
    #         return best_match
            
    #     # 3. æ ¹æ®å›¾è¡¨ç±»å‹æ¨æ–­å¯èƒ½çš„åˆ—
    #     # å¦‚æœæ ‡ç­¾æš—ç¤ºæ˜¯è®¡æ•°/æ•°é‡
    #     if any(word in label.lower() for word in ['count', 'number', 'quantity', 'amount']):
    #         # å°è¯•æ‰¾åˆ°æ•°å€¼å‹åˆ—
    #         numeric_cols = [col for col in df.columns if pd.api.types.is_numeric_dtype(df[col])]
    #         if numeric_cols:
    #             print(f"ğŸ“Š æ ‡ç­¾'{label}'æš—ç¤ºè®¡æ•°/æ•°é‡ï¼Œä½¿ç”¨æ•°å€¼åˆ—: '{numeric_cols[0]}'")
    #             return numeric_cols[0]
                
    #     # æ²¡æœ‰æ‰¾åˆ°åˆé€‚çš„åŒ¹é…
    #     return None

    def _find_last_dataframe_variable(self, code):
        """ä»ä»£ç ä¸­æ‰¾å‡ºæœ€åä¸€ä¸ªå®šä¹‰çš„DataFrameå˜é‡
        
        å‚æ•°:
            code: å¯è§†åŒ–ä»£ç 
            
        è¿”å›:
            å˜é‡åæˆ–None
        """
        # æŸ¥æ‰¾å˜é‡å®šä¹‰æ¨¡å¼
        var_assigns = re.findall(r'(\w+)\s*=\s*', code)
        plot_vars = re.findall(r'(\w+)\.plot', code)
        
        # å¦‚æœæ‰¾åˆ°äº†ç”¨äºç»˜å›¾çš„å˜é‡ï¼Œä¼˜å…ˆè¿”å›
        if plot_vars:
            return plot_vars[-1]
        
        # å¦åˆ™è¿”å›æœ€åå®šä¹‰çš„å˜é‡
        if var_assigns:
            return var_assigns[-1]
        
        return None
        
   # def _extract_actual_data(self, visualization):
        """å°è¯•ä»å¯è§†åŒ–å¯¹è±¡æå–å®é™…ç”¨äºç»˜å›¾çš„æ•°æ®
        
        å‚æ•°:
            visualization: å¯è§†åŒ–å¯¹è±¡
            
        è¿”å›:
            dict: åŒ…å«æ•°æ®çš„å­—å…¸ï¼Œæ ¼å¼é€‚ç”¨äºChart.js
        """
        try:
            # æ£€æŸ¥å¯è§†åŒ–å¯¹è±¡æ˜¯å¦æœ‰æ•°æ®å±æ€§
            if not hasattr(visualization, 'code'):
                return None
                
            code = visualization.code
            print("\nğŸ“Š å°è¯•æå–å›¾è¡¨å®é™…æ•°æ®:")
            
            # 1. è§£æä»£ç ä»¥ç¡®å®šå›¾è¡¨ç±»å‹
            chart_type = "bar"  # é»˜è®¤
            if 'plt.bar(' in code or '.plot.bar(' in code or 'kind="bar"' in code or "kind='bar'" in code:
                chart_type = "bar"
            elif 'plt.line(' in code or '.plot(' in code and not '.plot.bar(' in code:
                chart_type = "line"
            elif 'plt.scatter(' in code or '.plot.scatter(' in code:
                chart_type = "scatter" 
            elif 'plt.pie(' in code or 'kind="pie"' in code or "kind='pie'" in code:
                chart_type = "pie"
            elif 'plt.hist(' in code or 'kind="hist"' in code or "kind='hist'" in code:
                chart_type = "bar"  # ç›´æ–¹å›¾åœ¨ Chart.js ä¸­ä½¿ç”¨ bar
            
            # 2. æ£€æŸ¥å¯è§†åŒ–å¯¹è±¡æ˜¯å¦æœ‰Figureå±æ€§
            fig = None
            if hasattr(visualization, 'fig'):
                fig = visualization.fig
                print("âœ“ æ‰¾åˆ°figå±æ€§")
            elif hasattr(visualization, 'figure'):
                fig = visualization.figure
                print("âœ“ æ‰¾åˆ°figureå±æ€§")
            elif hasattr(visualization, 'plt') and hasattr(visualization.plt, 'gcf'):
                # å°è¯•ä»pltå¯¹è±¡è·å–å½“å‰å›¾å½¢
                try:
                    fig = visualization.plt.gcf()
                    print("âœ“ ä»plt.gcf()è·å–åˆ°å½“å‰å›¾å½¢")
                except:
                    pass
                    
            # 3. å°è¯•ä»å¯è§†åŒ–ä»£ç ä¸­æå–æœ€åçš„ç»“æœå˜é‡
            if not fig:
                # å°è¯•ä»ä»£ç ä¸­æ‰¾åˆ°æœ€åè¿”å›çš„å˜é‡
                result_match = re.search(r'return\s+(\w+)', code)
                if result_match:
                    result_var = result_match.group(1)
                    print(f"âœ“ ä»ä»£ç ä¸­æ‰¾åˆ°è¿”å›å˜é‡: {result_var}")
                    
                    # æ£€æŸ¥visualizationå¯¹è±¡æ˜¯å¦æœ‰è¿™ä¸ªå±æ€§
                    if hasattr(visualization, result_var):
                        result_obj = getattr(visualization, result_var)
                        if hasattr(result_obj, 'figure'):
                            fig = result_obj.figure
                            print(f"âœ“ ä»è¿”å›å˜é‡è·å–åˆ°figure")
                        elif hasattr(result_obj, 'gcf'):
                            try:
                                fig = result_obj.gcf()
                                print(f"âœ“ ä»è¿”å›å˜é‡çš„gcf()è·å–åˆ°figure")
                            except:
                                pass
                
            # 4. å¦‚æœæœ‰Figureï¼Œå°è¯•ä»ä¸­æå–æ•°æ®
            data_extracted = False
            if fig is not None:
                try:
                    # ç›´æ¥ä»å›¾å½¢å¯¹è±¡æå–æ‰€æœ‰æ•°æ®
                    all_data = {}
                    
                    for i, ax in enumerate(fig.axes):
                        print(f"âœ“ åˆ†æå›¾è¡¨è½´ #{i+1}")
                        
                        # æå–æ¡å½¢å›¾æ•°æ®
                        if chart_type == "bar" and hasattr(ax, 'containers') and ax.containers:
                            try:
                                container = ax.containers[0]
                                heights = [rect.get_height() for rect in container]
                                
                                # æå–Xè½´æ ‡ç­¾
                                if hasattr(ax, 'get_xticklabels'):
                                    labels = [label.get_text() for label in ax.get_xticklabels() if label.get_text()]
                                    if not labels or len(labels) != len(heights):
                                        # å°è¯•ä»åæ ‡ä¸­è·å–ä½ç½®
                                        x_positions = [rect.get_x() + rect.get_width()/2 for rect in container]
                                        labels = [str(pos) for pos in x_positions]
                                else:
                                    # æ‰¾ä¸åˆ°æ ‡ç­¾ï¼Œä½¿ç”¨é»˜è®¤å€¼
                                    labels = [f"ç±»åˆ«{i+1}" for i in range(len(heights))]
                                    
                                all_data = {
                                    "labels": labels,
                                    "datasets": [{
                                        "label": "æ•°æ®",
                                        "data": heights
                                    }]
                                }
                                print(f"âœ“ ä»æ¡å½¢å›¾æå–åˆ°{len(heights)}ä¸ªæ•°æ®ç‚¹")
                                data_extracted = True
                                break
                            except Exception as e:
                                print(f"ä»æ¡å½¢å›¾å®¹å™¨æå–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                        
                        # æå–çº¿å›¾æ•°æ®
                        if (chart_type == "line" or not data_extracted) and hasattr(ax, 'lines') and ax.lines:
                            try:
                                all_datasets = []
                                for j, line in enumerate(ax.lines):
                                    x_data = line.get_xdata()
                                    y_data = line.get_ydata()
                                    
                                    # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶å¤„ç†numpyæ•°ç»„
                                    if hasattr(x_data, 'tolist'):
                                        x_data = x_data.tolist()
                                    if hasattr(y_data, 'tolist'):
                                        y_data = y_data.tolist()
                                    
                                    # åªä¿ç•™å‰100ä¸ªç‚¹(å¦‚æœæ•°æ®å¤ªå¤§)
                                    if len(x_data) > 100:
                                        step = len(x_data) // 100
                                        x_data = x_data[::step][:100]
                                        y_data = y_data[::step][:100]
                                        
                                    # å¦‚æœæ˜¯ç¬¬ä¸€æ¡çº¿ï¼Œè®¾ç½®labels
                                    if j == 0:
                                        all_data["labels"] = [str(x) for x in x_data]
                                        
                                    all_datasets.append({
                                        "label": f"ç³»åˆ—{j+1}",
                                        "data": y_data
                                    })
                                
                                if all_datasets:
                                    all_data["datasets"] = all_datasets
                                    print(f"âœ“ ä»çº¿å›¾æå–åˆ°{len(all_datasets)}ä¸ªç³»åˆ—çš„æ•°æ®")
                                    data_extracted = True
                                    break
                            except Exception as e:
                                print(f"ä»çº¿å›¾æå–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                        
                        # æå–æ•£ç‚¹å›¾æ•°æ®
                        if (chart_type == "scatter" or not data_extracted) and hasattr(ax, 'collections') and ax.collections:
                            try:
                                all_datasets = []
                                for j, collection in enumerate(ax.collections):
                                    if hasattr(collection, 'get_offsets'):
                                        offsets = collection.get_offsets()
                                        if hasattr(offsets, 'tolist'):
                                            points = offsets.tolist()
                                            
                                            # é™åˆ¶æ•°æ®ç‚¹æ•°é‡
                                            if len(points) > 100:
                                                points = points[:100]
                                                
                                            x_data = [point[0] for point in points]
                                            y_data = [point[1] for point in points]
                                            
                                            # å¦‚æœæ˜¯ç¬¬ä¸€ä¸ªé›†åˆï¼Œè®¾ç½®labels
                                            if j == 0:
                                                all_data["labels"] = [str(x) for x in x_data]
                                                
                                            all_datasets.append({
                                                "label": f"ç³»åˆ—{j+1}",
                                                "data": y_data
                                            })
                                
                                if all_datasets:
                                    all_data["datasets"] = all_datasets
                                    print(f"âœ“ ä»æ•£ç‚¹å›¾æå–åˆ°{len(all_datasets)}ä¸ªç³»åˆ—çš„æ•°æ®")
                                    data_extracted = True
                                    break
                            except Exception as e:
                                print(f"ä»æ•£ç‚¹å›¾æå–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                        
                        # æå–é¥¼å›¾æ•°æ® 
                        if (chart_type == "pie" or not data_extracted) and hasattr(ax, 'patches') and ax.patches:
                            try:
                                patches = ax.patches
                                sizes = [patch.theta2 - patch.theta1 for patch in patches]
                                
                                # æå–æ ‡ç­¾
                                labels = []
                                if hasattr(ax, 'texts') and ax.texts:
                                    labels = [text.get_text() for text in ax.texts if text.get_text()]
                                
                                if not labels or len(labels) != len(sizes):
                                    labels = [f"éƒ¨åˆ†{i+1}" for i in range(len(sizes))]
                                    
                                # å½’ä¸€åŒ–å°ºå¯¸ä¸ºç™¾åˆ†æ¯”
                                total = sum(sizes)
                                sizes = [size/total*100 for size in sizes]
                                
                                all_data = {
                                    "labels": labels,
                                    "datasets": [{
                                        "label": "æ•°æ®",
                                        "data": sizes
                                    }]
                                }
                                print(f"âœ“ ä»é¥¼å›¾æå–åˆ°{len(sizes)}ä¸ªæ•°æ®ç‚¹")
                                data_extracted = True
                                break
                            except Exception as e:
                                print(f"ä»é¥¼å›¾æå–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
                    
                    if data_extracted and all_data:
                        print(f"âœ“ æˆåŠŸä»å›¾å½¢å¯¹è±¡æå–æ•°æ®")
                        return all_data
                except Exception as e:
                    print(f"ä»å›¾å½¢å¯¹è±¡æå–æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            
            # 5. å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®å±æ€§
            if hasattr(visualization, '_data') and isinstance(visualization._data, pd.DataFrame):
                df = visualization._data
                print(f"âœ“ æ‰¾åˆ°æ•°æ®å±æ€§ _data")
                # æ ¹æ®ä¸åŒå›¾è¡¨ç±»å‹å¤„ç†æ•°æ®
                data = self._process_dataframe_for_chart(df, chart_type)
                if data:
                    return data
                
            elif hasattr(visualization, 'data') and isinstance(visualization.data, pd.DataFrame):
                df = visualization.data
                print(f"âœ“ æ‰¾åˆ°æ•°æ®å±æ€§ data")
                # æ ¹æ®ä¸åŒå›¾è¡¨ç±»å‹å¤„ç†æ•°æ®
                data = self._process_dataframe_for_chart(df, chart_type)
                if data:
                    return data
            
            # 6. å°è¯•ä»ä»£ç ä¸­æ‰¾åˆ°æ•°æ®æ¡†å˜é‡å¹¶æ‰§è¡Œä»£ç 
            try:
                # æŸ¥æ‰¾æœ€åä¸€ä¸ªDataFrameå˜é‡
                last_df_var = self._find_last_dataframe_variable(code)
                if last_df_var and 'df' in locals():
                    print(f"âœ“ æ‰¾åˆ°æœ€åçš„DataFrameå˜é‡: {last_df_var}")
                    # æå–ä»£ç ä¸­çš„æœ€ç»ˆæ•°æ®å¤„ç†éƒ¨åˆ†
                    # è¿™é‡Œåªæ˜¯ä¸€ä¸ªç®€åŒ–å¤„ç†ï¼Œå®é™…ä¸Šåº”è¯¥æ›´å¤æ‚
                    df_code_pattern = f"{last_df_var}\s*=.*?(?=\n\n|\Z)"
                    df_code_match = re.search(df_code_pattern, code, re.DOTALL)
                    if df_code_match:
                        df_code = df_code_match.group(0)
                        print(f"âœ“ æå–åˆ°DataFrameå¤„ç†ä»£ç ")
                        # è¿™é‡Œæˆ‘ä»¬ä¸èƒ½ç›´æ¥æ‰§è¡Œä»£ç ï¼Œä½†è‡³å°‘çŸ¥é“æœ‰è¿™æ ·çš„ä»£ç æ®µ
                        # å¯ä»¥æ·»åŠ åˆ°æ—¥å¿—ä¸­ä»¥ä¾¿åç»­åˆ†æ
            except Exception as e:
                print(f"åˆ†æä»£ç ä¸­çš„DataFrameå˜é‡æ—¶å‡ºé”™: {str(e)}")
                
            # 7. å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°æ•°æ®ï¼Œå°è¯•æ¨¡æ‹Ÿæ‰§è¡Œï¼Œè¿™éƒ¨åˆ†ä¿ç•™ç°æœ‰çš„_extract_chart_configæ–¹æ³•çš„èƒ½åŠ›
            print("âš ï¸ æ— æ³•ç›´æ¥ä»å¯è§†åŒ–å¯¹è±¡æå–æ•°æ®")
            return None
                
        except Exception as e:
            print(f"âš ï¸ æå–å›¾è¡¨å®é™…æ•°æ®æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
            
    def _process_dataframe_for_chart(self, df, chart_type):
        """æ ¹æ®å›¾è¡¨ç±»å‹å¤„ç†DataFrameå¹¶ç”Ÿæˆé€‚åˆçš„æ•°æ®ç»“æ„
        
        å‚æ•°:
            df: æ•°æ®æ¡†
            chart_type: å›¾è¡¨ç±»å‹
            
        è¿”å›:
            é€‚åˆChart.jsçš„æ•°æ®å­—å…¸
        """
        try:
            if df.empty:
                return None
                
            # é’ˆå¯¹ä¸åŒå›¾è¡¨ç±»å‹å¤„ç†æ•°æ®
            if chart_type in ["bar", "line"]:
                # å‡è®¾ç¬¬ä¸€åˆ—ä¸ºæ ‡ç­¾ï¼Œå…¶ä½™åˆ—ä¸ºæ•°æ®
                # è¿™æ˜¯ä¸€ä¸ªç®€åŒ–å¤„ç†ï¼Œå®é™…å¯èƒ½éœ€è¦æ›´å¤æ‚çš„é€»è¾‘
                if len(df.columns) >= 2:
                    labels = df.iloc[:, 0].astype(str).tolist()
                    data_cols = df.columns[1:]
                    
                    datasets = []
                    for col in data_cols:
                        datasets.append({
                            "label": col,
                            "data": df[col].tolist()
                        })
                    
                    return {
                        "labels": labels,
                        "datasets": datasets
                    }
                else:
                    # å•åˆ—æ•°æ®ï¼Œä½¿ç”¨ç´¢å¼•ä½œä¸ºæ ‡ç­¾
                    labels = [str(i) for i in range(len(df))]
                    data = df.iloc[:, 0].tolist()
                    
                    return {
                        "labels": labels,
                        "datasets": [{
                            "label": df.columns[0],
                            "data": data
                        }]
                    }
                    
            elif chart_type == "scatter":
                # æ•£ç‚¹å›¾é€šå¸¸éœ€è¦ä¸¤åˆ—ï¼šxå’Œy
                if len(df.columns) >= 2:
                    x_data = df.iloc[:, 0].tolist()
                    y_data = df.iloc[:, 1].tolist()
                    
                    return {
                        "labels": [str(x) for x in x_data],
                        "datasets": [{
                            "label": df.columns[1],
                            "data": y_data
                        }]
                    }
                    
            elif chart_type == "pie":
                # é¥¼å›¾é€šå¸¸æ˜¯ä¸€åˆ—æ ‡ç­¾å’Œä¸€åˆ—æ•°å€¼
                if len(df.columns) >= 2:
                    labels = df.iloc[:, 0].astype(str).tolist()
                    data = df.iloc[:, 1].tolist()
                    
                    return {
                        "labels": labels,
                        "datasets": [{
                            "label": df.columns[1],
                            "data": data
                        }]
                    }
                else:
                    # å•åˆ—æ•°æ®ï¼Œä½¿ç”¨å€¼è®¡æ•°
                    value_counts = df.iloc[:, 0].value_counts()
                    labels = value_counts.index.astype(str).tolist()
                    data = value_counts.values.tolist()
                    
                    return {
                        "labels": labels,
                        "datasets": [{
                            "label": df.columns[0],
                            "data": data
                        }]
                    }
                    
            return None
            
        except Exception as e:
            print(f"âš ï¸ å¤„ç†DataFrameæ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None

class ReviseVis(DataStorytellingAction):
    def __init__(self):
        super().__init__("A4", "å¯¹æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨è¿›è¡ŒReviseåˆ¤æ–­")
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨"""
        # åˆ›å»ºå­èŠ‚ç‚¹
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = self
        child_node.depth = node.depth + 1
        
        try:
            # éå†æ‰€æœ‰ç« èŠ‚
            for chapter_idx, chapter in enumerate(child_node.report.chapters):
                # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å¯è§†åŒ–ä»»åŠ¡
                if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                    print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡")
                    continue
                    
                for task in chapter.visualization_tasks:
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦æ˜¯ç”ŸæˆæˆåŠŸçš„æˆ–è€…å› ç›¸ä¼¼åº¦è·³è¿‡çš„
                    if task.get('visualization_success', False) == True:
                        continue
                        
                    # æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å› ç›¸ä¼¼åº¦é«˜è€Œè¢«è·³è¿‡çš„ï¼Œå¦‚æœæ˜¯åˆ™ä¸éœ€è¦ä¿®å¤
                    if task.get('skipped_due_to_similarity', False) == True:
                        print(f"âš ï¸ ä»»åŠ¡ '{task.get('task_id', '')}' å› ç›¸ä¼¼åº¦è¿‡é«˜è€Œè¢«è·³è¿‡ï¼Œä¸éœ€è¦ä¿®å¤")
                        continue
                        
                    task_id = task.get('task_id', "")
                    description = task.get('task_description', "")
                    
                    print(f"æ­£åœ¨ä¿®æ”¹ä»»åŠ¡ '{task_id}' çš„å›¾è¡¨...")
            
                    selected_chart = None
                    print(f"\nğŸ” åœ¨ç« èŠ‚ä¸­æŸ¥æ‰¾å›¾è¡¨:")
                    print(f"- ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
                    print(f"- ç« èŠ‚ä¸­çš„å›¾è¡¨æ•°é‡: {len(getattr(chapter, 'charts', []))}")
                    
                    for c in chapter.charts:
                        print(f"- æ£€æŸ¥å›¾è¡¨: task_id={getattr(c, 'task_id', 'None')}")
                        if hasattr(c, 'task_id') and c.task_id == task_id:
                            selected_chart = c
                            print(f"âœ“ æ‰¾åˆ°åŒ¹é…çš„å›¾è¡¨")
                            break
                    
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°åŒ¹é…çš„å›¾è¡¨ï¼Œè·³è¿‡æ­¤ä»»åŠ¡
                    if not selected_chart:
                        print(f"âš ï¸ æ‰¾ä¸åˆ°ä¸ä»»åŠ¡ '{task_id}' åŒ¹é…çš„å›¾è¡¨ï¼Œè·³è¿‡")
                        continue
                
                    try:
                        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„
                        dataset_path = node.report.dataset_path
                        
                        # è¯»å–æ•°æ®
                        df = pd.read_csv(dataset_path)
                        
                        # åˆ›å»º LIDA ç®¡ç†å™¨
                        from lida.components.manager import Manager
                        from lida.datamodel import Summary
                        
                        # åˆ›å»ºè‡ªå®šä¹‰çš„æ–‡æœ¬ç”Ÿæˆå™¨
                        text_gen = llm(provider="openai", model="gpt-4-32k")
                        manager = Manager(text_gen=text_gen)
                        
                        # è¯»å–æ•°æ®æ‘˜è¦ JSON æ–‡ä»¶
                        data_summary = {}
                        json_path = os.path.join("storyteller", "dataset", "data_context.json")
                        print(f"å°è¯•è¯»å–æ•°æ®æ‘˜è¦ JSON: {json_path}")
                        
                        try:
                            with open(json_path, 'r', encoding='utf-8') as f:
                                data_summary = json.load(f)
                            print("âœ“ æˆåŠŸè¯»å–æ•°æ®æ‘˜è¦ JSON")
                        except Exception as e:
                            print(f"âœ— è¯»å–æ•°æ®æ‘˜è¦ JSON å¤±è´¥: {str(e)}")
                            # å¦‚æœæ— æ³•è¯»å– JSON æ–‡ä»¶ï¼Œä½¿ç”¨é»˜è®¤å€¼
                            data_summary = {
                                "name": node.report.original_query,
                                "dataset_description": node.report.data_context,
                                "fields_info": {col: {"dtype": str(dtype)} for col, dtype in zip(df.columns, df.dtypes)}
                            }
                        
                        # åˆ›å»º Summary å¯¹è±¡ï¼Œç›´æ¥ä» JSON æ–‡ä»¶ä¸­æå–å¿…è¦å‚æ•°
                        summary = Summary(
                            name=data_summary.get("name", "æ•°æ®åˆ†æ"),
                            file_name=dataset_path,  # ä½¿ç”¨åŸå§‹æ•°æ®æ–‡ä»¶è·¯å¾„
                            dataset_description=str(data_summary.get("dataset_description", "è´­ç‰©æ•°æ®é›†")),
                            field_names=list(data_summary.get("fields_info", {}).keys()) if "fields_info" in data_summary else df.columns.tolist(),
                            fields=[info.get("dtype", "unknown") for info in data_summary.get("fields_info", {}).values()] if "fields_info" in data_summary else [str(dtype) for dtype in df.dtypes.tolist()]
                        )
                        
                        # ç”Ÿæˆç¼–è¾‘æŒ‡ä»¤
                        edit_instruction = "ä¿®æ”¹å›¾è¡¨é”™è¯¯ï¼Œæ¯”å¦‚ä¿®æ”¹ä¸ºæ›´åˆé€‚çš„å›¾è¡¨ç±»å‹ï¼Œè®©å›¾è¡¨æ›´åŠ ç¾è§‚ï¼Œæ¸…æ™°"
                        #print(f"ç”Ÿæˆçš„ç¼–è¾‘æŒ‡ä»¤: {edit_instruction}")
                        
                        # ä½¿ç”¨ LIDA çš„ edit åŠŸèƒ½ä¿®æ”¹å›¾è¡¨
                        print(f"æ­£åœ¨ä¿®æ”¹ä»»åŠ¡ '{description}' çš„å›¾è¡¨...")
                        edited_visualization = manager.edit(
                            code=selected_chart.code,
                            summary=summary,
                            instructions=edit_instruction,
                            library="matplotlib"
                        )
                        
                        # å¤„ç†ç¼–è¾‘åçš„å¯è§†åŒ–ç»“æœ
                        if edited_visualization is None:
                            print("âœ— ç¼–è¾‘å¯è§†åŒ–å›¾è¡¨å¤±è´¥: è¿”å›ç»“æœä¸ºNone")
                        elif isinstance(edited_visualization, list) and len(edited_visualization) > 0:
                            edited_visualization = edited_visualization[0]
                            print("âœ“ ä½¿ç”¨ç¬¬ä¸€ä¸ªç¼–è¾‘ç»“æœè¿›è¡Œå¤„ç†")
                        
                        # æ£€æŸ¥æ˜¯å¦ä¸ºæœ‰æ•ˆçš„ç¼–è¾‘ç»“æœ
                        if hasattr(edited_visualization, 'status') and edited_visualization.status:
                            print("âœ“ æˆåŠŸä¿®æ”¹å¯è§†åŒ–å›¾è¡¨")
                            
                            # æ‰¾åˆ°å½“å‰å›¾è¡¨æ‰€åœ¨çš„è¿­ä»£ç›®å½•
                            original_chart_path = selected_chart.url
                            chart_dir = os.path.dirname(original_chart_path)
                            
                            # å°†ä¿®æ”¹åçš„å›¾è¡¨ä¿å­˜åˆ°åŒä¸€ç›®å½•ä¸‹
                            edited_chart_name = f"{task_id}_edited.png"
                            edited_chart_path = os.path.join(chart_dir, edited_chart_name)
                            
                            # ä¿å­˜ä¿®æ”¹åçš„å›¾è¡¨
                            if hasattr(edited_visualization, 'savefig'):
                                edited_visualization.savefig(edited_chart_path)
                                print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨å·²ä¿å­˜åˆ°: {edited_chart_path}")
                            
                                
                                # é¢å¤–ç”Ÿæˆ Chart.js é…ç½® JSON æ–‡ä»¶
                                try:
                                    # å€Ÿç”¨ Tasks2Charts ç±»ä¸­çš„æ–¹æ³•æ¥æå–å›¾è¡¨é…ç½®
                                    from storyteller.algorithm.mcts_action import Tasks2Charts
                                    tasks2charts = Tasks2Charts()
                                    
                                    # æå–å›¾è¡¨ä½¿ç”¨çš„å®é™…æ•°æ®
                                    chart_data = tasks2charts._extract_actual_data(edited_visualization)
                                    chart_config = tasks2charts._extract_chart_config(edited_visualization, task_id, description, df)
                                    
                                    # å°†æå–çš„å®é™…æ•°æ®æ·»åŠ åˆ°é…ç½®ä¸­
                                    if chart_data:
                                        chart_config['data'] = chart_data
                                        print(f"âœ“ æˆåŠŸæå–å›¾è¡¨å®é™…æ•°æ®")
                                    
                                    # è·å– JSON é…ç½®ç›®å½•
                                    json_dir = os.path.join(os.path.dirname(chart_dir), "chart_configs")
                                    os.makedirs(json_dir, exist_ok=True)
                                    
                                    # ä¿å­˜ JSON é…ç½®
                                    json_file_name = f"{task_id}_edited.json"
                                    json_path = os.path.join(json_dir, json_file_name)
                                    with open(json_path, "w", encoding="utf-8") as f:
                                        json.dump(chart_config, f, ensure_ascii=False, indent=2)
                                    print(f"âœ“ å›¾è¡¨é…ç½® JSON å·²ä¿å­˜åˆ°: {json_path}")
                                    
                                    # é¢å¤–ä¿å­˜å›¾è¡¨æ•°æ®ä¸ºCSVï¼Œä»¥ä¾¿åç»­åˆ†æ
                                    try:
                                        csv_dir = os.path.join(os.path.dirname(chart_dir), "chart_data")
                                        os.makedirs(csv_dir, exist_ok=True)
                                        csv_file_name = f"{task_id}_edited.csv"
                                        csv_path = os.path.join(csv_dir, csv_file_name)
                                        
                                        # å°è¯•ä»å¯è§†åŒ–å¯¹è±¡ä¸­æå–å®é™…ä½¿ç”¨çš„æ•°æ®
                                        if hasattr(edited_visualization, '_data') and isinstance(edited_visualization._data, pd.DataFrame):
                                            edited_visualization._data.to_csv(csv_path, index=False)
                                            print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                        elif hasattr(edited_visualization, 'data') and isinstance(edited_visualization.data, pd.DataFrame):
                                            edited_visualization.data.to_csv(csv_path, index=False)
                                            print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å·²ä¿å­˜åˆ°: {csv_path}")
                                        else:
                                            # å°è¯•ä»ä»£ç ä¸­æå–å’Œåˆ†ææ•°æ®
                                            last_df_var = tasks2charts._find_last_dataframe_variable(edited_visualization.code)
                                            if last_df_var:
                                                # è¿™é‡Œæˆ‘ä»¬æ— æ³•ç›´æ¥è®¿é—®ä»£ç ä¸­çš„å˜é‡
                                                # æ‰€ä»¥åªèƒ½ä¿å­˜ä¸€ä¸ªæŒ‡ç¤ºæ–‡ä»¶ï¼Œæç¤ºchart_configä½¿ç”¨ä»€ä¹ˆå˜é‡
                                                with open(csv_path + ".info", "w") as f:
                                                    f.write(f"Last DataFrame variable: {last_df_var}")
                                                print(f"âœ“ ä¿®æ”¹åçš„å›¾è¡¨æ•°æ®å˜é‡ä¿¡æ¯å·²ä¿å­˜: {last_df_var}")
                                    except Exception as e:
                                        print(f"âš ï¸ ä¿å­˜ä¿®æ”¹åçš„å›¾è¡¨æ•°æ® CSV æ—¶å‡ºé”™: {str(e)}")
                                        traceback.print_exc()
                                except Exception as e:
                                    print(f"âš ï¸ ä¿å­˜å›¾è¡¨é…ç½® JSON æ—¶å‡ºé”™: {str(e)}")
                                    traceback.print_exc()
                                    json_path = None

                            # åˆ›å»ºæ–°çš„å›¾è¡¨å¯¹è±¡
                            from storyteller.algorithm.mcts_node import Chart
                            edited_chart = Chart(
                                url=edited_chart_path,
                                caption="",  # ä½¿ç”¨ç©ºå­—ç¬¦ä¸²ä½œä¸ºåˆå§‹è¯´æ˜
                                chart_type=selected_chart.chart_type,
                                task_id=task_id  # ä½¿ç”¨åŸå§‹ä»»åŠ¡ID/æè¿°
                            )
                            edited_chart.needs_caption = True  # è®¾ç½®éœ€è¦ç”Ÿæˆè¯´æ˜æ–‡å­—çš„æ ‡å¿—
                           
                            # æ·»åŠ JSONé…ç½®è·¯å¾„å±æ€§
                            if 'json_path' in locals() and json_path:
                                edited_chart.json_config_path = json_path
                                print(f"- JSON é…ç½®è·¯å¾„: {json_path}")                            

                            # æ›´æ–°ç« èŠ‚ä¸­çš„å›¾è¡¨
                            for i, c in enumerate(chapter.charts):
                                if hasattr(c, 'task_id') and c.task_id == task_id:
                                    chapter.charts[i] = edited_chart
                                    break
                        else:
                            error_msg = edited_visualization.error if hasattr(edited_visualization, 'error') else "æœªçŸ¥é”™è¯¯"
                            print(f"âœ— ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨å¤±è´¥: {error_msg}")
                    except Exception as e:
                        print(f"âœ— ä¿®æ”¹å¯è§†åŒ–å›¾è¡¨æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}")
                        import traceback
                        traceback.print_exc()
            
            # è®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a4
            return [child_node]
                
        except Exception as e:
            print(f"âŒ å¤„ç†èŠ‚ç‚¹æ—¶å‡ºé”™: {str(e)}")
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ä»»åŠ¡ï¼Œè¿”å›ç©ºåˆ—è¡¨
            print("âŒ æ²¡æœ‰æ‰¾åˆ°å¾…å¤„ç†çš„ä»»åŠ¡")
            # ç¡®ä¿å³ä½¿å¼‚å¸¸ä¹Ÿè®¾ç½®æ­£ç¡®çš„çŠ¶æ€
            child_node.node_type = ReportGenerationState.a4
            return [child_node]
   
 

class Charts2Captions(DataStorytellingAction):
    def __init__(self):
        super().__init__("A5", "æ ¹æ®æ‰€æœ‰å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆæ‰€æœ‰å¯¹åº”Caption")
    
    def _get_image_base64(self, image_path: str) -> str:
        """å°†å›¾ç‰‡è½¬æ¢ä¸º base64 ç¼–ç """
        try:
            with Image.open(image_path) as img:
                # å°†å›¾ç‰‡è½¬æ¢ä¸º bytes
                img_byte_arr = io.BytesIO()
                img.save(img_byte_arr, format=img.format)
                img_byte_arr = img_byte_arr.getvalue()
                # è½¬æ¢ä¸º base64
                return base64.b64encode(img_byte_arr).decode('utf-8')
        except Exception as e:
            print(f"âŒ å›¾ç‰‡è½¬æ¢å¤±è´¥: {str(e)}")
            return None

    def call_vision_api(self, prompt, image_base64_list, **kwargs):
        """ç»Ÿä¸€å¤„ç†è§†è§‰APIè°ƒç”¨ï¼Œæ”¯æŒå•ä¸ªæˆ–å¤šä¸ªå›¾åƒ"""
        url = "https://gpt-api.hkust-gz.edu.cn/v1/chat/completions"
        headers = {
            "Content-Type": "application/json",
            "Authorization": "7ca9f48d315049bbad0b355afcd5f3a147a8395e46f249e3b7890ffa9ca5122c"
        }
        
        # å‡†å¤‡å›¾åƒå†…å®¹
        image_contents = []
        for img_base64 in (image_base64_list if isinstance(image_base64_list, list) else [image_base64_list]):
            image_contents.append({
                "type": "image_url",
                "image_url": {
                    "url": f"data:image/png;base64,{img_base64}"
                }
            })
        
        # æ„å»ºæ¶ˆæ¯
        messages = [
            {"role": "system", "content": "You are a data visualization expert."},
            {"role": "user", "content": [{"type": "text", "text": prompt}, *image_contents]}
        ]
        
        data = {
            "model": "gpt-4-turbo",
            "messages": messages,
            "temperature": kwargs.get("temperature", 0.7),
            "max_tokens": kwargs.get("max_tokens", 4096)
        }
        
        # è°ƒç”¨API
        try:
            response = requests.post(url, headers=headers, data=json.dumps(data))
            response_json = response.json()
            
            if 'choices' in response_json and response_json['choices']:
                return response_json['choices'][0]['message']['content'].strip()
            else:
                print(f"âŒ APIè¿”å›é”™è¯¯æˆ–æ— å“åº”: {response_json}")
        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {str(e)}")
            traceback.print_exc()
        
        return None
            
    def generate_chapter_caption_schemes(self, node, chapter, chapter_idx, charts, num_schemes=3, llm_kwargs=None):
        """ä¸ºå•ä¸ªç« èŠ‚çš„æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆï¼Œå…·æœ‰é‡è¯•æœºåˆ¶"""
        # è¿‡æ»¤å‡ºæˆåŠŸç”Ÿæˆçš„å›¾è¡¨
        successful_charts = []
        for chart in charts:
            # æŸ¥æ‰¾å¯¹åº”çš„visualization_task
            chart_task_id = getattr(chart, 'task_id', '')
            task_success = False
            
            # ä»å¯è§†åŒ–ä»»åŠ¡ä¸­æŸ¥æ‰¾ä¸å›¾è¡¨å…³è”çš„ä»»åŠ¡çŠ¶æ€
            if hasattr(chapter, 'visualization_tasks'):
                for task in chapter.visualization_tasks:
                    if task.get('task_id') == chart_task_id:
                        task_success = task.get('visualization_success', False)
                        break
            
            # åªæ·»åŠ æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
            if task_success:
                successful_charts.append(chart)
        
        # å¦‚æœç« èŠ‚å†…æ²¡æœ‰æˆåŠŸç”Ÿæˆçš„å›¾è¡¨ï¼Œç›´æ¥è¿”å›ç©º
        if not successful_charts:
            print(f"âš ï¸ ç« èŠ‚ {chapter_idx+1} æ²¡æœ‰æˆåŠŸç”Ÿæˆçš„å›¾è¡¨éœ€è¦å¤„ç†")
            return []
        
        print(f"\nğŸ”„ ä¸ºç« èŠ‚ {chapter_idx+1} ç”Ÿæˆ {num_schemes} å¥—è¯´æ˜æ–¹æ¡ˆ")
        print(f"ç« èŠ‚æ ‡é¢˜: {getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}')}")
        print(f"éœ€å¤„ç†çš„å›¾è¡¨æ•°é‡: {len(successful_charts)} (ä» {len(charts)} æ€»å›¾è¡¨ä¸­ç­›é€‰)")
        
        # å‡†å¤‡å›¾è¡¨ä¿¡æ¯æ–‡æœ¬å’Œå›¾åƒ
        charts_info = ""
        chart_images = []
        
        for i, chart in enumerate(successful_charts):
            charts_info += f"\nå›¾è¡¨{i}:"
            charts_info += f"\n- ç±»å‹: {chart.chart_type}"
            charts_info += f"\n- ä»»åŠ¡: {chart.task_id}"
            
            # è·å–å›¾è¡¨å›¾åƒæ•°æ®
            image_base64 = self._get_image_base64(chart.url)
            if image_base64:
                chart_images.append(image_base64)
            else:
                print(f"âŒ æ— æ³•è·å–å›¾è¡¨ {i} çš„å›¾åƒæ•°æ®")
        
        if not chart_images:
            print("âŒ æ²¡æœ‰å¯ç”¨çš„å›¾è¡¨å›¾åƒæ•°æ®")
            return []
            
        # å®ç°é‡è¯•æœºåˆ¶
        max_retries = 3
        for retry in range(max_retries):
            try:
                # ä½¿ç”¨æ¨¡æ¿æ–‡ä»¶ç”Ÿæˆæç¤ºè¯
                prompt_args = {
                    "QUERY": node.original_query,
                    "CHAPTER_TITLE": getattr(chapter, 'title', f'ç« èŠ‚{chapter_idx+1}'),
                    "DATA_CONTEXT": node.report.data_context,
                    "NUM_SCHEMES": str(num_schemes),
                    "CHARTS_INFO": charts_info,
                    "RETRY_NUM": str(retry + 1)  # å‘Šè¯‰æ¨¡å‹è¿™æ˜¯ç¬¬å‡ æ¬¡å°è¯•
                }
                
                # å¢å¼ºæç¤ºè¯
                prompt = get_prompt("chapter_captions", prompt_args)
                if retry > 0:
                    # å¯¹äºé‡è¯•ï¼Œå¢åŠ æ›´æ˜ç¡®çš„JSONæ ¼å¼è¦æ±‚
                    prompt += f"\n\nã€é‡è¦ã€‘è¿™æ˜¯ç¬¬{retry+1}æ¬¡å°è¯•ï¼Œè¯·åŠ¡å¿…ç¡®ä¿è¿”å›æœ‰æ•ˆçš„JSONæ ¼å¼ã€‚æ‚¨çš„å“åº”å¿…é¡»åŒ…å«å®Œæ•´çš„JSONç»“æ„ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š\n"
                    prompt += """
{
  "schemes": [
    {
      "scheme_id": 1,
      "captions": [
        {
          "chart_idx": 0,
          "caption": "å›¾è¡¨0çš„è¯´æ˜æ–‡å­—"
        },
        {
          "chart_idx": 1,
          "caption": "å›¾è¡¨1çš„è¯´æ˜æ–‡å­—"
        }
      ]
    },
    {
      "scheme_id": 2,
      "captions": [
        {
          "chart_idx": 0,
          "caption": "å¦ä¸€ç§å›¾è¡¨0çš„è¯´æ˜æ–‡å­—"
        },
        {
          "chart_idx": 1,
          "caption": "å¦ä¸€ç§å›¾è¡¨1çš„è¯´æ˜æ–‡å­—"
        }
      ]
    }
  ]
}
"""
                
                # è°ƒç”¨è§†è§‰API
                print(f"ğŸ”„ æ­£åœ¨è°ƒç”¨APIç”Ÿæˆç« èŠ‚ {chapter_idx+1} çš„è¯´æ˜æ–¹æ¡ˆ... (å°è¯• {retry+1}/{max_retries})")
                # é™ä½æ¸©åº¦ï¼Œæé«˜ç¡®å®šæ€§
                api_kwargs = llm_kwargs.copy() if llm_kwargs else {}
                api_kwargs['temperature'] = max(0.1, 0.7 - retry * 0.2)  # é€æ¸é™ä½æ¸©åº¦
                response_text = self.call_vision_api(prompt, chart_images, **api_kwargs)
                
                if not response_text:
                    print(f"âŒ ç« èŠ‚ {chapter_idx+1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº” (å°è¯• {retry+1}/{max_retries})")
                    if retry < max_retries - 1:
                        print("å°†åœ¨1ç§’åé‡è¯•...")
                        import time
                        time.sleep(1)
                        continue
                    else:
                        return []
                
                # è§£æJSONå“åº”
                print(f"ğŸ” LLMå“åº”ç‰‡æ®µ: {response_text[:200]}...")
                result = self.extract_json_from_text(response_text)
                
                if result and "schemes" in result:
                    schemes = result["schemes"]
                    print(f"âœ… æˆåŠŸä¸ºç« èŠ‚ {chapter_idx+1} ç”Ÿæˆ {len(schemes)} å¥—è¯´æ˜æ–¹æ¡ˆ")
                    return schemes
                
                print(f"âŒ æ— æ³•è§£æç« èŠ‚ {chapter_idx+1} çš„å›¾è¡¨è¯´æ˜æ–¹æ¡ˆ (å°è¯• {retry+1}/{max_retries})")
                if retry < max_retries - 1:
                    print("å°†åœ¨1ç§’åé‡è¯•...")
                    import time
                    time.sleep(1)
                else:
                    print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¯´æ˜æ–¹æ¡ˆ")
                    return []
                    
            except Exception as e:
                print(f"âŒ ç”Ÿæˆç« èŠ‚å›¾è¡¨è¯´æ˜æ–¹æ¡ˆå‡ºé”™: {str(e)} (å°è¯• {retry+1}/{max_retries})")
                traceback.print_exc()
                if retry < max_retries - 1:
                    print("å°†åœ¨1ç§’åé‡è¯•...")
                    import time
                    time.sleep(1)
                else:
                    print("å·²è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼Œæ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„è¯´æ˜æ–¹æ¡ˆ")
                    return []
        
        # æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥
        return []
    
    def extract_json_from_text(self, text):
        """ä»LLMå“åº”ä¸­æå–JSONï¼Œå…·æœ‰æ›´å¼ºçš„å®¹é”™èƒ½åŠ›"""
        try:
            # å…ˆå°è¯•æŸ¥æ‰¾JSONå—
            match = re.search(r'```json\s*([\s\S]*?)\s*```', text)
            if match:
                json_str = match.group(1)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONå—è§£æå¤±è´¥: {str(e)}ï¼Œå°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ")
                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    json_str = self._fix_json(json_str)
                    return json.loads(json_str)
            
            # å¦‚æœæ²¡æœ‰JSONå—ï¼Œå°è¯•å¯»æ‰¾æ•´ä¸ªæ–‡æœ¬ä¸­çš„JSONå¯¹è±¡
            match = re.search(r'(\{[\s\S]*\})', text)
            if match:
                json_str = match.group(1)
                try:
                    return json.loads(json_str)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ JSONå¯¹è±¡è§£æå¤±è´¥: {str(e)}ï¼Œå°è¯•ä¿®å¤å¹¶é‡æ–°è§£æ")
                    # å°è¯•ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜
                    json_str = self._fix_json(json_str)
                    return json.loads(json_str)
            
            # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–schemeséƒ¨åˆ†
            schemes_match = re.search(r'"schemes"\s*:\s*(\[[\s\S]*?\])', text)
            if schemes_match:
                schemes_str = schemes_match.group(1)
                print(f"âœ“ æå–åˆ°schemesæ•°ç»„ï¼Œå°è¯•æ„å»ºå®Œæ•´JSON")
                try:
                    # æ„å»ºä¸€ä¸ªæ–°çš„JSON
                    new_json = f'{{"schemes": {schemes_str}}}'
                    return json.loads(new_json)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸ æå–çš„schemesè§£æå¤±è´¥: {str(e)}")
            
            # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å®Œæ•´ç»“æ„ï¼Œå°è¯•æ‰‹åŠ¨æå–æ¯ä¸ªcaption
            captions = re.findall(r'(?:chart_idx|å›¾è¡¨ç´¢å¼•)["\s:]+(\d+)[\s"]*(?:,|\})[\s\S]*?(?:caption|è¯´æ˜æ–‡å­—)["\s:]+([^"]*?)[",$}]', text)
            if captions:
                print(f"âœ“ æ‰‹åŠ¨æå–åˆ° {len(captions)} ä¸ªcaptionæ¡ç›®")
                manual_scheme = {
                    "scheme_id": 1,
                    "captions": []
                }
                
                for chart_idx_str, caption in captions:
                    try:
                        chart_idx = int(chart_idx_str)
                        manual_scheme["captions"].append({
                            "chart_idx": chart_idx,
                            "caption": caption.strip()
                        })
                    except ValueError:
                        pass
                
                if manual_scheme["captions"]:
                    return {"schemes": [manual_scheme]}
            
            return None
        except Exception as e:
            print(f"âŒ JSONè§£æé”™è¯¯: {str(e)}")
            traceback.print_exc()
            return None
    
    def _fix_json(self, json_str):
        """ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é—®é¢˜"""
        # ä¿®å¤ç¼ºå°‘é€—å·çš„é—®é¢˜
        json_str = re.sub(r'}\s*{', '},{', json_str)
        json_str = re.sub(r']\s*\[', '],[', json_str)
        
        # ä¿®å¤å¤šä½™çš„é€—å·
        json_str = re.sub(r',\s*}', '}', json_str)
        json_str = re.sub(r',\s*]', ']', json_str)
        
        # ç¡®ä¿å±æ€§åæœ‰å¼•å·
        json_str = re.sub(r'([{,]\s*)(\w+)(\s*:)', r'\1"\2"\3', json_str)
        
        # ä¿®å¤è½¬ä¹‰é—®é¢˜
        json_str = json_str.replace('\\"', '"').replace('\\\\', '\\')
        
        return json_str
    
    def generate_combined_nodes(self, node, all_chapter_schemes, max_nodes=3):
        """ç”Ÿæˆå­èŠ‚ç‚¹ç»„åˆ - ä½¿ç”¨ç®€å•ç­–ç•¥ï¼šå…¨éƒ¨ç« èŠ‚ä½¿ç”¨ç¬¬nå¥—æ–¹æ¡ˆ"""
        if not all_chapter_schemes:
            return []
        
        children_nodes = []
        
        # è®¡ç®—æ¯ä¸ªç« èŠ‚æœ€å¤šæœ‰å‡ å¥—æ–¹æ¡ˆ
        max_schemes = max([len(chapter_data["schemes"]) for chapter_data in all_chapter_schemes], default=0)
        
        # ç­–ç•¥ï¼šæ‰€æœ‰ç« èŠ‚ä½¿ç”¨åŒä¸€å¥—æ–¹æ¡ˆç¼–å·ï¼ˆå…¨éƒ¨ç”¨æ–¹æ¡ˆ1ï¼Œå…¨éƒ¨ç”¨æ–¹æ¡ˆ2...ï¼‰
        for scheme_idx in range(min(max_schemes, max_nodes)):
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            child_node.node_type = ReportGenerationState.a5
            
            caption_applied = False  # è·Ÿè¸ªæ˜¯å¦åº”ç”¨äº†ä»»ä½•è¯´æ˜
            
            # å¯¹æ¯ä¸ªç« èŠ‚åº”ç”¨ç›¸åŒç¼–å·çš„æ–¹æ¡ˆ
            for chapter_data in all_chapter_schemes:
                chapter_idx = chapter_data["chapter_idx"]
                schemes = chapter_data["schemes"]
                
                # å¦‚æœæ­¤ç« èŠ‚æœ‰å¯¹åº”ç¼–å·çš„æ–¹æ¡ˆ
                if 0 <= scheme_idx < len(schemes):
                    scheme = schemes[scheme_idx]
                    chapter = child_node.report.chapters[chapter_idx]
                    
                    print(f"ğŸ”„ ä¸ºå­èŠ‚ç‚¹{scheme_idx+1}åº”ç”¨ç« èŠ‚{chapter_idx+1}çš„æ–¹æ¡ˆ{scheme.get('scheme_id', scheme_idx+1)}")
                    
                    # åº”ç”¨æ­¤æ–¹æ¡ˆä¸­çš„æ‰€æœ‰å›¾è¡¨è¯´æ˜
                    for caption_info in scheme.get("captions", []):
                        chart_idx = caption_info.get("chart_idx")
                        caption = caption_info.get("caption", "")
                        
                        if hasattr(chapter, 'charts') and 0 <= chart_idx < len(chapter.charts):
                            chart = chapter.charts[chart_idx]
                            chart.caption = caption
                            chart.needs_caption = False
                            caption_applied = True
                            
                            # æ›´æ–°ä»»åŠ¡çŠ¶æ€
                            if hasattr(chapter, 'visualization_tasks'):
                                for task in chapter.visualization_tasks:
                                    if task.get('task_id') == chart.task_id:
                                        task['status'] = 'completed'
                                        task['caption_generated'] = True
                                        break
                        
            if caption_applied:  # åªæœ‰å½“åº”ç”¨äº†è¯´æ˜æ—¶æ‰æ·»åŠ èŠ‚ç‚¹
                child_node.caption_strategy = f"ç»Ÿä¸€æ–¹æ¡ˆ{scheme_idx+1}"
                children_nodes.append(child_node)
                print(f"âœ… æˆåŠŸåˆ›å»ºå­èŠ‚ç‚¹ {scheme_idx+1}ï¼Œä½¿ç”¨ç»Ÿä¸€æ–¹æ¡ˆ {scheme_idx+1}")
        
        return children_nodes

    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ä¸ºå›¾è¡¨ç”Ÿæˆè¯´æ˜æ–‡å­—ï¼ŒæŒ‰ç« èŠ‚å¤„ç†å¹¶ç”Ÿæˆå¤šä¸ªå­èŠ‚ç‚¹"""
        # æ”¶é›†éœ€è¦å¤„ç†çš„ç« èŠ‚åŠå…¶å›¾è¡¨
        chapters_with_charts = []
        for chapter_idx, chapter in enumerate(node.report.chapters):
            if not hasattr(chapter, 'charts') or not chapter.charts:
                continue
                
            # æ”¶é›†éœ€è¦ç”Ÿæˆè¯´æ˜çš„å›¾è¡¨
            charts_needing_captions = []
            for chart in chapter.charts:
                if not hasattr(chart, 'caption') or not chart.caption:
                    # æŸ¥æ‰¾è¯¥å›¾è¡¨å¯¹åº”çš„ä»»åŠ¡çŠ¶æ€
                    chart_task_id = getattr(chart, 'task_id', '')
                    task_success = False
                    
                    # ä»å¯è§†åŒ–ä»»åŠ¡ä¸­æŸ¥æ‰¾ä¸å›¾è¡¨å…³è”çš„ä»»åŠ¡çŠ¶æ€
                    if hasattr(chapter, 'visualization_tasks'):
                        for task in chapter.visualization_tasks:
                            if task.get('task_id') == chart_task_id:
                                task_success = task.get('visualization_success', False)
                                break
                # åªå¤„ç†æˆåŠŸç”Ÿæˆçš„å›¾è¡¨
                if task_success:
                    charts_needing_captions.append(chart)
                else:
                    print(f"âš ï¸ è·³è¿‡å›¾è¡¨ {chart_task_id}ï¼Œå› ä¸ºå®ƒçš„ç”ŸæˆçŠ¶æ€ä¸ºå¤±è´¥")
            if charts_needing_captions:
                chapters_with_charts.append({
                    "chapter_idx": chapter_idx,
                    "chapter": chapter,
                    "charts": charts_needing_captions
                })
                print(f"âœ… ç« èŠ‚ {chapter_idx+1} æœ‰ {len(charts_needing_captions)} ä¸ªå›¾è¡¨éœ€è¦ç”Ÿæˆè¯´æ˜")
        
        if not chapters_with_charts:
            # æ²¡æœ‰éœ€è¦å¤„ç†çš„å›¾è¡¨ï¼Œè¿”å›åŸèŠ‚ç‚¹
            print("æ²¡æœ‰éœ€è¦ç”Ÿæˆè¯´æ˜çš„å›¾è¡¨ï¼Œè¿”å›åŸèŠ‚ç‚¹")
            node.node_type = ReportGenerationState.a5
            return [node]
        
        # å¯¹æ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆ
        all_chapter_schemes = []
        for chapter_info in chapters_with_charts:
            chapter_idx = chapter_info["chapter_idx"]
            chapter = chapter_info["chapter"]
            charts = chapter_info["charts"]
            
            # ä¸ºè¯¥ç« èŠ‚æ‰€æœ‰å›¾è¡¨ç”Ÿæˆå¤šå¥—è¯´æ˜æ–¹æ¡ˆ
            chapter_schemes = self.generate_chapter_caption_schemes(
                node,
                chapter, 
                chapter_idx,
                charts, 
                num_schemes=3,  # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆ3ç§ä¸åŒçš„è¯´æ˜æ–¹æ¡ˆ
                llm_kwargs=llm_kwargs
            )
            
            if chapter_schemes:
                all_chapter_schemes.append({
                    "chapter_idx": chapter_idx,
                    "schemes": chapter_schemes
                })
                print(f"âœ… ç« èŠ‚ {chapter_idx} æˆåŠŸç”Ÿæˆ {len(chapter_schemes)} å¥—è¯´æ˜æ–¹æ¡ˆ")
            else:
                print(f"âŒ ç« èŠ‚ {chapter_idx} ç”Ÿæˆè¯´æ˜æ–¹æ¡ˆå¤±è´¥")
        
        # ç”Ÿæˆå­èŠ‚ç‚¹ç»„åˆ - ä½¿ç”¨ç®€å•ç­–ç•¥ï¼šå…¨éƒ¨ç« èŠ‚ä½¿ç”¨ç¬¬nå¥—æ–¹æ¡ˆ
        children_nodes = self.generate_combined_nodes(node, all_chapter_schemes)
        
        if not children_nodes:
            # å¦‚æœæ²¡æœ‰æˆåŠŸç”Ÿæˆå­èŠ‚ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªåŸºæœ¬èŠ‚ç‚¹
            print("âŒ æ— æ³•ç”Ÿæˆæœ‰æ•ˆçš„å­èŠ‚ç‚¹ç»„åˆï¼Œå°†è¿”å›åŸºæœ¬èŠ‚ç‚¹")
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            child_node.node_type = ReportGenerationState.a5
            return [child_node]
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ {len(children_nodes)} ä¸ªå­èŠ‚ç‚¹")
        return children_nodes


class Captions2Summaries(DataStorytellingAction):
    def __init__(self):
        super().__init__("A6", "æ ¹æ®æ¯ä¸ªç« èŠ‚çš„Captionç”Ÿæˆæ¯ä¸ªç« èŠ‚çš„æ€»ç»“")
        self.use_unified_framework = True  # æ˜¯å¦ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_summary_prompt(self, node, chapter_idx=None, **kwargs):
        """ç”Ÿæˆç« èŠ‚æ€»ç»“æç¤ºè¯"""
        # å¦‚æœæŒ‡å®šäº†ç« èŠ‚ç´¢å¼•ï¼Œç”Ÿæˆç‰¹å®šç« èŠ‚çš„æç¤ºè¯
        if chapter_idx is not None and 0 <= chapter_idx < len(node.report.chapters):
            chapter = node.report.chapters[chapter_idx]
            chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
            
            # æ”¶é›†æœ¬ç« èŠ‚æ‰€æœ‰å›¾è¡¨åŠå…¶è¯´æ˜
            visualization_tasks = []
            if hasattr(chapter, 'visualization_tasks'):
                for task in chapter.visualization_tasks:
                    task_info = {
                        'description': task.get('task_description', ''),
                        'charts': []
                    }
                    
                    # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨
                    if hasattr(chapter, 'charts') and chapter.charts:
                        # æŸ¥æ‰¾ä¸ä»»åŠ¡å…³è”çš„å›¾è¡¨
                        for chart in chapter.charts:
                            if hasattr(chart, 'task_id') and chart.task_id == task.get('task_id'):
                                # æ£€æŸ¥è¯¥å›¾è¡¨ä»»åŠ¡æ˜¯å¦æˆåŠŸå®Œæˆ
                                task_success = False
                                for t in chapter.visualization_tasks:
                                    if t.get('task_id') == chart.task_id and t.get('visualization_success', False):
                                        task_success = True
                                        break
                                
                                if task_success:
                                    caption = getattr(chart, 'caption', 'æ— è¯´æ˜æ–‡å­—')
                                    task_info['charts'].append({
                                        'caption': caption
                                    })
                    
                    # åªæ·»åŠ æœ‰å›¾è¡¨çš„ä»»åŠ¡
                    if task_info['charts']:
                        visualization_tasks.append(task_info)
            
            # å‡†å¤‡æç¤ºè¯å‚æ•°
            prompt_args = {
                "QUERY": node.original_query,
                "CHAPTER_TITLE": chapter_title,
                "visualization_tasks": json.dumps(visualization_tasks, ensure_ascii=False, indent=2)
            }
            
            return get_prompt("chapter_summary", prompt_args)
        
        # å¦‚æœæ²¡æœ‰æŒ‡å®šç« èŠ‚ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
        return {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "DATA_CONTEXT": node.report.data_context
        }
    
    def apply_summaries(self, node, action, cluster, **kwargs):
        """å°†ç« èŠ‚æ€»ç»“åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        # åˆ›å»ºå­èŠ‚ç‚¹
        child_node = copy.deepcopy(node)
        child_node.parent_node = node
        child_node.parent_action = action
        child_node.depth = node.depth + 1
        
        try:
            # ä»èšç±»ä¸­è·å–æ¯ä¸ªç« èŠ‚çš„æ€»ç»“
            if "chapter_summaries" in cluster:
                chapter_summaries = cluster["chapter_summaries"]
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                success_count = 0
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(child_node.report.chapters):
                        chapter = child_node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… å·²åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                if success_count > 0:
                    child_node.node_type = ReportGenerationState.FINALIZED
                    return [child_node]
            
            # å¦‚æœæ²¡æœ‰ä»èšç±»ä¸­è·å–åˆ°æ€»ç»“ï¼Œå°è¯•è‡ªè¡Œå¤„ç†
            print("âš ï¸ æœªä»èšç±»ä¸­è·å–åˆ°ç« èŠ‚æ€»ç»“ï¼Œå°è¯•è‡ªè¡Œå¤„ç†...")
            success = self.process_all_chapters(child_node, **kwargs)
            
            if success:
                # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            else:
                print("âŒ å¤„ç†ç« èŠ‚æ€»ç»“å¤±è´¥")
                return None
                
        except Exception as e:
            print(f"âŒ åº”ç”¨ç« èŠ‚æ€»ç»“æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def generate_chapter_summaries(self, node, llm_kwargs, n=3):
        """ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“"""
        all_chapter_summaries = []
        
        # éå†æ‰€æœ‰ç« èŠ‚
        for chapter_idx, chapter in enumerate(node.report.chapters):
            # å®‰å…¨åœ°è·å–ç« èŠ‚æ ‡é¢˜
            chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
            
            print(f"\nğŸ“‘ æ­£åœ¨ä¸ºç¬¬ {chapter_idx + 1} ç« ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“...")
            print(f"ç« èŠ‚æ ‡é¢˜: {chapter_title}")
            
            # æ£€æŸ¥è¯¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨åŠè¯´æ˜
            has_captions = False
            if hasattr(chapter, 'charts') and chapter.charts:
                for chart in chapter.charts:
                    if hasattr(chart, 'caption') and chart.caption:
                        has_captions = True
                        break
            
            if not has_captions:
                print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å›¾è¡¨æˆ–è¯´æ˜æ–‡å­—ï¼Œè·³è¿‡")
                continue
                
            # ç”Ÿæˆè¯¥ç« èŠ‚çš„æç¤ºè¯
            prompt = self.generate_summary_prompt(node, chapter_idx=chapter_idx)
            
            # æ”¶é›†è¯¥ç« èŠ‚çš„å¤šä¸ªå€™é€‰æ€»ç»“
            chapter_summaries = []
            
            for i in range(n):
                # ä¸ºæ¯ä¸ªå€™é€‰ä½¿ç”¨ä¸åŒçš„æ¸©åº¦
                llm_kwargs_temp = llm_kwargs.copy()
                llm_kwargs_temp['temperature'] = 0.3 + i * 0.2  # 0.3, 0.5, 0.7
                
                print(f"ğŸ”„ ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1}/{n} (æ¸©åº¦: {llm_kwargs_temp['temperature']})")
                
                responses = call_openai(prompt, **llm_kwargs_temp)
                if responses:
                    summary = responses[0].strip()
                    
                    # æ”¶é›†å€™é€‰æ€»ç»“
                    chapter_summaries.append({
                        "chapter_idx": chapter_idx,
                        "summary": summary,
                        "variant_id": i
                    })
                    
                    print(f"âœ… æˆåŠŸç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1}")
                else:
                    print(f"âŒ ç¬¬ {chapter_idx + 1} ç« çš„å€™é€‰æ€»ç»“ {i+1} ç”Ÿæˆå¤±è´¥")
            
            # å¦‚æœæˆåŠŸç”Ÿæˆäº†å€™é€‰æ€»ç»“ï¼Œæ·»åŠ åˆ°åˆ—è¡¨ä¸­
            if chapter_summaries:
                all_chapter_summaries.append({
                    "chapter_idx": chapter_idx,
                    "chapter_title": chapter_title,
                    "candidate_summaries": chapter_summaries
                })
        
        return all_chapter_summaries
    
    def cluster_chapter_summaries(self, all_chapter_summaries, llm_kwargs):
        """å¯¹æ¯ä¸ªç« èŠ‚çš„å€™é€‰æ€»ç»“è¿›è¡Œèšç±»ï¼Œå¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“"""
        if not all_chapter_summaries:
            return []
        
        try:
            # å‡†å¤‡èšç±»æ•°æ®
            formatting_data = []
            for chapter_data in all_chapter_summaries:
                chapter_idx = chapter_data["chapter_idx"]
                chapter_title = chapter_data["chapter_title"]
                candidates = chapter_data["candidate_summaries"]
                
                # è½¬æ¢ä¸ºèšç±»æ‰€éœ€çš„æ ¼å¼
                formatted_candidates = [
                    {
                        "index": candidate["variant_id"],
                        "chapter_idx": chapter_idx,
                        "summary": candidate["summary"]
                    }
                    for candidate in candidates
                ]
                
                formatting_data.append({
                    "chapter_idx": chapter_idx,
                    "chapter_title": chapter_title,
                    "candidates": formatted_candidates
                })
            
            # ä½¿ç”¨æ¨¡æ¿æ–‡ä»¶ç”Ÿæˆèšç±»æç¤ºè¯
            prompt_args = {
                "CHAPTER_SUMMARIES_DATA": json.dumps(formatting_data, ensure_ascii=False, indent=2)
            }
            
            clustering_prompt = get_prompt("chapter_summary_clustering", prompt_args)
            
            # è°ƒç”¨ LLM è¿›è¡Œèšç±»
            print("\nğŸ” æ­£åœ¨å¯¹ç« èŠ‚æ€»ç»“è¿›è¡Œèšç±»åˆ†æ...")
            responses = call_openai(clustering_prompt, **llm_kwargs)
            
            if not responses:
                print("âŒ èšç±»åˆ†ææ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                return []
            
            # è§£æå“åº”
            clustering_response = responses[0]
            
            # æå– JSON éƒ¨åˆ†
            import re
            json_match = re.search(r'```json\s*([\s\S]*?)\s*```', clustering_response)
            if json_match:
                json_str = json_match.group(1)
            else:
                json_str = clustering_response
            
            try:
                # è§£æ JSON
                clustering_result = json.loads(json_str)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æœ‰æ•ˆçš„èšç±»ç»“æœ
                if "clusters" in clustering_result and clustering_result["clusters"]:
                    print(f"âœ… æˆåŠŸè·å– {len(clustering_result['clusters'])} ä¸ªèšç±»")
                    return clustering_result["clusters"]
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSON è§£æé”™è¯¯: {str(e)}")
                print(f"âŒ åŸå§‹å“åº”:\n{clustering_response}")
        
        except Exception as e:
            print(f"âŒ èšç±»ç« èŠ‚æ€»ç»“æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
        
        return []
    
    def process_all_chapters(self, node, **kwargs):
        """å¤„ç†æ‰€æœ‰ç« èŠ‚ï¼Œä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆæ€»ç»“"""
        llm_kwargs = kwargs.get("llm_kwargs", {})
        
        try:
            # å¦‚æœæ˜¯ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶å¹¶ä¸”æœ‰å¤šä¸ªå€™é€‰æ€»ç»“
            if self.use_unified_framework:
                # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“
                all_chapter_summaries = self.generate_chapter_summaries(node, llm_kwargs)
                
                if not all_chapter_summaries:
                    print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç« èŠ‚çš„å€™é€‰æ€»ç»“")
                    return False
                
                # å¯¹å€™é€‰æ€»ç»“è¿›è¡Œèšç±»å¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“
                clusters = self.cluster_chapter_summaries(all_chapter_summaries, llm_kwargs)
                
                if not clusters:
                    print("âŒ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„èšç±»ç»“æœ")
                    return False
                
                # åº”ç”¨ç¬¬ä¸€ä¸ªèšç±»çš„ç»“æœ
                cluster = clusters[0]
                print(f"âœ… åº”ç”¨èšç±» {cluster.get('cluster_id', 'æœªçŸ¥')} çš„æ€»ç»“ç»“æœ")
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                chapter_summaries = cluster.get("chapter_summaries", [])
                success_count = 0
                
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(node.report.chapters):
                        chapter = node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… å·²åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                return success_count > 0
            else:
                # åŸæœ‰çš„é€»è¾‘ï¼ˆæœªä½¿ç”¨ç»Ÿä¸€æ¡†æ¶ï¼‰
                success_count = 0

                # éå†æ‰€æœ‰ç« èŠ‚
                for chapter_idx, chapter in enumerate(node.report.chapters):
                    # å®‰å…¨åœ°è·å–ç« èŠ‚æ ‡é¢˜
                    chapter_title = getattr(chapter, 'title', f"ç« èŠ‚{chapter_idx+1}") if not isinstance(chapter, dict) else chapter.get('title', f"ç« èŠ‚{chapter_idx+1}")
                    
                    print(f"\nğŸ“‘ æ­£åœ¨å¤„ç†ç¬¬ {chapter_idx + 1} ç« : {chapter_title}")
                    
                    # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å¯è§†åŒ–ä»»åŠ¡
                    if not hasattr(chapter, 'visualization_tasks') or not chapter.visualization_tasks:
                        print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡")
                        continue
                    
                    # æ”¶é›†æœ¬ç« èŠ‚æ‰€æœ‰å›¾è¡¨åŠå…¶è¯´æ˜
                    visualization_tasks = []
                    for task in chapter.visualization_tasks:
                        task_info = {
                            'description': task.get('task_description', ''),
                            'charts': []
                        }
                        
                        # æ£€æŸ¥ç« èŠ‚æ˜¯å¦æœ‰å›¾è¡¨
                        if not hasattr(chapter, 'charts') or not chapter.charts:
                            continue
                            
                        # æŸ¥æ‰¾ä¸ä»»åŠ¡å…³è”çš„å›¾è¡¨
                        for chart in chapter.charts:
                            if hasattr(chart, 'task_id') and chart.task_id == task.get('task_id'):
                                caption = getattr(chart, 'caption', 'æ— è¯´æ˜æ–‡å­—')
                                task_info['charts'].append({
                                    'caption': caption
                                })
                        
                        # åªæ·»åŠ æœ‰å›¾è¡¨çš„ä»»åŠ¡
                        if task_info['charts']:
                            visualization_tasks.append(task_info)
                    
                    # å¦‚æœæ²¡æœ‰æ”¶é›†åˆ°ä»»ä½•æœ‰æ•ˆçš„å¯è§†åŒ–ä»»åŠ¡ï¼Œè·³è¿‡æ­¤ç« èŠ‚
                    if not visualization_tasks:
                        print(f"âš ï¸ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰æœ‰æ•ˆçš„å¯è§†åŒ–ä»»åŠ¡å›¾è¡¨ï¼Œè·³è¿‡")
                        continue
                    
                    # å‡†å¤‡ prompt
                    prompt_args = {
                        "QUERY": node.original_query,
                        "CHAPTER_TITLE": chapter_title,
                        "visualization_tasks": json.dumps(visualization_tasks, ensure_ascii=False, indent=2)
                    }
                    
                    prompt = get_prompt("chapter_summary", prompt_args)
                    
                    # è°ƒç”¨ LLM ç”Ÿæˆæ‘˜è¦
                    responses = call_openai(prompt, **llm_kwargs)
                    if not responses:
                        print(f"âŒ ç« èŠ‚ {chapter_idx + 1} æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆå“åº”")
                        continue
                    
                    summary = responses[0].strip()
                    
                    print(f"\nğŸ“ ç¬¬ {chapter_idx + 1} ç« çš„æ‘˜è¦:")
                    print("-" * 50)
                    print(summary)
                    print("-" * 50)
                    
                    # ä¿å­˜æ‘˜è¦åˆ°ç« èŠ‚
                    chapter.summary = summary
                    print(f"âœ… å·²ç”Ÿæˆç¬¬ {chapter_idx + 1} ç« çš„æ‘˜è¦")
                    success_count += 1

                return success_count > 0
                
        except Exception as e:
            print(f"âŒ ç”Ÿæˆç« èŠ‚æ‘˜è¦æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return False
                
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        if self.use_unified_framework:
            # ä¸ºæ¯ä¸ªç« èŠ‚ç”Ÿæˆå¤šä¸ªå€™é€‰æ€»ç»“
            all_chapter_summaries = self.generate_chapter_summaries(node, llm_kwargs)
            
            if not all_chapter_summaries:
                print("âŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç« èŠ‚çš„å€™é€‰æ€»ç»“ï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            
            # å¯¹å€™é€‰æ€»ç»“è¿›è¡Œèšç±»å¹¶é€‰æ‹©æœ€ä¼˜æ€»ç»“
            clusters = self.cluster_chapter_summaries(all_chapter_summaries, llm_kwargs)
            
            if not clusters:
                print("âŒ æ²¡æœ‰è·å–åˆ°æœ‰æ•ˆçš„èšç±»ç»“æœï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            
            # ä¸ºæ¯ä¸ªèšç±»åˆ›å»ºä¸€ä¸ªå­èŠ‚ç‚¹
            children_nodes = []
            
            for cluster_idx, cluster in enumerate(clusters):
                cluster_id = cluster.get("cluster_id", f"cluster_{cluster_idx+1}")
                
                print(f"ğŸ”„ æ­£åœ¨ä¸ºèšç±» {cluster_id} åˆ›å»ºå­èŠ‚ç‚¹")
                
                # åˆ›å»ºå­èŠ‚ç‚¹
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                
                # åº”ç”¨ç« èŠ‚æ€»ç»“
                chapter_summaries = cluster.get("chapter_summaries", [])
                success_count = 0
                
                for chapter_summary in chapter_summaries:
                    chapter_idx = chapter_summary.get("chapter_idx", -1)
                    summary = chapter_summary.get("summary", "")
                    
                    if 0 <= chapter_idx < len(child_node.report.chapters):
                        chapter = child_node.report.chapters[chapter_idx]
                        chapter.summary = summary
                        success_count += 1
                        print(f"âœ… ä¸ºèšç±» {cluster_id} åº”ç”¨ç¬¬ {chapter_idx + 1} ç« çš„æ€»ç»“")
                
                if success_count > 0:
                    # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
                    child_node.node_type = ReportGenerationState.FINALIZED
                    child_node.summary_cluster_id = cluster_id
                    children_nodes.append(child_node)
                    print(f"âœ… æˆåŠŸåˆ›å»ºèšç±» {cluster_id} çš„å­èŠ‚ç‚¹")
            
            # å¦‚æœæ²¡æœ‰åˆ›å»ºä»»ä½•å­èŠ‚ç‚¹ï¼Œåˆ›å»ºä¸€ä¸ªé»˜è®¤èŠ‚ç‚¹
            if not children_nodes:
                print("âŒ æ²¡æœ‰åˆ›å»ºä»»ä½•æœ‰æ•ˆçš„å­èŠ‚ç‚¹ï¼Œåˆ›å»ºé»˜è®¤èŠ‚ç‚¹")
                child_node = copy.deepcopy(node)
                child_node.parent_node = node
                child_node.parent_action = self
                child_node.depth = node.depth + 1
                child_node.node_type = ReportGenerationState.FINALIZED
                return [child_node]
            
            return children_nodes
        else:
            # åŸæœ‰å®ç°ï¼ˆä¿ç•™ä»¥ä¾¿å…¼å®¹ï¼‰
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = self
            child_node.depth = node.depth + 1
            
            # å¤„ç†æ‰€æœ‰ç« èŠ‚çš„æ€»ç»“
            self.process_all_chapters(child_node, llm_kwargs=llm_kwargs)
        
        # è®¾ç½®æœ€ç»ˆçŠ¶æ€
        child_node.node_type = ReportGenerationState.FINALIZED
        
        return [child_node]
    
class ReviseNarrativeStrategy(DataStorytellingAction):
    def __init__(self):
        super().__init__("NarrativeStrategy", "è°ƒæ•´æŠ¥å‘Šå™äº‹ç­–ç•¥ï¼Œé‡æ–°æ’åºç« èŠ‚")
        self.use_unified_framework = True  # ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_narrative_prompt(self, node, **kwargs):
        """ç”Ÿæˆå™äº‹ç­–ç•¥æç¤ºè¯"""
        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapters_info = []
        for i, chapter in enumerate(node.report.chapters):
            chapter_info = {
                "index": i,
                "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}"),
                "summary": getattr(chapter, 'summary', "") if hasattr(chapter, 'summary') else ""
            }
            chapters_info.append(chapter_info)
        
        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        prompt_args = {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "CHAPTERS": json.dumps(chapters_info, ensure_ascii=False, indent=2)
        }
        
        return get_prompt("revise_narrative", prompt_args)
    
    def apply_narrative_strategy(self, node, action, cluster, **kwargs):
        """å°†å™äº‹ç­–ç•¥åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–å™äº‹ç­–ç•¥å’Œç« èŠ‚é¡ºåº
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            strategy = cluster.get("strategy", "")
            strategy_reason = cluster.get("strategy_reason", "")
            chapter_order = cluster.get("chapter_order", [])
            
            if not chapter_order:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰ç« èŠ‚é¡ºåºä¿¡æ¯ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“˜ åº”ç”¨èšç±» {cluster_id} çš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ")
            print(f"   ç­–ç•¥: {strategy}")
            print(f"   åŸå› : {strategy_reason}")
            
            # éªŒè¯ç« èŠ‚é¡ºåº
            if len(chapter_order) != len(node.report.chapters):
                print(f"âš ï¸ ç« èŠ‚æ•°é‡ä¸åŒ¹é…: æœŸæœ› {len(node.report.chapters)}, å®é™… {len(chapter_order)}")
                return None
                
            # æ ¹æ®æ–°é¡ºåºé‡æ’ç« èŠ‚
            new_chapters = []
            for chapter_info in chapter_order:
                original_index = chapter_info.get("original_index")
                if not isinstance(original_index, int) or original_index < 0 or original_index >= len(node.report.chapters):
                    print(f"âš ï¸ æ— æ•ˆçš„ç« èŠ‚ç´¢å¼•: {original_index}")
                    continue
                
                new_chapters.append(copy.deepcopy(node.report.chapters[original_index]))
                print(f"   - ç§»åŠ¨ç« èŠ‚ '{chapter_info.get('title', '')}' åˆ°æ–°ä½ç½®")
                print(f"     åŸå› : {chapter_info.get('reason', 'æœªæä¾›')}")
            
            # å¦‚æœæ²¡æœ‰æˆåŠŸé‡æ’æ‰€æœ‰ç« èŠ‚ï¼Œè·³è¿‡æ­¤èšç±»
            if len(new_chapters) != len(node.report.chapters):
                print(f"âš ï¸ ç« èŠ‚é‡æ’ä¸å®Œæ•´ï¼Œè·³è¿‡æ­¤èšç±»")
                return None
            
            # æ›´æ–°æŠ¥å‘Šçš„ç« èŠ‚é¡ºåºå’Œå™äº‹ç­–ç•¥
            child_node.report.chapters = new_chapters
            child_node.report.narrative_strategy = {
                "strategy": strategy,
                "strategy_reason": strategy_reason,
                "cluster_id": cluster_id
            }
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.REVISECHAPTERSORDERS
            
            print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨å™äº‹ç­–ç•¥æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ç”Ÿæˆå¤šä¸ªå™äº‹ç­–ç•¥æ–¹æ¡ˆå¹¶èšç±»é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"""
        return unified_generation_framework(
            node=node,
            action=self,
            llm_kwargs=llm_kwargs,
            action_type="narrative",
            prompt_generator=self.generate_narrative_prompt,
            node_applier=self.apply_narrative_strategy,
            n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„å™äº‹ç­–ç•¥æ–¹æ¡ˆ
        )


class TransitionAction(DataStorytellingAction):
    def __init__(self):
        super().__init__("Transition", "æ·»åŠ ç« èŠ‚é—´è¿‡æ¸¡æ–‡æœ¬ï¼Œæé«˜æŠ¥å‘Šè¿è´¯æ€§")
        self.use_unified_framework = True  # ä½¿ç”¨ç»Ÿä¸€æ¡†æ¶
    
    def generate_transition_prompt(self, node, **kwargs):
        """ç”Ÿæˆè¿‡æ¸¡æ–‡æœ¬æç¤ºè¯"""
        # å‡†å¤‡ç« èŠ‚ä¿¡æ¯
        chapters_info = []
        for i, chapter in enumerate(node.report.chapters):
            chapter_info = {
                "index": i,
                "title": getattr(chapter, 'title', f"ç« èŠ‚{i+1}"),
                "summary": getattr(chapter, 'summary', "") if hasattr(chapter, 'summary') else "",
                "charts_captions": [
                    getattr(chart, 'caption', "") for chart in getattr(chapter, 'charts', [])
                ]
            }
            chapters_info.append(chapter_info)
        
        # ä½¿ç”¨æ¨¡æ¿ç”Ÿæˆæç¤ºè¯
        prompt_args = {
            "QUERY": node.report.clarified_query if node.report.clarified_query else node.report.original_query,
            "CHAPTERS": json.dumps(chapters_info, ensure_ascii=False, indent=2),
            "NARRATIVE_STRATEGY": json.dumps(getattr(node.report, 'narrative_strategy', {}), ensure_ascii=False, indent=2)
        }
        
        return get_prompt("add_transitions", prompt_args)
    
    def apply_transitions(self, node, action, cluster, **kwargs):
        """å°†è¿‡æ¸¡æ–‡æœ¬åº”ç”¨åˆ°å­èŠ‚ç‚¹"""
        try:
            # åˆ›å»ºå­èŠ‚ç‚¹
            child_node = copy.deepcopy(node)
            child_node.parent_node = node
            child_node.parent_action = action
            child_node.depth = node.depth + 1
            
            # è·å–è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ
            cluster_id = cluster.get("cluster_id", "æœªçŸ¥")
            transitions = cluster.get("transitions", [])
            
            if not transitions:
                print(f"âš ï¸ èšç±» {cluster_id} æ²¡æœ‰è¿‡æ¸¡æ–‡æœ¬ä¿¡æ¯ï¼Œè·³è¿‡")
                return None
            
            print(f"ğŸ“ åº”ç”¨èšç±» {cluster_id} çš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ")
            
            # åº”ç”¨è¿‡æ¸¡æ–‡æœ¬
            success_count = 0
            for transition in transitions:
                chapter_idx = transition.get("chapter_idx")
                transition_text = transition.get("transition_text", "")
                
                if not isinstance(chapter_idx, int) or chapter_idx < 0 or chapter_idx >= len(child_node.report.chapters):
                    print(f"âš ï¸ æ— æ•ˆçš„ç« èŠ‚ç´¢å¼•: {chapter_idx}")
                    continue
                
                # æ·»åŠ è¿‡æ¸¡æ–‡æœ¬åˆ°ç« èŠ‚
                chapter = child_node.report.chapters[chapter_idx]
                if not hasattr(chapter, 'transition'):
                    chapter.transition = ""
                
                chapter.transition = transition_text
                success_count += 1
                print(f"   âœ… ä¸ºç¬¬ {chapter_idx + 1} ç« æ·»åŠ è¿‡æ¸¡æ–‡æœ¬")
            
            # å¦‚æœæ²¡æœ‰æˆåŠŸæ·»åŠ ä»»ä½•è¿‡æ¸¡æ–‡æœ¬ï¼Œè·³è¿‡æ­¤èšç±»
            if success_count == 0:
                print(f"âš ï¸ æ²¡æœ‰æˆåŠŸæ·»åŠ ä»»ä½•è¿‡æ¸¡æ–‡æœ¬ï¼Œè·³è¿‡æ­¤èšç±»")
                return None
            
            # è®¾ç½®èŠ‚ç‚¹çŠ¶æ€
            child_node.node_type = ReportGenerationState.FINALIZED
            
            print(f"âœ… æˆåŠŸåº”ç”¨èšç±» {cluster_id} çš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆï¼Œå…± {success_count} ä¸ªè¿‡æ¸¡")
            return [child_node]
            
        except Exception as e:
            print(f"âŒ åº”ç”¨è¿‡æ¸¡æ–‡æœ¬æ—¶å‡ºé”™: {str(e)}")
            traceback.print_exc()
            return None
    
    def create_children_nodes(self, node: "MCTSNode", llm_kwargs: Dict[str, Any]) -> List["MCTSNode"]:
        """ç”Ÿæˆå¤šä¸ªè¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆå¹¶èšç±»é€‰æ‹©æœ€ä¼˜æ–¹æ¡ˆ"""
        return unified_generation_framework(
            node=node,
            action=self,
            llm_kwargs=llm_kwargs,
            action_type="transition",
            prompt_generator=self.generate_transition_prompt,
            node_applier=self.apply_transitions,
            n=3  # ç”Ÿæˆ3ä¸ªä¸åŒçš„è¿‡æ¸¡æ–‡æœ¬æ–¹æ¡ˆ
        )

    

# ä¿®æ­£ save_chart æ–¹æ³•ï¼Œå°†å…¶ä½œä¸ºç±»æ–¹æ³•è€Œä¸æ˜¯ç‹¬ç«‹å‡½æ•°
class ChartUtils:
    @staticmethod
    def save_chart(node: MCTSNode, chart_data: dict) -> str:
        """ä¿å­˜å›¾è¡¨å¹¶è¿”å›URL"""
        # è·å–å½“å‰è¿­ä»£å·ï¼Œæ·»åŠ è°ƒè¯•ä¿¡æ¯
        current_iteration = node.report.current_iteration
        print(f"Debug: ä¿å­˜å›¾è¡¨æ—¶çš„è¿­ä»£å·: {current_iteration}")
        print(f"Debug: èŠ‚ç‚¹ç±»å‹: {node.node_type}")
        print(f"Debug: èŠ‚ç‚¹æ·±åº¦: {node.depth}")
        
        # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„è¿­ä»£å·
        if current_iteration is None or current_iteration < 1:
            print("è­¦å‘Š: current_iteration æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼ 1")
            current_iteration = 1
        
        # æ„å»ºä¿å­˜è·¯å¾„
        iteration_dir = os.path.join("storyteller", "output", "iterations", f"iteration_{current_iteration}")
        charts_dir = os.path.join(iteration_dir, "charts")
        os.makedirs(charts_dir, exist_ok=True)
        
        print(f"Debug: å›¾è¡¨å°†ä¿å­˜åˆ°: {charts_dir}")
        
        return charts_dir




# å°†å­—å…¸å®šä¹‰ä¿ç•™ä¸ºæ¨¡å—çº§å˜é‡
NODE_TYPE_TO_VALID_ACTIONS = {
    ReportGenerationState.EMPTY: [
        Query2Chapters
    ],
    ReportGenerationState.a1: [
        Chapters2Tasks,
    ],
    ReportGenerationState.a2: [
        Tasks2Charts
    ],
    ReportGenerationState.a3: [
        ReviseVis,
        Charts2Captions
    ],
    ReportGenerationState.a4: [
        Charts2Captions
    ],
    ReportGenerationState.a5: [
        Captions2Summaries,
    ],
    ReportGenerationState.a6: [
        ReviseNarrativeStrategy,
        TransitionAction
    ],
    ReportGenerationState.REVISECHAPTERSORDERS: [
        TransitionAction
    ], 
    ReportGenerationState.FINALIZED: []  # ç»ˆæ­¢çŠ¶æ€ï¼Œæ·»åŠ è¿‡æ¸¡åçš„æœ€ç»ˆçŠ¶æ€
}



